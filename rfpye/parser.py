# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/01_parser.ipynb (unless otherwise specified).

__all__ = ['parse_bin', 'evaluate_checksum', 'byte2base_block', 'create_block', 'classify_blocks', 'parse_bin',
           'evaluate_checksum', 'byte2base_block', 'create_block', 'classify_blocks']

# Internal Cell
import os
from pathlib import Path
from typing import *
from collections import defaultdict, namedtuple
from fastcore.basics import partialler, listify
from fastcore.utils import parallel
from fastcore.foundation import L
from .constants import BYTES_HEADER, ENDMARKER, KEY_ATTRS
from .blocks import MAIN_BLOCKS
from .utils import get_files, getattrs, bin2int, bin2str
from .cyparser import cy_extract_compressed
from loguru import logger
import pandas as pd
import numpy as np

# Internal Cell
logger.add("parser.log", rotation="1 month", compression='zip', backtrace=True, diagnose=True)

# Cell
def parse_bin(
    bin_file: Union[str, Path],
    slice_: slice = None,
) -> dict:
    """Receives a CRFS binfile and return a dictionary with its different blocks
    A block is a piece of the .bin file with a known start and end and that contains different types of information.
    It has several fields: file_type, header, data and footer.
    Each field has lengths and information defined in the documentation.
    Args:
        bin_file (Union[str, Path]): path to the bin file
        btypes (Iterable, optional): Restrict processing to only these block types. Defaults to MAIN_BLOCKS.keys().
        slice_ (slice, optional): Slice to cut the bin file if desired. Defaults to None.
        bytes_header (int, optional): File Header Size. Defaults to BYTES_HEADER.
        marker (bytes, optional): Byte marker delimiting the end of one block. Defaults to ENDMARKER.

    Returns:
        Dictionary with the bin_file version, string info and metadata from the different blocks.
    """
    bin_file = Path(bin_file)
    with open(bin_file, mode="rb") as bfile:
        # The first block of the file is the header and is 36 bytes long.
        header = bfile.read(BYTES_HEADER)
        body = bfile.read()
    if slice_ is not None:
        assert (
            slice_.start >= BYTES_HEADER
        ), f"The start of your slice has to be >= {BYTES_HEADER}, you passed {slice_.start} "
        body = body[slice_]
    return {
        "filename" : bin_file.name,
        "file_version": bin2int(header[:4]),
        "string": bin2str(header[4:]),
        "blocks": classify_blocks(body.split(ENDMARKER)),
    }

# Cell
def evaluate_checksum(byte_block: bytes)->int:
    """Receives a byte_block and verify if the calculated checksum is equal to the one registed in the specific byte"""
    try:
        checksum = np.frombuffer(byte_block[-4:], dtype=np.uint32).item()
        calculated_checksum = (
            np.frombuffer(byte_block[:-4], dtype=np.uint8).sum().astype(np.uint32).item()
        )
    except ValueError:
        return -1
    return checksum if calculated_checksum == checksum else -1

# Cell
def byte2base_block(byte_block: bytes) -> tuple:
    """Receives a byte block from the bin file and returns a dictionary with the attributes
    'thread_id', 'size', 'type', 'data', 'checksum' or an empty dict in case any error is identified.
    """
    if byte_block == b"": return ()
    base_block = namedtuple('base_block', ['thread_id', 'size', 'type', 'data', 'checksum'])
    checksum = evaluate_checksum(byte_block)
    size = bin2int(byte_block[4:8])
    data = byte_block[12:-4]
    # Discard the block if a fail in checksum or in case of a truncated block
    if checksum == -1 or size != len(data): return ()
    return base_block(bin2int(byte_block[:4]), size, bin2int(byte_block[8:12]), data, checksum)

# Cell
def create_block(byte_block):
    base_block = byte2base_block(byte_block)
    if not base_block: return None
    block_type = base_block.type
    constructor = MAIN_BLOCKS.get(block_type)
    if not constructor:
        logger.debug(f'This block type constructor is not implemented: {block_type}')
        return None
    block = constructor(base_block)
    if getattr(block, "gerror", -1) != -1 or getattr(block, 'gps_status', -1) == 0:
        logger.debug(f'Block with error: {block_type}')
        return None #spectral or gps blocks with error
    return block


# Cell
def classify_blocks(byte_blocks: Iterable) -> defaultdict:
    """Receives an iterable L with binary blocks and returns a defaultdict with a tuple (block types, thread_id) as keys and a list of the Class Blocks as values
    :param file: A string or pathlib.Path like path to a `.bin`file generated by CFRS - Logger
    :return: A Dictionary with block types as keys and a list of the Class Blocks available as values
    """
    map_block: Mapping[Tuple, L] = defaultdict(L)
    for byte_block in byte_blocks:
        block = create_block(byte_block)
        if not block: continue
        attrs = getattrs(block, attrs=KEY_ATTRS.get(block.type, ('type', 'thread_id')))
        map_block[attrs].append(block)
    return map_block

# Internal Cell
import os
from pathlib import Path
from typing import *
from collections import defaultdict, namedtuple
from fastcore.basics import partialler, listify
from fastcore.utils import parallel
from fastcore.foundation import L
from .constants import BYTES_HEADER, ENDMARKER, KEY_ATTRS
from .blocks import MAIN_BLOCKS
from .utils import get_files, getattrs, bin2int, bin2str
from .cyparser import cy_extract_compressed
from loguru import logger
import pandas as pd
import numpy as np

# Internal Cell
logger.add("parser.log", rotation="1 month", compression='zip', backtrace=True, diagnose=True)

# Cell
def parse_bin(
    bin_file: Union[str, Path],
    slice_: slice = None,
) -> dict:
    """Receives a CRFS binfile and return a dictionary with its different blocks
    A block is a piece of the .bin file with a known start and end and that contains different types of information.
    It has several fields: file_type, header, data and footer.
    Each field has lengths and information defined in the documentation.
    Args:
        bin_file (Union[str, Path]): path to the bin file
        btypes (Iterable, optional): Restrict processing to only these block types. Defaults to MAIN_BLOCKS.keys().
        slice_ (slice, optional): Slice to cut the bin file if desired. Defaults to None.
        bytes_header (int, optional): File Header Size. Defaults to BYTES_HEADER.
        marker (bytes, optional): Byte marker delimiting the end of one block. Defaults to ENDMARKER.

    Returns:
        Dictionary with the bin_file version, string info and metadata from the different blocks.
    """
    bin_file = Path(bin_file)
    with open(bin_file, mode="rb") as bfile:
        # The first block of the file is the header and is 36 bytes long.
        header = bfile.read(BYTES_HEADER)
        body = bfile.read()
    if slice_ is not None:
        assert (
            slice_.start >= BYTES_HEADER
        ), f"The start of your slice has to be >= {BYTES_HEADER}, you passed {slice_.start} "
        body = body[slice_]
    return {
        "filename" : bin_file.name,
        "file_version": bin2int(header[:4]),
        "string": bin2str(header[4:]),
        "blocks": classify_blocks(body.split(ENDMARKER)),
    }

# Cell
def evaluate_checksum(byte_block: bytes)->int:
    """Receives a byte_block and verify if the calculated checksum is equal to the one registed in the specific byte"""
    try:
        checksum = np.frombuffer(byte_block[-4:], dtype=np.uint32).item()
        calculated_checksum = (
            np.frombuffer(byte_block[:-4], dtype=np.uint8).sum().astype(np.uint32).item()
        )
    except ValueError:
        return -1
    return checksum if calculated_checksum == checksum else -1

# Cell
def byte2base_block(byte_block: bytes) -> tuple:
    """Receives a byte block from the bin file and returns a dictionary with the attributes
    'thread_id', 'size', 'type', 'data', 'checksum' or an empty dict in case any error is identified.
    """
    if byte_block == b"": return ()
    base_block = namedtuple('base_block', ['thread_id', 'size', 'type', 'data', 'checksum'])
    checksum = evaluate_checksum(byte_block)
    size = bin2int(byte_block[4:8])
    data = byte_block[12:-4]
    # Discard the block if a fail in checksum or in case of a truncated block
    if checksum == -1 or size != len(data): return ()
    return base_block(bin2int(byte_block[:4]), size, bin2int(byte_block[8:12]), data, checksum)

# Cell
def create_block(byte_block):
    base_block = byte2base_block(byte_block)
    if not base_block: return None
    block_type = base_block.type
    constructor = MAIN_BLOCKS.get(block_type)
    if not constructor:
        logger.debug(f'This block type constructor is not implemented: {block_type}')
        return None
    block = constructor(base_block)
    if getattr(block, "gerror", -1) != -1 or getattr(block, 'gps_status', -1) == 0:
        logger.debug(f'Block with error: {block_type}')
        return None #spectral or gps blocks with error
    return block


# Cell
def classify_blocks(byte_blocks: Iterable) -> defaultdict:
    """Receives an iterable L with binary blocks and returns a defaultdict with a tuple (block types, thread_id) as keys and a list of the Class Blocks as values
    :param file: A string or pathlib.Path like path to a `.bin`file generated by CFRS - Logger
    :return: A Dictionary with block types as keys and a list of the Class Blocks available as values
    """
    map_block: Mapping[Tuple, L] = defaultdict(L)
    for byte_block in byte_blocks:
        block = create_block(byte_block)
        if not block: continue
        attrs = getattrs(block, attrs=KEY_ATTRS.get(block.type, ('type', 'thread_id')))
        map_block[attrs].append(block)
    return map_block