{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser\n",
    "> Este módulo processa o arquivo bin e extrai os metadados e dados do espectro dos blocos, além de criar estatísticas das medições.\n",
    "  en: This module process the bin file extracting its metadata and spectrum levels besides extracting useful statistics.\n",
    "  fr: Ce module traite le fichier bin et extrait les métadonnées et les données spectrales des blocs, en plus de créer des statistiques de mesure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "The cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext line_profiler\n",
    "%load_ext cython\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exporti\n",
    "import os\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "from dataclasses import make_dataclass\n",
    "from datetime import datetime, timedelta\n",
    "from fastcore.basics import partialler\n",
    "from fastcore.utils import parallel\n",
    "from fastcore.foundation import L, GetAttr\n",
    "from rfpye.constants import *\n",
    "from rfpye.blocks import MAIN_BLOCKS, BaseBlock\n",
    "from rfpye.utils import get_files, getattrs, bin2int, bin2str, cached\n",
    "from rfpye.cyparser import cy_extract_compressed\n",
    "from loguru import logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rich import print\n",
    "\n",
    "# For scripts\n",
    "config = {\n",
    "    \"handlers\": [\n",
    "        {\n",
    "            \"sink\": \"parser.log\",\n",
    "            \"serialize\": True,\n",
    "            \"rotation\": \"1 week\",\n",
    "            \"compression\": \"zip\",\n",
    "            \"backtrace\": True,\n",
    "            \"diagnose\": True,\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "logger.configure(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "class CrfsGPS:\n",
    "    \"\"\"Class with the GPS Attributes from the CRFS Bin File\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        self._data: L = L()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self._latitude[key], self._longitude[key], self._altitude[key], self._num_satellites[key]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return zip(self._latitude, self._longitude, self._altitude, self._num_satellites)\n",
    "\n",
    "    @cached\n",
    "    def _gps_datetime(self):\n",
    "        return self._data.attrgot(\"gps_datetime\")\n",
    "\n",
    "    @cached\n",
    "    def _latitude(self):\n",
    "        return self._data.attrgot(\"latitude\")\n",
    "\n",
    "    @cached\n",
    "    def _longitude(self):\n",
    "        return self._data.attrgot(\"longitude\")\n",
    "\n",
    "    @cached\n",
    "    def _altitude(self):\n",
    "        return self._data.attrgot(\"altitude\")\n",
    "\n",
    "    @cached\n",
    "    def _num_satellites(self):\n",
    "        return self._data.attrgot(\"num_satellites\")\n",
    "\n",
    "    @property\n",
    "    def latitude(self) -> float:\n",
    "        return np.median(self._latitude) if self._latitude else -1\n",
    "\n",
    "    @property\n",
    "    def longitude(self) -> float:\n",
    "        return np.median(self._longitude) if self._longitude else -1\n",
    "\n",
    "    @property\n",
    "    def altitude(self) -> float:\n",
    "        return np.median(self._altitude) if self._altitude else -1\n",
    "\n",
    "    @property\n",
    "    def num_satellites(self) -> float:\n",
    "        return np.median(self._num_satellites) if self._num_satellites else 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"GPS Data - Median of Coordinates: {self.latitude:.5f}:{self.longitude:.5f} Altitude: {self.altitude:.2f} #Satellites: {self.num_satellites:.1f}\"\n",
    "\n",
    "\n",
    "class CrfsSpectrum(GetAttr):\n",
    "    \"\"\"Class with the metadata and levels of a spectrum block from a CRFS Bin File\"\"\"\n",
    "\n",
    "    def __init__(self, metadata, precision=np.float32):\n",
    "        self.default = metadata\n",
    "        self._data: L = L()\n",
    "        self.precision = precision\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.timestamp[key], self.levels[key]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return zip(self.timestamp, self.levels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(self.default)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"\"\"Blocks of Type: {self.type}, Thread_id: {self.thread_id}, Start: {self.start_mega} MHz, Stop: {self.stop_mega} MHz\"\"\"\n",
    "\n",
    "    @cached\n",
    "    def timestamp(self):\n",
    "        return self._data.attrgot('wallclock_datetime')\n",
    "\n",
    "    @cached\n",
    "    def start_dateidx(self):\n",
    "        return getattr(self._data[0], 'wallclock_datetime').item()\n",
    "\n",
    "    @cached\n",
    "    def stop_dateidx(self):\n",
    "        return getattr(self._data[-1], 'wallclock_datetime').item()\n",
    "\n",
    "    @cached\n",
    "    def levels(self):\n",
    "        \"\"\"Return the spectrum levels\"\"\"\n",
    "        if self.type in UNCOMPRESSED:\n",
    "            levels = np.empty((len(self._data), self.ndata), dtype=self.precision)\n",
    "            for i, level in enumerate(self._data.attrgot('levels')):\n",
    "                levels[i,:] = level\n",
    "            # levels = np.concatenate(self._data.attrgot('levels')).reshape((-1, self.ndata))\n",
    "        elif self.type in COMPRESSED:\n",
    "            levels = cy_extract_compressed(\n",
    "                list(self._data.attrgot('levels')),\n",
    "                len(self._data),\n",
    "                int(self.ndata),\n",
    "                int(self.thresh),\n",
    "                float(self.minimum),\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"The current block is not of type spectrum or it's not implemented yet\"\n",
    "            )\n",
    "        if self.precision != np.float32:\n",
    "            levels = levels.astype(self.precision)\n",
    "        return levels\n",
    "\n",
    "    @cached\n",
    "    def frequencies(self) -> np.ndarray:\n",
    "        return np.linspace(self.start_mega, self.stop_mega, num=self.ndata)\n",
    "\n",
    "    def matrix(self):\n",
    "        \"\"\"Returns the matrix formed from the spectrum levels and timestamp\"\"\"\n",
    "        index = self.timestamp if len(self.timestamp) == len(self) else None\n",
    "        data = pd.DataFrame(self.levels, index=index, columns=self.frequencies)\n",
    "        data.columns.name = \"Frequencies\"\n",
    "        data.index.name = \"Time\"\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def append_spec_data(block_type, fluxos, block, precision=np.float32) -> None:\n",
    "    \"\"\"Append the spectrum data to the fluxos dict\"\"\"\n",
    "    keys, vals = getattrs(block, KEY_ATTRS.get(block_type), as_tuple=True)\n",
    "    if vals not in fluxos:\n",
    "        metadata = make_dataclass('Spectrum', fields=[(k,type(k)) for k in keys], eq=True, frozen=True)\n",
    "        fluxos[vals] = CrfsSpectrum(metadata(*vals), precision)\n",
    "    fluxos[vals]._data.append(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento do Arquivo `.bin` e criação dos diferentes tipos de blocos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def evaluate_checksum(file, next_block, data_size) -> int:\n",
    "    \"\"\"Receives a byte_block and verify if the calculated checksum is equal to the one registed in the specific byte\"\"\"\n",
    "    try:\n",
    "        checksum = np.frombuffer(file.read(4), np.uint32).item()\n",
    "    except ValueError:\n",
    "        logger.error(f\"Erro na leitura do checksum, posição: {file.tell()}\")\n",
    "        return None\n",
    "    block_size = file.tell() - next_block\n",
    "    file.seek(-block_size, 1) # Go back to the beginning of the block\n",
    "    calculated_checksum = (\n",
    "            np.frombuffer(file.read(12+data_size), dtype=np.uint8)\n",
    "            .sum()\n",
    "            .astype(np.uint32)\n",
    "            .item()\n",
    "        )\n",
    "    file.seek(4,1) # skip checksum\n",
    "    if checksum != calculated_checksum:\n",
    "        logger.error(f\"Checksum diferente: {checksum} != {calculated_checksum}. Posicao: {file.tell()}\")\n",
    "        return None\n",
    "    return checksum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def buffer2base_block(file, next_block: int) -> Union[BaseBlock, None]:\n",
    "    \"\"\"Receives an opened file buffer from the bin file and returns a dataclass with the attributes\n",
    "    'thread_id', 'size', 'type', 'data', 'checksum' or None in case any error is identified.\n",
    "    \"\"\"\n",
    "    start = file.tell()\n",
    "    thread_id = np.frombuffer(file.read(4), np.int32).item()\n",
    "    block_size = np.frombuffer(file.read(4), np.int32).item()\n",
    "    block_type = np.frombuffer(file.read(4), np.int32).item()\n",
    "    data_block = file.read(block_size)\n",
    "    if (checksum := evaluate_checksum(file, next_block, block_size)) is None:\n",
    "        file.seek(start, 0)\n",
    "        while file.read(4) not in (b'', b'UUUU'):\n",
    "            continue\n",
    "        return None, None \n",
    "    if (eof := file.read(4)) != b'UUUU':\n",
    "        logger.error(f\"EOF diferente de UUUU: {eof}, posicao: {file.tell()}\")\n",
    "        return None, None                      \n",
    "    return block_type, BaseBlock(thread_id, block_size, block_type, data_block, checksum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função a seguir recebe os bytes lidos do arquivo `.bin` e mapeia esses bytes em diferentes classes de acordo com o tipo de bloco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def create_block(file, next_block) -> Tuple:\n",
    "    \"\"\"Receives a byte_block, and converts it into one of the main classes\n",
    "    Args: byte_block: A byte block directly returned from the file\n",
    "    Returns: The Instance of the Block Type or None in case of error\n",
    "    \"\"\"\n",
    "    block_type, base_block = buffer2base_block(file, next_block)\n",
    "    if block_type is None:\n",
    "        return None, None\n",
    "    constructor = MAIN_BLOCKS.get(block_type)\n",
    "    if not constructor:\n",
    "        logger.warning(f\"This block type constructor is not implemented: {block_type}\")\n",
    "        return None, None\n",
    "    block = constructor(base_block)\n",
    "    if getattr(block, \"gerror\", -1) != -1 or getattr(block, \"gps_status\", -1) == 0:\n",
    "        logger.error(\"INFO\", f\"Block with error: {block_type}\")\n",
    "        return None, None  # spectral or gps blocks with error\n",
    "    return block_type, block\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função a seguir recebe os bytes lidos do arquivo `.bin` e mapeia esses bytes em diferentes classes de acordo com o tipo de bloco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def parse_bin(bin_file: Union[str, Path], precision=np.float32) -> dict:\n",
    "    \"\"\"Receives a CRFS binfile and returns a dictionary with the file metadata, a GPS Class and a list with the different Spectrum Classes\n",
    "    A block is a piece of the .bin file with a known start and end and that contains different types of information.\n",
    "    It has several fields: file_type, header, data and footer.\n",
    "    Each field has lengths and information defined in the documentation.\n",
    "    Args:\n",
    "        bin_file (Union[str, Path]): path to the bin file\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with the file metadata, file_version, string info, gps and spectrum blocks.\n",
    "    \"\"\"\n",
    "    bin_file = Path(bin_file)\n",
    "    meta = {}\n",
    "    fluxos = {}\n",
    "    gps = CrfsGPS()\n",
    "    with open(bin_file, mode=\"rb\") as file:\n",
    "        # The first block of the file is the header and is 36 bytes long.\n",
    "        header = file.read(BYTES_HEADER)\n",
    "        meta[\"filename\"] = bin_file.name\n",
    "        meta[\"file_version\"] = bin2int(header[:4])\n",
    "        if meta['file_version'] == 21:\n",
    "            meta['method'] = 'Script_CRFSBINv2'\n",
    "        meta[\"string\"] = bin2str(header[4:])\n",
    "        file_size = file.seek(0, 2)\n",
    "        file.seek(36, 0)\n",
    "        while (next_block := file.tell()) < file_size:\n",
    "            block_type, block = create_block(file, next_block)\n",
    "            if block is None: \n",
    "                continue\n",
    "            if block_type in (2, 40):\n",
    "                gps._data.append(block)\n",
    "            elif block_type in VECTOR_BLOCKS:\n",
    "                append_spec_data(block_type,fluxos, block, precision)\n",
    "            else:\n",
    "                meta.update(getattrs(block, KEY_ATTRS.get(block_type)))\n",
    "    meta[\"gps\"] = gps\n",
    "    meta[\"spectrum\"] = L(fluxos.values())\n",
    "    meta['hostname'] = meta['hostname'][:2].upper() + meta['hostname'][2:]\n",
    "    \n",
    "    if modtime := getattr(gps, '_gps_datetime'):\n",
    "        modtime = modtime[-1] #.astype(datetime)\n",
    "    else:\n",
    "        modtime = np.datetime64(datetime.fromtimestamp(bin_file.stat().st_mtime))\n",
    "        \n",
    "    def set_timestamp(spec)-> None:\n",
    "        \"\"\"Create a timestamp from the file modification time backwards by 1s for each measurement\"\"\"\n",
    "        timestamp = L()\n",
    "        mtime = modtime\n",
    "        for s in range(len(spec)):\n",
    "            timestamp.append(mtime)\n",
    "            mtime -= np.timedelta64(1, \"s\")\n",
    "        timestamp.reverse()\n",
    "        setattr(spec, 'timestamp', timestamp)\n",
    "        \n",
    "\n",
    "    meta['spectrum'].filter(lambda x: x.type in (4,7)).map(set_timestamp)\n",
    "    \n",
    "    return meta                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) [Path('D:/OneDrive - ANATEL/BinFiles/Combo1 (RFLook - arquivos iniciais)/201201_T153421_OneThreadID.bin'),Path('D:/OneDrive - ANATEL/BinFiles/Combo1 (RFLook - arquivos iniciais)/201201_T154509_MultiplesThreadID.bin'),Path('D:/OneDrive - ANATEL/BinFiles/Combo1 (RFLook - arquivos iniciais)/SCAN_M_450470_rfeye002088_170426_171908.bin'),Path('D:/OneDrive - ANATEL/BinFiles/Combo1 (RFLook - arquivos iniciais)/Script1.cfg')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = get_files('D:\\OneDrive - ANATEL\\BinFiles\\Combo1 (RFLook - arquivos iniciais)')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': 'rfeye002292_210208_T203238_CRFSBINv.3.bin',\n",
       " 'file_version': 21,\n",
       " 'method': 'Script_CRFSBINv3',\n",
       " 'string': 'CRFS DATA FILE V021',\n",
       " 'hostname': 'RFeye002292',\n",
       " 'unit_info': 'Stationary',\n",
       " 'file_number': 0,\n",
       " 'identifier': 'LOGGER_VERSION',\n",
       " 'description': 'ClearWrite. Peak.',\n",
       " 'gps': GPS Data - Median of Coordinates: -12.97163:-38.48149 Altitude: 150.60 #Satellites: 12.0,\n",
       " 'spectrum': (#8) [Spectrum(type=60, thread_id=10, start_mega=105, stop_mega=140, ndata=3584, nloops=1, processing='peak', antuid=0),Spectrum(type=60, thread_id=11, start_mega=105, stop_mega=140, ndata=3584, nloops=1, processing='average', antuid=0),Spectrum(type=60, thread_id=20, start_mega=76, stop_mega=108, ndata=8192, nloops=1, processing='peak', antuid=0),Spectrum(type=60, thread_id=30, start_mega=70, stop_mega=110, ndata=1024, nloops=4, processing='peak', antuid=0),Spectrum(type=60, thread_id=12, start_mega=105, stop_mega=140, ndata=3584, nloops=1, processing='peak', antuid=0),Spectrum(type=60, thread_id=13, start_mega=105, stop_mega=140, ndata=3584, nloops=1, processing='average', antuid=0),Spectrum(type=61, thread_id=14, thresh=-90, minimum=-147.5, start_mega=105, stop_mega=140, ndata=3584, nloops=1, processing='average', antuid=0),Spectrum(type=62, thread_id=15, start_mega=105, stop_mega=140, thresh=-90, ndata=3584, antuid=0)]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = r'D:\\OneDrive - ANATEL\\SpecFiles\\Combo3 (CRFS Bin - DataTypes 4, 7, 8, 60-65 e 67-69)\\rfeye002292_210208_T203238_CRFSBINv.3.bin'\n",
    "#file = r'D:\\OneDrive - ANATEL\\SpecFiles\\Combo3 (CRFS Bin - DataTypes 4, 7, 8, 60-65 e 67-69)\\rfeye002292_210208_T202215_CRFSBINv.4.bin'\n",
    "dados = parse_bin(file)\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('D:/OneDrive - ANATEL/SpecFiles/.git'),\n",
       " Path('D:/OneDrive - ANATEL/SpecFiles/Combo1 (Arquivos Performance)'),\n",
       " Path('D:/OneDrive - ANATEL/SpecFiles/Combo2 (Arquivos com Erros)'),\n",
       " Path('D:/OneDrive - ANATEL/SpecFiles/Combo3 (CRFS Bin - DataTypes 4, 7, 8, 60-65 e 67-69)'),\n",
       " Path('D:/OneDrive - ANATEL/SpecFiles/Combo4 (CRFS Bin - Multiples ThreadID 10)'),\n",
       " Path('D:/OneDrive - ANATEL/SpecFiles/Combo5 (CRFS Bin - Same Task Differents ThreadIDs)'),\n",
       " Path('D:/OneDrive - ANATEL/SpecFiles/Combo6 (CRFS Bin - PMEC e PRD 2020)'),\n",
       " Path('D:/OneDrive - ANATEL/SpecFiles/Combo7 (CRFS Bin - PMEC e PRD 2021)'),\n",
       " Path('D:/OneDrive - ANATEL/SpecFiles/Combo8 (Argus CSV)'),\n",
       " Path('D:/OneDrive - ANATEL/SpecFiles/Combo9 (RF Look Bin)'),\n",
       " Path('D:/OneDrive - ANATEL/SpecFiles/README.md')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "list(Path('D:\\OneDrive - ANATEL\\SpecFiles').iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">numpy.datetime64</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'2021-02-08T20:32:59'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">numpy.datetime64</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'2021-02-08T20:33:59'</span><span style=\"font-weight: bold\">)</span>, \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">numpy.datetime64</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'2021-02-08T20:34:59'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">numpy.datetime64</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'2021-02-08T20:35:59'</span><span style=\"font-weight: bold\">)</span>, \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">numpy.datetime64</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'2021-02-08T20:36:59'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">numpy.datetime64</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'2021-02-08T20:37:59'</span><span style=\"font-weight: bold\">)</span>, \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">numpy.datetime64</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'2021-02-08T20:38:59'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">numpy.datetime64</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'2021-02-08T20:39:59'</span><span style=\"font-weight: bold\">)</span>, \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">numpy.datetime64</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'2021-02-08T20:40:59'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">numpy.datetime64</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'2021-02-08T20:41:59'</span><span style=\"font-weight: bold\">)</span>, \n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">numpy.datetime64</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'2021-02-08T20:42:59'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">numpy.datetime64</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'2021-02-08T20:43:59'</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;35mnumpy.datetime64\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'2021-02-08T20:32:59'\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mnumpy.datetime64\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'2021-02-08T20:33:59'\u001b[0m\u001b[1m)\u001b[0m, \n",
       "\u001b[1;35mnumpy.datetime64\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'2021-02-08T20:34:59'\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mnumpy.datetime64\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'2021-02-08T20:35:59'\u001b[0m\u001b[1m)\u001b[0m, \n",
       "\u001b[1;35mnumpy.datetime64\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'2021-02-08T20:36:59'\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mnumpy.datetime64\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'2021-02-08T20:37:59'\u001b[0m\u001b[1m)\u001b[0m, \n",
       "\u001b[1;35mnumpy.datetime64\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'2021-02-08T20:38:59'\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mnumpy.datetime64\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'2021-02-08T20:39:59'\u001b[0m\u001b[1m)\u001b[0m, \n",
       "\u001b[1;35mnumpy.datetime64\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'2021-02-08T20:40:59'\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mnumpy.datetime64\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'2021-02-08T20:41:59'\u001b[0m\u001b[1m)\u001b[0m, \n",
       "\u001b[1;35mnumpy.datetime64\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'2021-02-08T20:42:59'\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mnumpy.datetime64\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'2021-02-08T20:43:59'\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dados['gps']._gps_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Error compiling Cython file:\n",
      "------------------------------------------------------------\n",
      "...\n",
      "\n",
      "ctypedef object CrfsGPS\n",
      "\n",
      "@cython.boundscheck(False)\n",
      "@cython.wraparound(False)\n",
      "^\n",
      "------------------------------------------------------------\n",
      "\n",
      "C:\\Users\\rsilva\\.ipython\\cython\\_cython_magic_98c655412a46cff311afb5f5b8b31186.pyx:7:0: Decorators can only be followed by functions or classes\n"
     ]
    }
   ],
   "source": [
    "%%cython --annotate\n",
    "cimport cython\n",
    "\n",
    "ctypedef object CrfsGPS\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rfpye39]",
   "language": "python",
   "name": "conda-env-rfpye39-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
