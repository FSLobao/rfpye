{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser\n",
    ">  Este módulo lida com o processamento e análise dos metadados e dados do espectro dos blocos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))\n",
    "\n",
    "%load_ext autoreload\n",
    "%load_ext line_profiler\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rsilva\\Miniconda3\\envs\\rfpy\\lib\\site-packages\\fastprogress\\fastprogress.py:102: UserWarning: Couldn't import ipywidgets properly, progress bar will use console behavior\n",
      "  warn(\"Couldn't import ipywidgets properly, progress bar will use console behavior\")\n"
     ]
    }
   ],
   "source": [
    "#exporti\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "from collections import defaultdict, namedtuple\n",
    "from fastcore.basics import partialler, listify\n",
    "from fastcore.utils import parallel\n",
    "from fastcore.foundation import L\n",
    "from rfpye.constants import BYTES_HEADER, ENDMARKER, KEY_ATTRS\n",
    "from rfpye.blocks import MAIN_BLOCKS\n",
    "from rfpye.utils import get_files, getattrs, bin2int, bin2str\n",
    "from rfpye.cyparser import cy_extract_compressed\n",
    "from loguru import logger\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exporti\n",
    "logger.add(\"parser.log\", rotation=\"1 month\", compression='zip', backtrace=True, diagnose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento do Arquivo `.bin` e criação dos diferentes tipos de blocos\n",
    "A função seguinte `parse_bin` recebe um arquivo `.bin` e mapeia os blocos contidos nele retornando um dicionário:\n",
    " * `file_version`: Versão do arquivo `.bin`\n",
    " * `blocks`: Dicionário com os blocos do arquivo `.bin`. Cada tipo de bloco tem sua Classe Própria\n",
    " \n",
    " O dicionário `blocks` retornado tem como chave uma tupla (tipo de bloco, `thread_id`) e os valores como uma lista com os blocos ( classes ) extraídos sequencialmente.\n",
    "\n",
    "O tipo de bloco é a natureza do dado contido, por exemplo: 40 - GPS, 67 - Dado Espectral. O `thread_id` discrimina em geral diferentes \"faixas\" do mesmo tipo de dado. Para dados espectrais, por exemplo, diferentes thread_id representam varreduras de faixas de frequência distintas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_files(r'D:\\OneDrive - ANATEL\\Sensores', extensions=['.bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_bin(\n",
    "    bin_file: Union[str, Path],\n",
    "    slice_: slice = None,\n",
    ") -> dict:\n",
    "    \"\"\"Receives a CRFS binfile and return a dictionary with its different blocks\n",
    "    A block is a piece of the .bin file with a known start and end and that contains different types of information.\n",
    "    It has several fields: file_type, header, data and footer.\n",
    "    Each field has lengths and information defined in the documentation.\n",
    "    Args:\n",
    "        bin_file (Union[str, Path]): path to the bin file\n",
    "        btypes (Iterable, optional): Restrict processing to only these block types. Defaults to MAIN_BLOCKS.keys().\n",
    "        slice_ (slice, optional): Slice to cut the bin file if desired. Defaults to None.\n",
    "        bytes_header (int, optional): File Header Size. Defaults to BYTES_HEADER.\n",
    "        marker (bytes, optional): Byte marker delimiting the end of one block. Defaults to ENDMARKER.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with the bin_file version, string info and metadata from the different blocks.\n",
    "    \"\"\"\n",
    "    bin_file = Path(bin_file)\n",
    "    with open(bin_file, mode=\"rb\") as bfile:\n",
    "        # The first block of the file is the header and is 36 bytes long.\n",
    "        header = bfile.read(BYTES_HEADER)\n",
    "        body = bfile.read()\n",
    "    if slice_ is not None:\n",
    "        assert (\n",
    "            slice_.start >= BYTES_HEADER\n",
    "        ), f\"The start of your slice has to be >= {BYTES_HEADER}, you passed {slice_.start} \"\n",
    "        body = body[slice_]\n",
    "    return {\n",
    "        \"filename\" : bin_file.name,\n",
    "        \"file_version\": bin2int(header[:4]),\n",
    "        \"string\": bin2str(header[4:]),\n",
    "        \"blocks\": classify_blocks(body.split(ENDMARKER)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = files.shuffle()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função a seguir recebe os bytes lidos do arquivo `.bin` e mapeia esses bytes em diferentes classes de acordo com o tipo de bloco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def evaluate_checksum(byte_block: bytes)->int:\n",
    "    \"\"\"Receives a byte_block and verify if the calculated checksum is equal to the one registed in the specific byte\"\"\"\n",
    "    try:\n",
    "        checksum = np.frombuffer(byte_block[-4:], dtype=np.uint32).item()\n",
    "        calculated_checksum = (\n",
    "            np.frombuffer(byte_block[:-4], dtype=np.uint8).sum().astype(np.uint32).item()\n",
    "        )\n",
    "    except ValueError:\n",
    "        return -1\n",
    "    return checksum if calculated_checksum == checksum else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def byte2base_block(byte_block: bytes) -> tuple:\n",
    "    \"\"\"Receives a byte block from the bin file and returns a dictionary with the attributes\n",
    "    'thread_id', 'size', 'type', 'data', 'checksum' or an empty dict in case any error is identified.\n",
    "    \"\"\"\n",
    "    if byte_block == b\"\": return ()\n",
    "    base_block = namedtuple('base_block', ['thread_id', 'size', 'type', 'data', 'checksum'])\n",
    "    checksum = evaluate_checksum(byte_block)\n",
    "    size = bin2int(byte_block[4:8])\n",
    "    data = byte_block[12:-4]\n",
    "    # Discard the block if a fail in checksum or in case of a truncated block\n",
    "    if checksum == -1 or size != len(data): return () \n",
    "    return base_block(bin2int(byte_block[:4]), size, bin2int(byte_block[8:12]), data, checksum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_block(byte_block):\n",
    "    base_block = byte2base_block(byte_block)\n",
    "    if not base_block: return None\n",
    "    block_type = base_block.type\n",
    "    constructor = MAIN_BLOCKS.get(block_type)\n",
    "    if not constructor:\n",
    "        logger.debug(f'This block type constructor is not implemented: {block_type}')\n",
    "        return None\n",
    "    block = constructor(base_block)\n",
    "    if getattr(block, \"gerror\", -1) != -1 or getattr(block, 'gps_status', -1) == 0:\n",
    "        logger.debug(f'Block with error: {block_type}')\n",
    "        return None #spectral or gps blocks with error\n",
    "    return block \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def classify_blocks(byte_blocks: Iterable) -> defaultdict:\n",
    "    \"\"\"Receives an iterable L with binary blocks and returns a defaultdict with a tuple (block types, thread_id) as keys and a list of the Class Blocks as values\n",
    "    :param file: A string or pathlib.Path like path to a `.bin`file generated by CFRS - Logger\n",
    "    :return: A Dictionary with block types as keys and a list of the Class Blocks available as values\n",
    "    \"\"\"\n",
    "    map_block: Mapping[Tuple, L] = defaultdict(L)\n",
    "    for byte_block in byte_blocks:\n",
    "        block = create_block(byte_block)\n",
    "        if not block: continue\n",
    "        attrs = getattrs(block, attrs=KEY_ATTRS.get(block.type, ('type', 'thread_id')))\n",
    "        map_block[attrs].append(block)\n",
    "    return map_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_main.ipynb.\n",
      "Converted 01_parser.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_blocks.ipynb.\n",
      "Converted 04_constants.ipynb.\n",
      "Converted 05_stats.ipynb.\n",
      "Converted 06_meta.ipynb.\n",
      "No export destination, ignored:\n",
      "#exporti\n",
      "def _extract_uncompressed(\n",
      "    blocks: Iterable, rows: int, cols: int, min_level: float, dtype=np.float16\n",
      "):\n",
      "    levels = np.full((rows, cols), min_level, dtype=dtype)\n",
      "    block_data = \"raw_data\" if dtype == np.uint8 else \"block_data\"\n",
      "    for b, block in enumerate(blocks):\n",
      "        levels[b] = getattr(block, block_data)\n",
      "    return levels\n",
      "No export destination, ignored:\n",
      "#export\n",
      "def extract_level(spectrum_blocks: L, dtype=np.float32) -> pd.DataFrame:\n",
      "    \"\"\"Receives a mapping `spectrum_blocks` and returns the Matrix with the Levels as values, Frequencies as columns and Block Number as index.\n",
      "    :param pivoted: If False, optionally returns an unpivoted version of the Matrix\n",
      "    \"\"\"\n",
      "    assert len(spectrum_blocks), \"The spectrum block list is empty\"\n",
      "    #     spectrum_blocks = spectrum_blocks.itemgot(1)\n",
      "    block = spectrum_blocks[0]\n",
      "    assert block.type in (\n",
      "        63,\n",
      "        64,\n",
      "        67,\n",
      "        68,\n",
      "    ), \"The input blocks are not spectral blocks\"\n",
      "\n",
      "    rows = len(spectrum_blocks)\n",
      "    cols = min(len(block.data[block.start : block.stop]), block.ndata)\n",
      "    min_level = 0 if dtype == np.uint8 else block.offset - 127.5\n",
      "    if block.type in (63, 67):\n",
      "        #         frequencies = getattr(block, \"frequencies\")\n",
      "        return _extract_uncompressed(spectrum_blocks, rows, cols, min_level, dtype)\n",
      "    thresh = block.thresh - 1\n",
      "    block_data = [b.raw_data for b in spectrum_blocks]\n",
      "    #         frequencies = np.linspace(block.start_mega, block.stop_mega, num=cols)\n",
      "    levels = cy_extract_compressed(block_data, rows, cols, thresh, min_level)\n",
      "    if dtype != np.float32:\n",
      "        levels = levels.astype(dtype)\n",
      "    return levels\n",
      "No export destination, ignored:\n",
      "#exporti\n",
      "def _export_level(\n",
      "    parsed_blocks: tuple,\n",
      "    stem: Union[str, Path],\n",
      "    saida: Union[str, Path],\n",
      "    ext: str = \".fth\",\n",
      "    dtype: Union[str, np.dtype] = np.float16,\n",
      ") -> None:\n",
      "\n",
      "    ((tipo, tid), blocos), index = parsed_blocks\n",
      "    assert (\n",
      "        tipo in SPECTRAL_BLOCKS\n",
      "    ), \"Tentativa de extrair espectro de um bloco que não é espectral\"\n",
      "\n",
      "    saida = Path(saida)\n",
      "    level = extract_level(blocos, dtype)\n",
      "    if index is not None:\n",
      "        level.index = index\n",
      "\n",
      "    name = f\"{stem}-B_{tipo}_TId_{tid}\"\n",
      "    if ext == \".fth\":\n",
      "        if index is not None:\n",
      "            level = level.reset_index()\n",
      "        level.columns = [str(c) for c in level.columns]\n",
      "        level.to_feather(f\"{saida}/{name}{ext}\")\n",
      "    else:\n",
      "        raise ValueError(f\"Extension {ext} not implemented\")\n",
      "No export destination, ignored:\n",
      "#export\n",
      "def export_level(\n",
      "    stem: Union[str, Path],\n",
      "    blocks: dict,\n",
      "    saida: Union[str, Path],\n",
      "    ext: str = \".fth\",\n",
      "    index: pd.DatetimeIndex = None,\n",
      "    dtype: Union[str, np.dtype] = np.float16,\n",
      ") -> None:\n",
      "\n",
      "    blocks = [((t, i), b) for (t, i), b in blocks.items() if t in SPECTRAL_BLOCKS]\n",
      "    if not index:\n",
      "        index = [None] * len(blocks)\n",
      "    items = list(zip(blocks, index))\n",
      "    func = partialler(_export_level, stem=stem, saida=saida, ext=ext, dtype=dtype)\n",
      "    func.__module__ = _export_level.__module__\n",
      "    parallel(func, items, n_workers=os.cpu_count())\n",
      "Warning: Exporting to \"None.py\" but this module is not part of this build\n",
      "Warning: Exporting to \"None.py\" but this module is not part of this build\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'start'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11104/2093650178.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#hide\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnbdev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnotebook2script\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mnotebook2script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\rfpy\\lib\\site-packages\\nbdev\\export.py\u001b[0m in \u001b[0;36mnotebook2script\u001b[1;34m(fname, silent, to_dict, bare, recursive)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mto_dict\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[0mmodules\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_mod_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbare\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbare\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_notebook2script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbare\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbare\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mto_dict\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0madd_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lib_path\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\rfpy\\lib\\site-packages\\nbdev\\export.py\u001b[0m in \u001b[0;36m_notebook2script\u001b[1;34m(fname, modules, silent, to_dict, bare)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_from_future_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mto_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_add2all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34mf\"'{f}'\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'.'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m         \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr' +$'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMULTILINE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\rfpy\\lib\\site-packages\\nbdev\\export.py\u001b[0m in \u001b[0;36m_add2all\u001b[1;34m(fname, names, line_width)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[0mtw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_indent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubsequent_indent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbreak_long_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0mre_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_re__all__def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m     \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mre_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m     \u001b[0mtext_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{text[start:end-1]}{'' if text[end-2]=='[' else ', '}{', '.join(names)}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_all\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'start'"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rfpy]",
   "language": "python",
   "name": "conda-env-rfpy-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
