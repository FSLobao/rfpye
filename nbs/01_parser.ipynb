{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser\n",
    "> Este módulo processa o arquivo bin e extrai os metadados e dados do espectro dos blocos, além de criar estatísticas das medições.\n",
    "  en: This module process the bin file extracting its metadata and spectrum levels besides extracting useful statistics.\n",
    "  fr: Ce module traite le fichier bin et extrait les métadonnées et les données spectrales des blocs, en plus de créer des statistiques de mesure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext line_profiler\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exporti\n",
    "import os\n",
    "import gc\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "from collections import defaultdict\n",
    "from dataclasses import asdict, make_dataclass\n",
    "from fastcore.utils import parallel\n",
    "from fastcore.foundation import L, GetAttr\n",
    "from rfpye.constants import *\n",
    "from rfpye.blocks import MAIN_BLOCKS, BaseBlock\n",
    "from rfpye.utils import get_files, getattrs, bin2int, bin2str, cached\n",
    "from rfpye.cyparser import cy_extract_compressed\n",
    "from loguru import logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rich import print\n",
    "\n",
    "# For scripts\n",
    "config = {\n",
    "    \"handlers\": [\n",
    "        {\n",
    "            \"sink\": \"parser.log\",\n",
    "            \"serialize\": True,\n",
    "            \"rotation\": \"1 month\",\n",
    "            \"compression\": \"zip\",\n",
    "            \"backtrace\": True,\n",
    "            \"diagnose\": True,\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "logger.configure(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"binfiles\\v4\\rfeye002159_SLMA_bimestral_PEAK_210313_120302.bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento do Arquivo `.bin` e criação dos diferentes tipos de blocos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def evaluate_checksum(file, next_block, data_size) -> int:\n",
    "    \"\"\"Receives a byte_block and verify if the calculated checksum is equal to the one registed in the specific byte\"\"\"\n",
    "    checksum = np.frombuffer(file.read(4), np.uint32).item()\n",
    "    block_size = file.tell() - next_block\n",
    "    file.seek(-block_size, 1) # Go back to the beginning of the block\n",
    "    calculated_checksum = (\n",
    "            np.frombuffer(file.read(12+data_size), dtype=np.uint8)\n",
    "            .sum()\n",
    "            .astype(np.uint32)\n",
    "            .item()\n",
    "        )\n",
    "    file.seek(4,1) # skip checksum\n",
    "    return checksum if calculated_checksum == checksum else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def buffer2base_block(file, next_block: int) -> Union[BaseBlock, None]:\n",
    "    \"\"\"Receives an opened file buffer from the bin file and returns a dataclass with the attributes\n",
    "    'thread_id', 'size', 'type', 'data', 'checksum' or None in case any error is identified.\n",
    "    \"\"\"\n",
    "    thread_id = np.frombuffer(file.read(4), np.uint32).item()\n",
    "    block_size = np.frombuffer(file.read(4), np.uint32).item()\n",
    "    block_type = np.frombuffer(file.read(4), np.int32).item()\n",
    "    data_block = file.read(block_size)\n",
    "    if (checksum := evaluate_checksum(file, next_block, block_size)) is None:\n",
    "        return None, None           \n",
    "    return block_type, BaseBlock(thread_id, block_size, block_type, data_block, checksum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função a seguir recebe os bytes lidos do arquivo `.bin` e mapeia esses bytes em diferentes classes de acordo com o tipo de bloco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_block(file, next_block) -> Tuple:\n",
    "    \"\"\"Receives a byte_block, and converts it into one of the main classes\n",
    "    Args: byte_block: A byte block directly returned from the file\n",
    "    Returns: The Instance of the Block Type or None in case of error\n",
    "    \"\"\"\n",
    "    block_type, base_block = buffer2base_block(file, next_block)\n",
    "    if block_type is None:\n",
    "        return None, None\n",
    "    constructor = MAIN_BLOCKS.get(block_type)\n",
    "    if not constructor:\n",
    "        _ = logger.log(\n",
    "            \"INFO\", f\"This block type constructor is not implemented: {block_type}\"\n",
    "        )\n",
    "        return None, None\n",
    "    block = constructor(base_block)\n",
    "    if getattr(block, \"gerror\", -1) != -1 or getattr(block, \"gps_status\", -1) == 0:\n",
    "        _ = logger.log(\"INFO\", f\"Block with error: {block_type}\")\n",
    "        return None, None  # spectral or gps blocks with error\n",
    "    return block_type, block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função a seguir recebe os bytes lidos do arquivo `.bin` e mapeia esses bytes em diferentes classes de acordo com o tipo de bloco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_bin(bin_file: Union[str, Path], precision=np.float32) -> dict:\n",
    "    \"\"\"Receives a CRFS binfile and returns a dictionary with the file metadata, a GPS Class and a list with the different Spectrum Classes\n",
    "    A block is a piece of the .bin file with a known start and end and that contains different types of information.\n",
    "    It has several fields: file_type, header, data and footer.\n",
    "    Each field has lengths and information defined in the documentation.\n",
    "    Args:\n",
    "        bin_file (Union[str, Path]): path to the bin file\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with the file metadata, file_version, string info, gps and spectrum blocks.\n",
    "    \"\"\"\n",
    "    bin_file = Path(bin_file)\n",
    "    meta = {}\n",
    "    fluxos = {}\n",
    "    gps = CrfsGPS()\n",
    "    with open(bin_file, mode=\"rb\") as file:\n",
    "        # The first block of the file is the header and is 36 bytes long.\n",
    "        header = file.read(BYTES_HEADER)\n",
    "        meta[\"filename\"] = bin_file.name\n",
    "        meta[\"file_version\"] = bin2int(header[:4])\n",
    "        meta[\"string\"] = bin2str(header[4:])\n",
    "        file_size = file.seek(0, 2)\n",
    "        file.seek(36, 0)\n",
    "        while (next_block := file.tell()) < file_size:\n",
    "            block_type, block = create_block(file, next_block)\n",
    "            if file.read(4) != b'UUUU':\n",
    "                logger.warning(\"End of block not found, skipping it\")\n",
    "                continue\n",
    "            if block is None: \n",
    "                continue\n",
    "            if block_type == 40:\n",
    "                gps._data.append(block)\n",
    "            elif block_type in VECTOR_BLOCKS:\n",
    "                append_spec_data(block_type,fluxos, block, precision)\n",
    "            else:\n",
    "                meta.update(getattrs(block, KEY_ATTRS.get(block_type)))\n",
    "    meta[\"gps\"] = gps\n",
    "    meta[\"spectrum\"] = L(fluxos.values())\n",
    "    return meta                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "@dataclass\n",
    "class CrfsGPS:\n",
    "    \"\"\"Class with the GPS Attributes from the CRFS Bin File\"\"\"\n",
    "\n",
    "    _data: L = L()\n",
    "\n",
    "    @cached\n",
    "    def _gps_datetime(self):\n",
    "        return self._data.attrgot(\"gps_datetime\")\n",
    "\n",
    "    @cached\n",
    "    def _latitude(self):\n",
    "        return self._data.attrgot(\"latitude\")\n",
    "\n",
    "    @cached\n",
    "    def _longitude(self):\n",
    "        return self._data.attrgot(\"longitude\")\n",
    "\n",
    "    @cached\n",
    "    def _altitude(self):\n",
    "        return self._data.attrgot(\"altitude\")\n",
    "\n",
    "    @cached\n",
    "    def _num_satellites(self):\n",
    "        return self._data.attrgot(\"num_satellites\")\n",
    "\n",
    "    @property\n",
    "    def latitude(self) -> float:\n",
    "        return np.median(self._latitude) if self._latitude else -1\n",
    "\n",
    "    @property\n",
    "    def longitude(self) -> float:\n",
    "        return np.median(self._longitude) if self._longitude else -1\n",
    "\n",
    "    @property\n",
    "    def altitude(self) -> float:\n",
    "        return np.median(self._altitude) if self._altitude else -1\n",
    "\n",
    "    @property\n",
    "    def num_satellites(self) -> float:\n",
    "        return np.median(self._num_satellites) if self._num_satellites else 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"GPS Data - Median of Coordinates: {self.latitude:.5f}:{self.longitude:.5f} Altitude: {self.altitude:.2f} #Satellites: {self.num_satellites:.1f}\"\n",
    "\n",
    "\n",
    "class CrfsSpectrum(GetAttr):\n",
    "    \"\"\"Class with the metadata and levels of a spectrum block from a CRFS Bin File\"\"\"\n",
    "\n",
    "    def __init__(self, metadata, precision=np.float32):\n",
    "        self.default = metadata\n",
    "        # self._timestamp: L = L()\n",
    "        self._data: L = L()\n",
    "        self.precision = precision\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(self.default)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"\"\"Blocks of Type: {self.type}, Thread_id: {self.thread_id}, Start: {self.start_mega} MHz, Stop: {self.stop_mega} MHz\"\"\"\n",
    "\n",
    "    @cached\n",
    "    def _timestamp(self):\n",
    "        return self._data.attrgot('wallclock_datetime')\n",
    "\n",
    "    @cached\n",
    "    def start_dateidx(self):\n",
    "        return self._timestamp[0].item()\n",
    "\n",
    "    @cached\n",
    "    def stop_dateidx(self):\n",
    "        return self._timestamp[-1].item()\n",
    "\n",
    "    @cached\n",
    "    def levels(self):\n",
    "        \"\"\"Return the spectrum levels\"\"\"\n",
    "        if self.type in UNCOMPRESSED:\n",
    "            levels = np.concatenate(self._data.attrgot('levels')).reshape((-1, self.ndata))\n",
    "        elif self.type in COMPRESSED:\n",
    "            levels = cy_extract_compressed(\n",
    "                list(self._data.attrgot('levels')),\n",
    "                len(self._data),\n",
    "                int(self.ndata),\n",
    "                int(self.thresh),\n",
    "                float(self.minimum),\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"The current block is not of type spectrum or it's not implemented yet\"\n",
    "            )\n",
    "        if self.precision != np.float32:\n",
    "            levels = levels.astype(self.precision)\n",
    "        return levels\n",
    "\n",
    "    @cached\n",
    "    def frequencies(self) -> np.ndarray:\n",
    "        return np.linspace(self.start_mega, self.stop_mega, num=self.ndata)\n",
    "\n",
    "    def matrix(self):\n",
    "        \"\"\"Returns the matrix formed from the spectrum levels and timestamp\"\"\"\n",
    "        index = self._timestamp if len(self._timestamp) == len(self) else None\n",
    "        data = pd.DataFrame(self.levels, index=index, columns=self.frequencies)\n",
    "        data.columns.name = \"Frequencies\"\n",
    "        data.index.name = \"Time\"\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def check_block_exists(keys, vals, fluxos, precision):\n",
    "    \"\"\"Receives a dict of attributes and check if its values exist as keys in fluxos, otherwise create one and set to CrfsSpectrum Class\"\"\"\n",
    "    if vals not in fluxos:\n",
    "        metadata = make_dataclass('SpecData', fields=[(k,type(k)) for k in keys])\n",
    "        fluxos[vals] = CrfsSpectrum(metadata(*vals), precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def append_spec_data(block_type, fluxos, block, precision=np.float32) -> None:\n",
    "    \"\"\"Append the spectrum data to the fluxos dict\"\"\"\n",
    "    keys, vals = getattrs(block, KEY_ATTRS.get(block_type), as_tuple=True)\n",
    "    if vals not in fluxos:\n",
    "        metadata = make_dataclass('SpecData', fields=[(k,type(k)) for k in keys])\n",
    "        fluxos[vals] = CrfsSpectrum(metadata(*vals), precision)\n",
    "    fluxos[vals]._data.append(block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 14.6849 s\n",
      "File: C:\\Users\\rsilva\\AppData\\Local\\Temp/ipykernel_25332/586484204.py\n",
      "Function: parse_bin at line 2\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     2                                           def parse_bin(bin_file: Union[str, Path], precision=np.float32) -> dict:\n",
      "     3                                               \"\"\"Receives a CRFS binfile and returns a dictionary with the file metadata, a GPS Class and a list with the different Spectrum Classes\n",
      "     4                                               A block is a piece of the .bin file with a known start and end and that contains different types of information.\n",
      "     5                                               It has several fields: file_type, header, data and footer.\n",
      "     6                                               Each field has lengths and information defined in the documentation.\n",
      "     7                                               Args:\n",
      "     8                                                   bin_file (Union[str, Path]): path to the bin file\n",
      "     9                                           \n",
      "    10                                               Returns:\n",
      "    11                                                   Dictionary with the file metadata, file_version, string info, gps and spectrum blocks.\n",
      "    12                                               \"\"\"\n",
      "    13         1        459.0    459.0      0.0      bin_file = Path(bin_file)\n",
      "    14         1         12.0     12.0      0.0      meta = {}\n",
      "    15         1          7.0      7.0      0.0      fluxos = {}\n",
      "    16         1         61.0     61.0      0.0      gps = CrfsGPS()\n",
      "    17         1       6656.0   6656.0      0.0      with open(bin_file, mode=\"rb\") as file:\n",
      "    18                                                   # The first block of the file is the header and is 36 bytes long.\n",
      "    19         1        444.0    444.0      0.0          header = file.read(BYTES_HEADER)\n",
      "    20         1         65.0     65.0      0.0          meta[\"filename\"] = bin_file.name\n",
      "    21         1         68.0     68.0      0.0          meta[\"file_version\"] = bin2int(header[:4])\n",
      "    22         1         49.0     49.0      0.0          meta[\"string\"] = bin2str(header[4:])\n",
      "    23         1         90.0     90.0      0.0          file_size = file.seek(0, 2)\n",
      "    24         1         33.0     33.0      0.0          file.seek(36, 0)\n",
      "    25     43025    1832786.0     42.6      1.2          while (next_block := file.tell()) < file_size:\n",
      "    26     43024   70265201.0   1633.2     47.8              block_type, block = create_block(file, next_block)\n",
      "    27     43024     598742.0     13.9      0.4              if file.read(4) != b'UUUU':\n",
      "    28                                                           logger.warning(\"End of block not found, skipping it\")\n",
      "    29                                                           continue\n",
      "    30     43024     269157.0      6.3      0.2              if block is None: \n",
      "    31                                                           continue\n",
      "    32     43024     252191.0      5.9      0.2              if block_type == 40:\n",
      "    33      9057     450498.0     49.7      0.3                  gps._data.append(block)\n",
      "    34     33967     281404.0      8.3      0.2              elif block_type in VECTOR_BLOCKS:\n",
      "    35     33814   72849910.0   2154.4     49.6                  append_spec_data(block_type,fluxos, block, precision)\n",
      "    36                                                       else:\n",
      "    37       153      41232.0    269.5      0.0                  meta.update(getattrs(block, KEY_ATTRS.get(block_type)))\n",
      "    38         1         11.0     11.0      0.0      meta[\"gps\"] = gps\n",
      "    39         1        296.0    296.0      0.0      meta[\"spectrum\"] = L(fluxos.values())\n",
      "    40         1          5.0      5.0      0.0      return meta"
     ]
    }
   ],
   "source": [
    "file = get_files('binfiles/v5')[0]\n",
    "%lprun -f parse_bin parse_bin(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rfpye]",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
