{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser\n",
    "> Este módulo processa o arquivo bin e extrai os metadados e dados do espectro dos blocos, além de criar estatísticas das medições.\n",
    "  en: This module process the bin file extracting its metadata and spectrum levels besides extracting useful statistics.\n",
    "  fr: Ce module traite le fichier bin et extrait les métadonnées et les données spectrales des blocs, en plus de créer des statistiques de mesure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "The cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext cython\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "import os\n",
    "import gc\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "from collections import defaultdict, namedtuple\n",
    "from fastcore.basics import partialler, listify\n",
    "from fastcore.utils import parallel\n",
    "from fastcore.foundation import L, GetAttr\n",
    "from rfpye.constants import *\n",
    "from rfpye.blocks import MAIN_BLOCKS, BaseBlock\n",
    "from rfpye.utils import get_files, getattrs, bin2int, bin2str, cached\n",
    "from rfpye.cyparser import cy_extract_compressed\n",
    "from loguru import logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exporti\n",
    "# For scripts\n",
    "config = {\n",
    "    \"handlers\": [\n",
    "        {\n",
    "            \"sink\": \"parser.log\",\n",
    "            \"serialize\": True,\n",
    "            \"rotation\": \"1 month\",\n",
    "            \"compression\": \"zip\",\n",
    "            \"backtrace\": True,\n",
    "            \"diagnose\": True,\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "logger.configure(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento do Arquivo `.bin` e criação dos diferentes tipos de blocos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def evaluate_checksum(byte_block: bytes) -> int:\n",
    "    \"\"\"Receives a byte_block and verify if the calculated checksum is equal to the one registed in the specific byte\"\"\"\n",
    "    try:\n",
    "        checksum = np.frombuffer(byte_block[-4:], dtype=np.uint32).item()\n",
    "        calculated_checksum = (\n",
    "            np.frombuffer(byte_block[:-4], dtype=np.uint8)\n",
    "            .sum()\n",
    "            .astype(np.uint32)\n",
    "            .item()\n",
    "        )\n",
    "    except ValueError:\n",
    "        return -1\n",
    "    return checksum if calculated_checksum == checksum else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def byte2base_block(byte_block: bytes) -> Union[BaseBlock, None]:\n",
    "    \"\"\"Receives a byte block from the bin file and returns a dataclass with the attributes\n",
    "    'thread_id', 'size', 'type', 'data', 'checksum' or None in case any error is identified.\n",
    "    \"\"\"\n",
    "    if byte_block == b\"\":\n",
    "        return None\n",
    "    checksum = evaluate_checksum(byte_block)\n",
    "    size = bin2int(byte_block[4:8])\n",
    "    data = byte_block[12:-4]\n",
    "    # Discard the block if a fail in checksum or in case of a truncated block\n",
    "    if checksum == -1 or size != len(data):\n",
    "        return None\n",
    "    return BaseBlock(\n",
    "        bin2int(byte_block[:4]), size, bin2int(byte_block[8:12]), data, checksum\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função a seguir recebe os bytes lidos do arquivo `.bin` e mapeia esses bytes em diferentes classes de acordo com o tipo de bloco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_block(byte_block: bytes) -> Union[GetAttr, None]:\n",
    "    \"\"\"Receives a byte_block, and converts it into one of the main classes\n",
    "    Args: byte_block: A byte block directly returned from the file\n",
    "    Returns: The Instance of the Block Type or None in case of error\n",
    "    \"\"\"\n",
    "    base_block = byte2base_block(byte_block)\n",
    "    if not base_block:\n",
    "        return None, None\n",
    "    block_type = base_block.type\n",
    "    constructor = MAIN_BLOCKS.get(block_type)\n",
    "    if not constructor:\n",
    "        _ = logger.log(\n",
    "            \"INFO\", f\"This block type constructor is not implemented: {block_type}\"\n",
    "        )\n",
    "        return None, None\n",
    "    block = constructor(base_block)\n",
    "    if getattr(block, \"gerror\", -1) != -1 or getattr(block, \"gps_status\", -1) == 0:\n",
    "        _ = logger.log(\"INFO\", f\"Block with error: {block_type}\")\n",
    "        return None, None  # spectral or gps blocks with error\n",
    "    return getattrs(block, KEY_ATTRS.get(block.type)), block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função a seguir recebe os bytes lidos do arquivo `.bin` e mapeia esses bytes em diferentes classes de acordo com o tipo de bloco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_bin(bin_file: Union[str, Path]) -> dict:\n",
    "    \"\"\"Receives a CRFS binfile and returns a dictionary with the file metadata, a GPS Class and a list with the different Spectrum Classes\n",
    "    A block is a piece of the .bin file with a known start and end and that contains different types of information.\n",
    "    It has several fields: file_type, header, data and footer.\n",
    "    Each field has lengths and information defined in the documentation.\n",
    "    Args:\n",
    "        bin_file (Union[str, Path]): path to the bin file\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with the file metadata, file_version, string info, gps and spectrum blocks.\n",
    "    \"\"\"\n",
    "    bin_file = Path(bin_file)\n",
    "    with open(bin_file, mode=\"rb\") as bfile:\n",
    "        # The first block of the file is the header and is 36 bytes long.\n",
    "        header = bfile.read(BYTES_HEADER)\n",
    "        body = bfile.read()\n",
    "    blocks = parallel(create_block, body.split(ENDMARKER), threadpool=True)\n",
    "    meta = classify_blocks(blocks)\n",
    "    parsed = {\n",
    "        \"filename\": bin_file.name,\n",
    "        \"file_version\": bin2int(header[:4]),\n",
    "        \"string\": bin2str(header[4:]),\n",
    "    }\n",
    "    parsed.update(meta)\n",
    "    return parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "@dataclass\n",
    "class CrfsGPS:\n",
    "    \"\"\"Class with the GPS Attributes from the CRFS Bin File\"\"\"\n",
    "\n",
    "    _gps_datetime: L = L()\n",
    "    _latitude: L = L()\n",
    "    _longitude: L = L()\n",
    "    _altitude: L = L()\n",
    "    _num_satellites: L = L()\n",
    "\n",
    "    @property\n",
    "    def latitude(self) -> float:\n",
    "        return np.median(self._latitude) if self._latitude else -1\n",
    "\n",
    "    @property\n",
    "    def longitude(self) -> float:\n",
    "        return np.median(self._longitude) if self._longitude else -1\n",
    "\n",
    "    @property\n",
    "    def altitude(self) -> float:\n",
    "        return np.median(self._altitude) if self._altitude else -1\n",
    "\n",
    "    @property\n",
    "    def num_satellites(self) -> float:\n",
    "        return np.median(self._num_satellites) if self._num_satellites else 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"GPS Data - Median of Coordinates: {self.latitude:.5f}:{self.longitude:.5f} Altitude: {self.altitude:.2f} #Satellites: {self.num_satellites:.1f}\"\n",
    "\n",
    "\n",
    "class CrfsSpectrum(GetAttr):\n",
    "    \"\"\"Class with the metadata and levels of a spectrum block from a CRFS Bin File\"\"\"\n",
    "\n",
    "    def __init__(self, metadata: namedtuple):\n",
    "        self.default = metadata\n",
    "        self._timestamp: L = L()\n",
    "        self._data: L = L()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.levels.shape[0]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(self.default)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"\"\"Blocks of Type: {self.type}, Thread_id: {self.thread_id}, Start: {self.start_mega} MHz, Stop: {self.stop_mega} MHz\"\"\"\n",
    "\n",
    "    @cached\n",
    "    def levels(self):\n",
    "        \"\"\"Return the spectrum levels\"\"\"\n",
    "        if self.type in UNCOMPRESSED:\n",
    "            levels = np.concatenate(self._data).reshape(\n",
    "                (-1, self.ndata)\n",
    "            )\n",
    "        elif self.type in COMPRESSED:\n",
    "            levels = cy_extract_compressed(\n",
    "                self._data, len(self._data), self.ndata, self.thresh, self.minimum\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"The current block is not of type spectrum or it's not implemented yet\"\n",
    "            )\n",
    "        self._data = None\n",
    "        gc.collect()\n",
    "        return levels\n",
    "    \n",
    "    @cached\n",
    "    def frequencies(self)->np.ndarray:\n",
    "        return np.linspace(self.start_mega, self.stop_mega, num=self.ndata)\n",
    "\n",
    "    def matrix(self):\n",
    "        \"\"\"Returns the matrix formed from the spectrum levels and timestamp\"\"\"\n",
    "        index = self._timestamp if len(self._timestamp) == len(self) else None\n",
    "        data = pd.DataFrame(self.levels, index=index, columns=self.frequencies)\n",
    "        data.columns.name = \"Frequencies\"\n",
    "        data.index.name = \"Time\"\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def check_block_exists(attrs, fluxos):\n",
    "    \"\"\"Receives a dict of attributes and check if its values exist as keys in fluxos, otherwise create one and set to CrfsSpectrum Class\"\"\"\n",
    "    values = tuple(attrs.values())\n",
    "    if values not in fluxos:\n",
    "        # attributes = list(attrs.keys())\n",
    "        # metavalues = list(values)\n",
    "        # if hasattr(block, 'thresh'):\n",
    "        #     if 'thresh' not in attributes:\n",
    "        #         attributes.append('thresh')\n",
    "        #     metavalues.append(block.thresh)\n",
    "        # if hasattr(block, 'minimum'):\n",
    "        #     if 'minimum' not in attributes:\n",
    "        #         attributes.append('minimum')\n",
    "        #     metavalues.append(block.minimum)\n",
    "        metadata = namedtuple(\"SpecData\", attrs.keys())\n",
    "        fluxos[values] = CrfsSpectrum(metadata(*attrs.values()))\n",
    "    return values, fluxos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def append_spec_data(attrs, fluxos, block)->None:\n",
    "    values, fluxos = check_block_exists(attrs, fluxos)\n",
    "    time = getattr(block, \"wallclock_datetime\", None)\n",
    "    data = getattr(block, 'levels', None)\n",
    "    if time is not None:\n",
    "        fluxos[values]._timestamp.append(time)\n",
    "    if data is not None:\n",
    "        fluxos[values]._data.append(data)\n",
    "\n",
    "def classify_blocks(byte_blocks: Iterable) -> dict:\n",
    "    \"\"\"Receives an iterable with binary blocks and returns a dict with the metadata from file, the gps class and a list with the different spectrum classes\"\"\"\n",
    "    meta = {}\n",
    "    fluxos = {}\n",
    "    gps = CrfsGPS()\n",
    "    for attrs, block in byte_blocks:\n",
    "        if not block:\n",
    "            continue\n",
    "        dtype = block.type\n",
    "        if dtype == 40:\n",
    "            for k in BLOCK_ATTRS.get(40, []):\n",
    "                getattr(gps, f\"_{k}\").append(getattr(block, k))\n",
    "            continue\n",
    "        if dtype in VECTOR_BLOCKS:\n",
    "            append_spec_data(attrs, fluxos, block)\n",
    "        else:\n",
    "            meta.update(attrs)\n",
    "    meta[\"gps\"] = gps\n",
    "    meta[\"spectrum\"] = L(fluxos.values())\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
