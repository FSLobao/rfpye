{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2            #Reload the code automatically\r\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \r\n",
    "import sys, os\r\n",
    "from pathlib import Path\r\n",
    "\r\n",
    "# Insert in Path Project Directory\r\n",
    "sys.path.insert(0, str(Path().cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'console' from 'rfpye.constants' (g:\\Meu Drive\\repos\\Code\\rfpye\\rfpye\\constants.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5912/1450666485.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfastcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfoundation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlistify\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrfpye\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mrfpye\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconsole\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'console' from 'rfpye.constants' (g:\\Meu Drive\\repos\\Code\\rfpye\\rfpye\\constants.py)"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from typing import Iterable\r\n",
    "import pandas as pd\r\n",
    "from fastcore.foundation import L, listify\r\n",
    "from rfpye.utils import get_files\r\n",
    "from rfpye.constants import console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo Estatístico\n",
    "A seguinte função recebe um DataFrame cujas linhas são as diferentes varreduras do espectro, cada uma com seu timestamp, e colunas as diferentes frequências centrais medidas. Essa função é chamada pela função `extract_bin_stats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\r\n",
    "@logger.catch\r\n",
    "def filter_spectrum(\r\n",
    "    df: pd.DataFrame,\r\n",
    "    time_start: str = None,\r\n",
    "    time_stop: str = None,\r\n",
    "    freq_start: str = None,\r\n",
    "    freq_stop: str = None,\r\n",
    ") -> pd.DataFrame:\r\n",
    "    \"\"\"Recebe o arquivo de espectro df e retorna de acordo com os filtros\r\n",
    "\r\n",
    "    Args:\r\n",
    "        df (pd.DataFrame): Arquivo de espectro. Timestamp como linhas e frequências como colunas\r\n",
    "        time_start (str): Timestamp de início. Se None filtra desde o início do arquivo\r\n",
    "        time_stop (str): Timestamp de fim. Se None filtra até o fim do arquivo\r\n",
    "        freq_start (str): Filtro inicial de frequência. Se None retorna desde a menor frequências\r\n",
    "        freq_stop (str): Filtro Final de frequência. Se None retorna até a maior frequência.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        pd.DataFrame: DataFrame com Frequência, min, max e mean após os filtros aplicados.\r\n",
    "    \"\"\"\r\n",
    "    df = df.copy()\r\n",
    "    if time_start is None:\r\n",
    "        time_start = \"01/01/2000\"\r\n",
    "    if time_stop is None:\r\n",
    "        time_stop = \"31/12/2100\"\r\n",
    "    try:\r\n",
    "        time_start = pd.to_datetime(time_start)\r\n",
    "        time_stop = pd.to_datetime(time_stop)\r\n",
    "    except pd.errors.ParserError:\r\n",
    "        log.error(\r\n",
    "            f\"[bold red blink] Datas inválidas! Verifique as strings de data {freq_start} e {freq_stop}\"\r\n",
    "        )\r\n",
    "\r\n",
    "    try:\r\n",
    "        df.set_index(\"index\", inplace=True)\r\n",
    "        df.index = pd.to_datetime(df.index)\r\n",
    "    except pd.errors.KeyError:\r\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\r\n",
    "            log.warning(\r\n",
    "                f\"Não foi passado uma coluna ou índice com datetime a ser filtrado, todas as linhas serão processadas\",\r\n",
    "                exc_info=True,\r\n",
    "            )\r\n",
    "            time_start = 0\r\n",
    "            time_stop = df.shape[0]\r\n",
    "\r\n",
    "    cols = df.columns.values.astype(\"float\")\r\n",
    "    rows = df.index.values\r\n",
    "\r\n",
    "    if freq_start is None:\r\n",
    "        freq_start = 0\r\n",
    "    if freq_stop is None:\r\n",
    "        freq_stop = np.inf\r\n",
    "\r\n",
    "    filtered_cols = df.columns[(float(freq_start) <= cols) & (cols <= float(freq_stop))]\r\n",
    "    filtered_rows = df.index[(time_start <= rows) & (rows <= time_stop)]\r\n",
    "    if len(filtered_cols) == 0 or len(filtered_rows) == 0:\r\n",
    "        return None\r\n",
    "    count = filtered_rows.shape[0]\r\n",
    "    array = df.loc[filtered_rows, filtered_cols].values\r\n",
    "    freq = filtered_cols.values.astype(\"float32\")\r\n",
    "    min_ = array.min(axis=0)\r\n",
    "    max_ = array.max(axis=0)\r\n",
    "    mean = array.mean(axis=0)\r\n",
    "    return pd.DataFrame(\r\n",
    "        {\"Frequency\": freq, \"Min\": min_, \"Max\": max_, \"Mean\": mean, \"Count\": count}\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração, Estatísticas e Salvamento dos Arquivos de\r\n",
    "> Nesse módulo temos algumas funções que extraem estatísticas dados determinados filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\r\n",
    "def read_meta(filename):\r\n",
    "    ext = filename.suffix\r\n",
    "    if ext == \".csv\":\r\n",
    "        df = pd.read_csv(filename)\r\n",
    "    elif ext == \".xlsx\":\r\n",
    "        df = pd.read_excel(filename, engine=\"openpyxl\")\r\n",
    "    elif ext == \".fth\":\r\n",
    "        df = pd.read_feather(filename)\r\n",
    "        if \"wallclock_datetime\" in df.columns:\r\n",
    "            df.set_index(\"wallclock_datetime\", inplace=True)\r\n",
    "    else:\r\n",
    "        raise ValueError(f\"Extension {ext} not implemented\")\r\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento e Extração \n",
    "A função a seguir é um wrapper de toda funcionalidade desta biblioteca. Ela recebe o caminho `entrada` para um arquivo `.bin` ou pasta contendo vários arquivos `.bin`, extrai os metadados e os dados de espectro. Mescla o timestamp dos metadados com o arquivo de espectro e salva ambos na pasta `saida`. Essa pasta é usada como repositório e cache dos dados processados que serão utilizados pela função `extract_bin_stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\r\n",
    "def process_bin(\r\n",
    "    entrada: str,\r\n",
    "    saida: str,\r\n",
    "    recursivo: bool = False,\r\n",
    "    pastas: Iterable[str] = None,\r\n",
    "    levels: bool = False,\r\n",
    "    substituir: bool = False,\r\n",
    "    dtype: str = \"float16\",\r\n",
    ") -> None:\r\n",
    "    \"\"\"Recebe uma pasta ou arquivo bin, processa e salva os metadados e espectro na saida.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        entrada (str): Caminho para a Pasta ou Arquivo .bin\r\n",
    "        saida (str): Pasta onde salvar os arquivos processados\r\n",
    "        recursivo (bool, optional): Buscar os arquivos de entrada recursivamente. Defaults to False.\r\n",
    "        pastas (Iterable[str], optional): Limitar a busca a essas pastas. Defaults to None.\r\n",
    "        levels (bool, optional): Extrair e salvar os dados de espectro. Defaults to False.\r\n",
    "        substituir (bool, optional): Reprocessar arquivos já processados?. Defaults to False.\r\n",
    "        dtype (str, optional): Tipo de dados a salvar o espectro. Defaults to \"float16\".\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    entrada = Path(entrada)\r\n",
    "    if entrada.is_file():\r\n",
    "        lista_bins = [entrada]\r\n",
    "    else:\r\n",
    "        lista_bins = get_files(\r\n",
    "            entrada, extensions=[\".bin\"], recurse=recursivo, folders=pastas\r\n",
    "        )\r\n",
    "    parsed_bins = {}\r\n",
    "    meta_path = Path(f\"{saida}/meta\")\r\n",
    "    levels_path = Path(f\"{saida}/levels\")\r\n",
    "    meta_path.mkdir(exist_ok=True, parents=True)\r\n",
    "    levels_path.mkdir(exist_ok=True, parents=True)\r\n",
    "    log_meta = Path(f\"{saida}/log_meta.txt\")\r\n",
    "    log_levels = Path(f\"{saida}/log_levels.txt\")\r\n",
    "    if substituir:\r\n",
    "        done_meta = set()\r\n",
    "        done_levels = set()\r\n",
    "    else:\r\n",
    "\r\n",
    "        done_meta = (\r\n",
    "            set(log_meta.read_text().split(\"\\n\")) if log_meta.exists() else set()\r\n",
    "        )\r\n",
    "        done_levels = (\r\n",
    "            set(log_levels.read_text().split(\"\\n\")) if log_levels.exists() else set()\r\n",
    "        )\r\n",
    "\r\n",
    "    console.rule(\"Lista de Arquivos a serem processados\", style=\"bold red\")\r\n",
    "    console.print(\r\n",
    "        [f.name for f in lista_bins],\r\n",
    "        style=\"bold white\",\r\n",
    "        overflow=\"fold\",\r\n",
    "        justify=\"left\",\r\n",
    "    )\r\n",
    "    if not lista_bins:\r\n",
    "        console.print(\":sleeping: Nenhum arquivo .bin a processar :zzz:\")\r\n",
    "        return\r\n",
    "\r\n",
    "    if not levels:\r\n",
    "        lista_bins = [f for f in lista_bins if f.name not in done_meta]\r\n",
    "    else:\r\n",
    "        lista_bins = [f for f in lista_bins if f.name not in done_levels]\r\n",
    "\r\n",
    "    if not lista_bins:\r\n",
    "        console.print(\":sleeping: Nenhum arquivo novo a processar :zzz:\")\r\n",
    "        console.print(\r\n",
    "            \":point_up: use --substituir no terminal ou substituir=True na chamada caso queira reprocessar os bins e sobrepôr os arquivos existentes :wink:\"\r\n",
    "        )\r\n",
    "        return\r\n",
    "\r\n",
    "    try:\r\n",
    "\r\n",
    "        with Progress(transient=True, auto_refresh=False) as progress:\r\n",
    "            bins = progress.track(\r\n",
    "                lista_bins,\r\n",
    "                total=len(lista_bins),\r\n",
    "                description=\"[green]Processando Blocos Binários\",\r\n",
    "            )\r\n",
    "\r\n",
    "            for file in bins:\r\n",
    "                progress.console.print(f\"[cyan]Processando Blocos de: [red]{file.name}\")\r\n",
    "                parsed_bins[file.name] = parse_bin(file)\r\n",
    "                progress.refresh()\r\n",
    "\r\n",
    "            lista_meta = [(k, v) for k, v in parsed_bins.items() if k not in done_meta]\r\n",
    "\r\n",
    "            if lista_meta:\r\n",
    "                blocks = progress.track(\r\n",
    "                    lista_meta,\r\n",
    "                    total=len(lista_meta),\r\n",
    "                    description=\"[cyan]Exportando Metadados\",\r\n",
    "                )\r\n",
    "                for filename, block_dict in blocks:\r\n",
    "                    progress.console.print(f\"[cyan]Extraindo Metadados de: [red]{file}\")\r\n",
    "                    export_metadata(filename, block_dict, meta_path, ext=\".fth\")\r\n",
    "                    done_meta.add(file)\r\n",
    "                    progress.refresh()\r\n",
    "            if levels:\r\n",
    "                lista_levels = lista_meta = [\r\n",
    "                    (k, v) for k, v in parsed_bins.items() if k not in done_levels\r\n",
    "                ]\r\n",
    "                if lista_levels:\r\n",
    "                    bins = progress.track(\r\n",
    "                        lista_levels,\r\n",
    "                        total=len(lista_levels),\r\n",
    "                        description=\"[grey]Exportando Dados de Espectro\",\r\n",
    "                    )\r\n",
    "                    for file, block_obj in bins:\r\n",
    "                        progress.console.print(\r\n",
    "                            f\"[grey]Extraindo Espectro de: [red]{file}\"\r\n",
    "                        )\r\n",
    "                        meta_index = []\r\n",
    "                        blocks = block_obj[\"blocks\"]\r\n",
    "                        for (tipo, tid) in blocks.keys():\r\n",
    "                            if tipo not in SPECTRAL_BLOCKS:\r\n",
    "                                continue\r\n",
    "                            meta_file = Path(\r\n",
    "                                f\"{meta_path}/{file}-B_{tipo}_TId_{tid}.fth\"\r\n",
    "                            )\r\n",
    "                            if not meta_file.exists():\r\n",
    "                                export_meta(\r\n",
    "                                    file,\r\n",
    "                                    block_obj,\r\n",
    "                                    meta_path,\r\n",
    "                                    ext=\".fth\",\r\n",
    "                                )\r\n",
    "                                done_meta.add(file)\r\n",
    "                            meta_df = read_meta(meta_file)\r\n",
    "                            meta_index.append(meta_df.index.tolist())\r\n",
    "                        export_level(\r\n",
    "                            file,\r\n",
    "                            block_obj,\r\n",
    "                            levels_path,\r\n",
    "                            ext=\".fth\",\r\n",
    "                            index=meta_index,\r\n",
    "                            dtype=dtype,\r\n",
    "                        )\r\n",
    "                        done_levels.add(file)\r\n",
    "                        progress.refresh()\r\n",
    "        console.print(\"kbô :satisfied:\")\r\n",
    "    finally:\r\n",
    "        log_meta.write_text(\"\\n\".join(sorted(list(done_meta))))\r\n",
    "        log_levels.write_text(\"\\n\".join(sorted(list(done_levels))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função a seguir é a que será mais comumente chamada por outro módulo que utilizar esta lib. Ela recebe o caminho para um arquivo `.bin` e retorna um DataFrame com Frequência, Máximo, Mínimo e Média dos dados de Espectro presentes no arquivo `.bin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\r\n",
    "def extract_bin_stats(\r\n",
    "    filename: str,\r\n",
    "    time_start: str = None,\r\n",
    "    time_stop: str = None,\r\n",
    "    freq_start: str = None,\r\n",
    "    freq_stop: str = None,\r\n",
    "    cache: str = CACHE_FOLDER,\r\n",
    ") -> pd.DataFrame:\r\n",
    "    \"\"\"Recebe o caminho para um arquivo CRFS bin e retorna um dataframe com o resumo estatístico dos dados de espectro\r\n",
    "\r\n",
    "    Args:\r\n",
    "        filename (str): Caminho para o arquivo bin\r\n",
    "        time_start (str): Timestamp de início. Se None filtra desde o início do arquivo\r\n",
    "        time_stop (str): Timestamp de fim. Se None filtra até o fim do arquivo\r\n",
    "        freq_start (str): Filtro inicial de frequência. Se None retorna desde a menor frequências\r\n",
    "        freq_stop (str): Filtro Final de frequência. Se None retorna até a maior frequência.\r\n",
    "        cache (str, optional): Caminho para a pasta de cache. Default é criar uma pasta oculta .cache no diretório atual.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        pd.DataFrame: Dataframe contendo o resumo estatístico do arquivo\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    cache = Path(cache)\r\n",
    "    cache.mkdir(exist_ok=True, parents=True)\r\n",
    "    filename = Path(filename)\r\n",
    "    if filename.is_dir():\r\n",
    "        filenames = get_files(filename, extensions=[\".bin\"])\r\n",
    "    else:\r\n",
    "        filenames = listify(filename)\r\n",
    "\r\n",
    "    cached_files = get_files(cache / \"levels\")\r\n",
    "    files = L()\r\n",
    "    for filename in filenames:\r\n",
    "        while True:\r\n",
    "            # TODO filter based on metadata\r\n",
    "            subset = cached_files.filter(lambda name: filename.stem in str(name))\r\n",
    "            if not len(subset):\r\n",
    "                process_bin(entrada=filename, saida=cache, levels=True)\r\n",
    "            else:\r\n",
    "                break\r\n",
    "        files += subset\r\n",
    "        subset = L()\r\n",
    "\r\n",
    "    dfs = files.map(pd.read_feather)\r\n",
    "    tids = files.map(lambda x: x.stem.split(\"_\")[-1])\r\n",
    "    spectra = dfs.map(\r\n",
    "        filter_spectrum,\r\n",
    "        time_start=time_start,\r\n",
    "        time_stop=time_stop,\r\n",
    "        freq_start=freq_start,\r\n",
    "        freq_stop=freq_stop,\r\n",
    "    )\r\n",
    "    spectra = [(i, s) for i, s in zip(tids, spectra) if s is not None]\r\n",
    "    columns = [\"Tid\", \"Frequency\", \"Min\", \"Max\", \"Mean\"]\r\n",
    "    out = pd.DataFrame(columns=columns)\r\n",
    "    if not spectra:\r\n",
    "        log.warning(\r\n",
    "            f\"Os parâmetros repassados não correspondem a nenhum dado espectral do arquivo\",\r\n",
    "            exc_info=True,\r\n",
    "        )\r\n",
    "        return out\r\n",
    "    for i, df in spectra:\r\n",
    "        df[\"Tid\"] = i\r\n",
    "    spectra = [s for i, s in spectra]\r\n",
    "    spectra = pd.concat(spectra)\r\n",
    "    if len(spectra.Frequency) == len(spectra.Frequency.unique()):\r\n",
    "        return spectra[columns]\r\n",
    "    gb = spectra.groupby([\"Tid\", \"Frequency\"])\r\n",
    "    out = gb.apply(appended_mean)\r\n",
    "    Min = gb.min()[\"Min\"]\r\n",
    "    Max = gb.max()[\"Max\"]\r\n",
    "    Mean = gb.apply(appended_mean)\r\n",
    "    out = pd.concat([Min, Max, Mean], axis=1).reset_index()\r\n",
    "    out.columns = columns\r\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamada da função somente fornecendo o caminho do arquivo `.bin`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pela saída do código acima, vemos que o arquivo `.bin` foi processado, seus metadados e espectro extraídos e salvos. Como não passamos uma pasta de saída uma pasta local `.cache` é criada e os arquivos são salvos nela. Posteriormente o arquivo de espectro no cache é lido e o resumo estatístico das frequências no tempo é retornado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se chamarmos novamente a função com os mesmos argumentos, dessa vez a execução será mais rápida por conta do cache e assim o arquivo `.bin` não precisa ser processado novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_bin_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16540/663480257.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_bin_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinfile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m;\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_bin_stats' is not defined"
     ]
    }
   ],
   "source": [
    "dados = extract_bin_stats(binfile) ; dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\r\n",
    "def appended_mean(df: pd.Series) -> float:\r\n",
    "    \"\"\"Recebe um agrupamento do DataFrame e retorna sua média ponderada pela coluna Count\r\n",
    "\r\n",
    "    Args:\r\n",
    "        df (pd.DataFrame): Groupby do DataFrame\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        float: Média Ponderada da linha pela coluna Count\r\n",
    "    \"\"\"\r\n",
    "    return (df[\"Count\"] * df[\"Mean\"]).sum() / df[\"Count\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que o arquivo possui frequências de 70MHz a 110MHz. Se tivermos interessados em faixas menos, podemos filtrá-las. Por exemplo, vamos filtrar pela faixa de FM somente `88 a 108`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_bin_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16540/3046342232.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_bin_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m88\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq_stop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m108\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m;\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_bin_stats' is not defined"
     ]
    }
   ],
   "source": [
    "dados = extract_bin_stats(binfile, freq_start=88, freq_stop=108) ; dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para filtrarmos os dados estatísticos relativo a um tempo específico, precisamos saber de antemão qual o período específico o arquivo `.bin` compreende, se passarmos um período de tempo inválido, é retornado um DataFrame vazio e uma mensagem de aviso é salva no log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_bin_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16540/1299479843.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_bin_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2021-05-21'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m;\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_bin_stats' is not defined"
     ]
    }
   ],
   "source": [
    "dados = extract_bin_stats(binfile, time_start='2021-05-21') ; dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_bin_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16540/1602464370.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_bin_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_stop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2020-05-12'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m;\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_bin_stats' is not defined"
     ]
    }
   ],
   "source": [
    "dados = extract_bin_stats(binfile, time_stop='2020-05-12') ; dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse arquivo específico compreende o período de `Timestamp('2020-12-01 15:34:21.578869') a Timestamp('2020-12-01 16:13:53.920250')`, um período de menos de uma hora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basta passarmos uma string de data válida, as horas, minutos e segundos são opcionais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_bin_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16540/1291844773.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_bin_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2020-12-01 16:00'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m;\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_bin_stats' is not defined"
     ]
    }
   ],
   "source": [
    "dados = extract_bin_stats(binfile, time_start='2020-12-01 16:00') ; dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_bin_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16540/3862235263.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_bin_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'01/12/2020 16:00'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m;\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_bin_stats' is not defined"
     ]
    }
   ],
   "source": [
    "dados = extract_bin_stats(binfile, time_start='01/12/2020 16:00') ; dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_bin_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16540/4139374052.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_bin_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_stop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2020-12-01 16:00'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m;\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_bin_stats' is not defined"
     ]
    }
   ],
   "source": [
    "dados = extract_bin_stats(binfile, time_stop='2020-12-01 16:00') ; dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se quisermos filtrar para constar somente a faixa de FM e somente os 15 minutos de 15:45 a 16:00 do dia 01/12/2020 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_bin_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16540/740508017.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m dados = extract_bin_stats(binfile, \n",
      "\u001b[0m\u001b[0;32m      2\u001b[0m                           \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'01/12/2020 15:45'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m      3\u001b[0m                           \u001b[0mtime_stop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2020-12-01 16:00'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m      4\u001b[0m                           \u001b[0mfreq_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m88\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m      5\u001b[0m                           freq_stop=108) \n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_bin_stats' is not defined"
     ]
    }
   ],
   "source": [
    "dados = extract_bin_stats(binfile, \r\n",
    "                          time_start='01/12/2020 15:45',\r\n",
    "                          time_stop='2020-12-01 16:00',\r\n",
    "                          freq_start=88,\r\n",
    "                          freq_stop=108) \r\n",
    "dados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
