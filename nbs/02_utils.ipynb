{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "from typing import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastcore.foundation import L\n",
    "from fastcore.xtras import Path\n",
    "from fastcore.basics import uniqueify\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "from rfpy.constants import EXCLUDE_ATTRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "custom_theme = Theme({\"info\": \"dim cyan\", \"warning\": \"magenta\", \"danger\": \"bold red\"})\n",
    "console = Console(theme=custom_theme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonte: # https://github.com/fastai/fastai/blob/master/fastai/data/transforms.py#L26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_files(p, fs, extensions=None):\n",
    "    p = Path(p)\n",
    "    res = [\n",
    "        p / f\n",
    "        for f in fs\n",
    "        if not f.startswith(\".\")\n",
    "        and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)\n",
    "    ]\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_files(path, extensions=None, recurse=True, folders=None, followlinks=True):\n",
    "    \"Get all the files in `path` with optional `extensions`, optionally with `recurse`, only in `folders`, if specified.\"\n",
    "    path = Path(path)\n",
    "    folders = L(folders)\n",
    "    if extensions is not None:\n",
    "        extensions = set(uniqueify(extensions))\n",
    "        extensions = {e.lower() for e in extensions}\n",
    "    if recurse:\n",
    "        res = []\n",
    "        for i, (p, d, f) in enumerate(\n",
    "            os.walk(path, followlinks=followlinks)\n",
    "        ):  # returns (dirpath, dirnames, filenames)\n",
    "            if len(folders) != 0 and i == 0:\n",
    "                d[:] = [o for o in d if o in folders]\n",
    "            else:\n",
    "                d[:] = [o for o in d if not o.startswith(\".\")]\n",
    "            if len(folders) != 0 and i == 0 and \".\" not in folders:\n",
    "                continue\n",
    "            res += _get_files(p, f, extensions)\n",
    "    else:\n",
    "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "        res = _get_files(path, f, extensions)\n",
    "    return L(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bin2int(binary_data: bytes, is_signed: bool = True) -> int:\n",
    "    \"\"\"Convert bytes number to int\n",
    "    :param binary_data: valor de int comprimido\n",
    "    :param is_signed: indica se é um valor negativo ou não\n",
    "    :return: decoded int\n",
    "    \"\"\"\n",
    "    return int.from_bytes(binary_data, byteorder=\"little\", signed=is_signed)\n",
    "\n",
    "\n",
    "def bin2str(binary_data: bytes) -> str:\n",
    "    \"\"\"\n",
    "    bytes > str\n",
    "    :param binary_data: valor de str comprimida\n",
    "    :return: str traduzida\n",
    "\n",
    "    Conversor binario para str.\n",
    "    Erros do 'decoder' são ignorados.\n",
    "    Ignora o final do dado binario ('\\x00') que é usado apenas para manter o tamanho dos campos.\n",
    "    \"\"\"\n",
    "    return binary_data.decode(errors=\"ignore\").rstrip(\"\\x00\")\n",
    "    # return binary_data.decode().rstrip('\\x00')\n",
    "\n",
    "\n",
    "def bin2date(binary_data: bytes) -> Tuple[int, int, int, int]:\n",
    "    \"\"\"\n",
    "    bytes > (int, int, int, int)\n",
    "    :param binary_data: valor de data comprimido\n",
    "    :return: dia, mês, ano, reserva\n",
    "\n",
    "    Date is expressed as dd/mm/yy/null, i.e. 4 bytes\n",
    "    \"\"\"\n",
    "    day = binary_data[:1]\n",
    "    month = binary_data[1:2]\n",
    "    year = binary_data[2:3]\n",
    "    reserve = binary_data[3:]\n",
    "    return bin2int(day), bin2int(month), bin2int(year), bin2int(reserve)\n",
    "\n",
    "\n",
    "def bin2time(binary_data: bytes) -> Tuple[int, int, int, int]:\n",
    "    \"\"\"\n",
    "    bytes > (int, int, int, int)\n",
    "    :param binary_data: valor de hora comprimido\n",
    "    :return: horas, minutos, segundos, décimos de segundo\n",
    "\n",
    "     Time is expressed as hh/mm/ss/cc (4 bytes), where cc is centiseconds;\n",
    "     and a 32-bit nanoseconds field, expressed as an unsigned 32-bit integer,\n",
    "     to support higher precision where required.\n",
    "     At most one of cc and nanoseconds can be nonzero.\n",
    "    \"\"\"\n",
    "    hours = binary_data[:1]\n",
    "    minutes = binary_data[1:2]\n",
    "    seconds = binary_data[2:3]\n",
    "    centiseconds = binary_data[3:]\n",
    "    return bin2int(hours), bin2int(minutes), bin2int(seconds), bin2int(centiseconds)\n",
    "\n",
    "\n",
    "def decode_spectrum(b: int, offset: int) -> float:\n",
    "    \"\"\"\n",
    "    int, int > float\n",
    "    :param b: valor comprimido\n",
    "    :param offset: offset do valor comprimido\n",
    "    :return: valor traduzido\n",
    "\n",
    "    return  spectral power level in dBm,\n",
    "        truncated if necessary to range [offset – 127.5, offset]\n",
    "\n",
    "    b = stored byte values, in range [0, 255]\n",
    "    offset = level offset in dBm,\n",
    "        stored as a signed byte, range [-128, 127].\n",
    "        A typical offset level is -20 dBm.\n",
    "    \"\"\"\n",
    "    return b / 2 + offset - 127.5\n",
    "\n",
    "\n",
    "def decode_spectrum_bytes(b: bytes, offset: bytes) -> float:\n",
    "    \"\"\"\n",
    "    byte, byte > float\n",
    "    :param b: valor comprimido\n",
    "    :param offset: offset do valor comprimido\n",
    "    :return: valor traduzido\n",
    "\n",
    "    return  spectral power level in dBm,\n",
    "        truncated if necessary to range [offset – 127.5, offset]\n",
    "\n",
    "    b = stored byte values, in range [0, 255]\n",
    "    offset = level offset in dBm,\n",
    "        stored as a signed byte, range [-128, 127].\n",
    "        A typical offset level is -20 dBm.\n",
    "    \"\"\"\n",
    "    b_int = bin2int(b)\n",
    "    offset_int = bin2int(offset, False)\n",
    "    return b_int / 2 + offset_int - 127.5\n",
    "\n",
    "\n",
    "def pad(text, block_size):\n",
    "\n",
    "    # Calculate the missing number of\n",
    "    # bytes, say N\n",
    "    pad_size = block_size - len(text) % block_size\n",
    "\n",
    "    # Pad with character of N\n",
    "    fit_text = text + chr(pad_size) * pad_size\n",
    "\n",
    "    return (fit_text,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below borrowed from https://medium.com/bigdatarepublic/advanced-pandas-optimize-speed-and-memory-a654b53be6c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def optimize_floats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    floats = df.select_dtypes(include=[\"float64\"]).columns.tolist()\n",
    "    df[floats] = df[floats].apply(pd.to_numeric, downcast=\"float\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def optimize_ints(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ints = df.select_dtypes(include=[\"int64\"]).columns.tolist()\n",
    "    df[ints] = df[ints].apply(pd.to_numeric, downcast=\"integer\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def optimize_objects(df: pd.DataFrame, datetime_features: List[str]) -> pd.DataFrame:\n",
    "    for col in df.select_dtypes(include=[\"object\"]):\n",
    "        if col not in datetime_features:\n",
    "            num_unique_values = len(df[col].unique())\n",
    "            num_total_values = len(df[col])\n",
    "            if float(num_unique_values) / num_total_values < 0.5:\n",
    "                df[col] = df[col].astype(\"category\")\n",
    "        else:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_optimize(df: pd.DataFrame, datetime_features: List[str] = []):\n",
    "    return optimize_floats(optimize_ints(optimize_objects(df, datetime_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def public_attrs(obj: Any) -> L:\n",
    "    \"\"\"Receives an object and return its public attributes (not starting with underscore _) excluding those listed in `EXCLUDE_ATTRS`\"\"\"\n",
    "    return L(k for k in dir(obj) if not k.startswith(\"_\") and k not in EXCLUDE_ATTRS)\n",
    "\n",
    "\n",
    "def getattrs(obj: Any, attrs: Iterable = None) -> L:\n",
    "    if attrs is None:\n",
    "        attrs = public_attrs(obj)\n",
    "    return {x: getattr(obj, x) for x in attrs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_main.ipynb.\n",
      "Converted 01_parser.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_blocks.ipynb.\n",
      "Converted 04_constants.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rfpy]",
   "language": "python",
   "name": "conda-env-rfpy-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
