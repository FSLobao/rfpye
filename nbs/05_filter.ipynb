{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a434cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0981d0",
   "metadata": {},
   "source": [
    "# Filter\n",
    "Utility functions to filter the spectrum data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2            #Reload the code automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891e7f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from datetime import datetime\n",
    "from typing import *\n",
    "import os\n",
    "import logging\n",
    "from fastcore.xtras import Path\n",
    "from fastcore.script import call_parse, Param, store_true\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rich.progress import Progress\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "from rich.logging import RichHandler\n",
    "from rfpy.utils import *\n",
    "from rfpy.constants import SPECTRAL_BLOCKS\n",
    "from rfpy.parser import *\n",
    "from rfpy.main import process_bin\n",
    "CACHE_FOLDER = Path(r\"C:\\Users\\rsilva\\Downloads\\saida\")\n",
    "if not CACHE_FOLDER.exists():\n",
    "    CACHE_FOLDER = Path.cwd() / 'cache'\n",
    "    CACHE_FOLDER.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0eedfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=\"NOTSET\",\n",
    "    format=\"%(message)s\",\n",
    "    datefmt=\"[%X]\",\n",
    "    handlers=[RichHandler(rich_tracebacks=True)]\n",
    ")\n",
    "\n",
    "log = logging.getLogger(\"rich\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c45912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def filter_spectrum(df, start, stop, freq_start, freq_stop):\n",
    "    df = df.copy()\n",
    "    try:\n",
    "        start = pd.to_datetime(start)\n",
    "        stop = pd.to_datetime(stop)\n",
    "    except pd.errors.ParserError:\n",
    "        log.error(f\"[bold red blink] Datas inválidas! Verifique as strings de data {start} e {stop}\")\n",
    "\n",
    "    try:\n",
    "        df.set_index('index', inplace=True)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "    except pd.errors.KeyError:\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            log.warning(\n",
    "                f\"Não foi passado uma coluna ou índice com datetime a ser filtrado, todas as linhas serão processadas\",\n",
    "                exc_info=True\n",
    "            )\n",
    "            start = 0\n",
    "            stop = df.shape[0]\n",
    "\n",
    "    cols = df.columns.values.astype('float')\n",
    "    rows = df.index.values\n",
    "\n",
    "    filtered_cols = df.columns[(float(freq_start) <= cols) & (cols <= float(freq_stop))]\n",
    "    filtered_rows = df.index[(start <= rows) & (rows <= stop)]\n",
    "    if len(filtered_cols) == 0 or len(filtered_rows) == 0:\n",
    "        return None\n",
    "    count = filtered_rows.shape[0]\n",
    "    array = df.loc[filtered_rows, filtered_cols].values\n",
    "    freq = filtered_cols.values.astype('float32')\n",
    "    min_ = array.min(axis=0)\n",
    "    max_ = array.max(axis=0)\n",
    "    mean = array.mean(axis=0)\n",
    "    return pd.DataFrame({'Frequency': freq, 'Min': min_, 'Max': max_, 'Mean': mean, 'Count': count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7644d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def appended_mean(row):\n",
    "    return (row['Count'] * row['Mean']).sum() / row['Count'].sum()\n",
    "\n",
    "@call_parse\n",
    "def extract_bin_stats(filename: Param(\"Caminho para o arquivo .bin\", str),\n",
    "                      start: Param(\"Timestamp do Início\", str),\n",
    "                      stop: Param(\"Timestamp do Fim\", str),\n",
    "                      freq_start: Param(\"Frequência Inicial (MHz)\", str),\n",
    "                      freq_stop: Param(\"Frequência Final (MHz)\", str)):\n",
    "\n",
    "    filename = Path(filename)\n",
    "    while True:\n",
    "        cached_files = get_files(CACHE_FOLDER / 'levels')\n",
    "        #TODO filter based on metadata\n",
    "        cached_levels = cached_files.filter(lambda name: filename.stem in str(name))\n",
    "        if not cached_levels:\n",
    "            process_bin(filename, CACHE_FOLDER, levels=True)\n",
    "        else:\n",
    "            break\n",
    "    dfs = cached_levels.map(pd.read_feather)\n",
    "    spectra = dfs.map(filter_spectrum, start=start, stop=stop, freq_start=freq_start, freq_stop=freq_stop)\n",
    "    spectra = [s for s in spectra if s is not None]\n",
    "    out = pd.DataFrame(columns=['Frequency', 'Min', 'Max', 'Mean'])\n",
    "    if not spectra:\n",
    "        log.warning(\n",
    "                f\"Os parâmetros repassados não correspondem a nenhum dado espectral do arquivo\",\n",
    "                exc_info=True\n",
    "            )\n",
    "        return out\n",
    "    spectra = pd.concat(spectra)\n",
    "    gb  = spectra.groupby('Frequency')\n",
    "    out['Frequency'] = spectra.Frequency.unique()\n",
    "    out['Min'] = gb.min()['Min'].values\n",
    "    out['Max'] = gb.max()['Max'].values\n",
    "    out['Mean'] = gb.apply(appended_mean).values\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0154c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_main.ipynb.\n",
      "Converted 01_parser.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_blocks.ipynb.\n",
      "Converted 04_constants.ipynb.\n",
      "Converted 05_filter.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rfpy]",
   "language": "python",
   "name": "conda-env-rfpy-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
