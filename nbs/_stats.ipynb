{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2            #Reload the code automatically\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide \n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'console' from 'rfpye.constants' (g:\\Meu Drive\\repos\\Code\\rfpye\\rfpye\\constants.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5912/1450666485.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfastcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfoundation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlistify\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrfpye\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mrfpye\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconsole\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'console' from 'rfpye.constants' (g:\\Meu Drive\\repos\\Code\\rfpye\\rfpye\\constants.py)"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from typing import Iterable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastcore.foundation import L, listify\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "from rich.progress import Progress\n",
    "from rfpye.utils import get_files\n",
    "from rfpye.parser import parse_bin\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_theme = Theme({\"info\": \"dim cyan\", \"warning\": \"magenta\", \"danger\": \"bold red\"})\n",
    "console = Console(theme=custom_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "# For scripts\n",
    "config = {\n",
    "    \"handlers\": [\n",
    "        {\"sink\": \"stats.log\", \"serialize\": True, 'rotation': \"1 month\", 'compression' :'zip', 'backtrace': True, 'diagnose': True},\n",
    "    ],\n",
    "}\n",
    "logger.configure(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo Estatístico\n",
    "A seguinte função recebe um DataFrame cujas linhas são as diferentes varreduras do espectro, cada uma com seu timestamp, e colunas as diferentes frequências centrais medidas. Essa função é chamada pela função `extract_bin_stats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@logger.catch\n",
    "def filter_spectrum(\n",
    "    df: pd.DataFrame,\n",
    "    time_start: str = None,\n",
    "    time_stop: str = None,\n",
    "    freq_start: str = None,\n",
    "    freq_stop: str = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Recebe o arquivo de espectro df e retorna de acordo com os filtros\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Arquivo de espectro. Timestamp como linhas e frequências como colunas\n",
    "        time_start (str): Timestamp de início. Se None filtra desde o início do arquivo\n",
    "        time_stop (str): Timestamp de fim. Se None filtra até o fim do arquivo\n",
    "        freq_start (str): Filtro inicial de frequência. Se None retorna desde a menor frequências\n",
    "        freq_stop (str): Filtro Final de frequência. Se None retorna até a maior frequência.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame com Frequência, min, max e mean após os filtros aplicados.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if time_start is None:\n",
    "        time_start = \"01/01/2000\"\n",
    "    if time_stop is None:\n",
    "        time_stop = \"31/12/2100\"\n",
    "    try:\n",
    "        time_start = pd.to_datetime(time_start)\n",
    "        time_stop = pd.to_datetime(time_stop)\n",
    "    except pd.errors.ParserError:\n",
    "        logger.error(\n",
    "            f\"[bold red blink] Datas inválidas! Verifique as strings de data {freq_start} e {freq_stop}\"\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        df.set_index(\"index\", inplace=True)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "    except pd.errors.KeyError:\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            logger.warning(\n",
    "                f\"Não foi passado uma coluna ou índice com datetime a ser filtrado, todas as linhas serão processadas\",\n",
    "                exc_info=True,\n",
    "            )\n",
    "            time_start = 0\n",
    "            time_stop = df.shape[0]\n",
    "\n",
    "    cols = df.columns.values.astype(\"float\")\n",
    "    rows = df.index.values\n",
    "\n",
    "    if freq_start is None:\n",
    "        freq_start = 0\n",
    "    if freq_stop is None:\n",
    "        freq_stop = np.inf\n",
    "\n",
    "    filtered_cols = df.columns[(float(freq_start) <= cols) & (cols <= float(freq_stop))]\n",
    "    filtered_rows = df.index[(time_start <= rows) & (rows <= time_stop)]\n",
    "    if len(filtered_cols) == 0 or len(filtered_rows) == 0:\n",
    "        return None\n",
    "    count = filtered_rows.shape[0]\n",
    "    array = df.loc[filtered_rows, filtered_cols].values\n",
    "    freq = filtered_cols.values.astype(\"float32\")\n",
    "    min_ = array.min(axis=0)\n",
    "    max_ = array.max(axis=0)\n",
    "    mean = array.mean(axis=0)\n",
    "    return pd.DataFrame(\n",
    "        {\"Frequency\": freq, \"Min\": min_, \"Max\": max_, \"Mean\": mean, \"Count\": count}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração, Estatísticas e Salvamento dos Arquivos de\n",
    "> Nesse módulo temos algumas funções que extraem estatísticas dados determinados filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def read_meta(filename):\n",
    "    ext = filename.suffix\n",
    "    if ext == \".csv\":\n",
    "        df = pd.read_csv(filename)\n",
    "    elif ext == \".xlsx\":\n",
    "        df = pd.read_excel(filename, engine=\"openpyxl\")\n",
    "    elif ext == \".fth\":\n",
    "        df = pd.read_feather(filename)\n",
    "        if \"wallclock_datetime\" in df.columns:\n",
    "            df.set_index(\"wallclock_datetime\", inplace=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Extension {ext} not implemented\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento e Extração \n",
    "A função a seguir é um wrapper de toda funcionalidade desta biblioteca. Ela recebe o caminho `entrada` para um arquivo `.bin` ou pasta contendo vários arquivos `.bin`, extrai os metadados e os dados de espectro. Mescla o timestamp dos metadados com o arquivo de espectro e salva ambos na pasta `saida`. Essa pasta é usada como repositório e cache dos dados processados que serão utilizados pela função `extract_bin_stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def process_bin(\n",
    "    entrada: str,\n",
    "    saida: str,\n",
    "    recursivo: bool = False,\n",
    "    pastas: Iterable[str] = None,\n",
    "    levels: bool = False,\n",
    "    substituir: bool = False,\n",
    "    dtype: str = \"float16\",\n",
    ") -> None:\n",
    "    \"\"\"Recebe uma pasta ou arquivo bin, processa e salva os metadados e espectro na saida.\n",
    "\n",
    "    Args:\n",
    "        entrada (str): Caminho para a Pasta ou Arquivo .bin\n",
    "        saida (str): Pasta onde salvar os arquivos processados\n",
    "        recursivo (bool, optional): Buscar os arquivos de entrada recursivamente. Defaults to False.\n",
    "        pastas (Iterable[str], optional): Limitar a busca a essas pastas. Defaults to None.\n",
    "        levels (bool, optional): Extrair e salvar os dados de espectro. Defaults to False.\n",
    "        substituir (bool, optional): Reprocessar arquivos já processados?. Defaults to False.\n",
    "        dtype (str, optional): Tipo de dados a salvar o espectro. Defaults to \"float16\".\n",
    "    \"\"\"\n",
    "\n",
    "    entrada = Path(entrada)\n",
    "    if entrada.is_file():\n",
    "        lista_bins = [entrada]\n",
    "    else:\n",
    "        lista_bins = get_files(\n",
    "            entrada, extensions=[\".bin\"], recurse=recursivo, folders=pastas\n",
    "        )\n",
    "    parsed_bins = {}\n",
    "    meta_path = Path(f\"{saida}/meta\")\n",
    "    levels_path = Path(f\"{saida}/levels\")\n",
    "    meta_path.mkdir(exist_ok=True, parents=True)\n",
    "    levels_path.mkdir(exist_ok=True, parents=True)\n",
    "    log_meta = Path(f\"{saida}/log_meta.txt\")\n",
    "    log_levels = Path(f\"{saida}/log_levels.txt\")\n",
    "    if substituir:\n",
    "        done_meta = set()\n",
    "        done_levels = set()\n",
    "    else:\n",
    "\n",
    "        done_meta = (\n",
    "            set(log_meta.read_text().split(\"\\n\")) if log_meta.exists() else set()\n",
    "        )\n",
    "        done_levels = (\n",
    "            set(log_levels.read_text().split(\"\\n\")) if log_levels.exists() else set()\n",
    "        )\n",
    "\n",
    "    console.rule(\"Lista de Arquivos a serem processados\", style=\"bold red\")\n",
    "    console.print(\n",
    "        [f.name for f in lista_bins],\n",
    "        style=\"bold white\",\n",
    "        overflow=\"fold\",\n",
    "        justify=\"left\",\n",
    "    )\n",
    "    if not lista_bins:\n",
    "        console.print(\":sleeping: Nenhum arquivo .bin a processar :zzz:\")\n",
    "        return\n",
    "\n",
    "    if not levels:\n",
    "        lista_bins = [f for f in lista_bins if f.name not in done_meta]\n",
    "    else:\n",
    "        lista_bins = [f for f in lista_bins if f.name not in done_levels]\n",
    "\n",
    "    if not lista_bins:\n",
    "        console.print(\":sleeping: Nenhum arquivo novo a processar :zzz:\")\n",
    "        console.print(\n",
    "            \":point_up: use --substituir no terminal ou substituir=True na chamada caso queira reprocessar os bins e sobrepôr os arquivos existentes :wink:\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    try:\n",
    "\n",
    "        with Progress(transient=True, auto_refresh=False) as progress:\n",
    "            bins = progress.track(\n",
    "                lista_bins,\n",
    "                total=len(lista_bins),\n",
    "                description=\"[green]Processando Blocos Binários\",\n",
    "            )\n",
    "\n",
    "            for file in bins:\n",
    "                progress.console.print(f\"[cyan]Processando Blocos de: [red]{file.name}\")\n",
    "                parsed_bins[file.name] = parse_bin(file)\n",
    "                progress.refresh()\n",
    "\n",
    "            lista_meta = [(k, v) for k, v in parsed_bins.items() if k not in done_meta]\n",
    "\n",
    "            if lista_meta:\n",
    "                blocks = progress.track(\n",
    "                    lista_meta,\n",
    "                    total=len(lista_meta),\n",
    "                    description=\"[cyan]Exportando Metadados\",\n",
    "                )\n",
    "                for filename, block_dict in blocks:\n",
    "                    progress.console.print(f\"[cyan]Extraindo Metadados de: [red]{file}\")\n",
    "                    export_metadata(filename, block_dict, meta_path, ext=\".fth\")\n",
    "                    done_meta.add(file)\n",
    "                    progress.refresh()\n",
    "            if levels:\n",
    "                lista_levels = lista_meta = [\n",
    "                    (k, v) for k, v in parsed_bins.items() if k not in done_levels\n",
    "                ]\n",
    "                if lista_levels:\n",
    "                    bins = progress.track(\n",
    "                        lista_levels,\n",
    "                        total=len(lista_levels),\n",
    "                        description=\"[grey]Exportando Dados de Espectro\",\n",
    "                    )\n",
    "                    for file, block_obj in bins:\n",
    "                        progress.console.print(\n",
    "                            f\"[grey]Extraindo Espectro de: [red]{file}\"\n",
    "                        )\n",
    "                        meta_index = []\n",
    "                        blocks = block_obj[\"blocks\"]\n",
    "                        for (tipo, tid) in blocks.keys():\n",
    "                            if tipo not in SPECTRAL_BLOCKS:\n",
    "                                continue\n",
    "                            meta_file = Path(\n",
    "                                f\"{meta_path}/{file}-B_{tipo}_TId_{tid}.fth\"\n",
    "                            )\n",
    "                            if not meta_file.exists():\n",
    "                                export_meta(\n",
    "                                    file,\n",
    "                                    block_obj,\n",
    "                                    meta_path,\n",
    "                                    ext=\".fth\",\n",
    "                                )\n",
    "                                done_meta.add(file)\n",
    "                            meta_df = read_meta(meta_file)\n",
    "                            meta_index.append(meta_df.index.tolist())\n",
    "                        export_level(\n",
    "                            file,\n",
    "                            block_obj,\n",
    "                            levels_path,\n",
    "                            ext=\".fth\",\n",
    "                            index=meta_index,\n",
    "                            dtype=dtype,\n",
    "                        )\n",
    "                        done_levels.add(file)\n",
    "                        progress.refresh()\n",
    "        console.print(\"kbô :satisfied:\")\n",
    "    finally:\n",
    "        log_meta.write_text(\"\\n\".join(sorted(list(done_meta))))\n",
    "        log_levels.write_text(\"\\n\".join(sorted(list(done_levels))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função a seguir é a que será mais comumente chamada por outro módulo que utilizar esta lib. Ela recebe o caminho para um arquivo `.bin` e retorna um DataFrame com Frequência, Máximo, Mínimo e Média dos dados de Espectro presentes no arquivo `.bin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_bin_stats(\n",
    "    filename: str,\n",
    "    time_start: str = None,\n",
    "    time_stop: str = None,\n",
    "    freq_start: str = None,\n",
    "    freq_stop: str = None,\n",
    "    cache: str = CACHE_FOLDER,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Recebe o caminho para um arquivo CRFS bin e retorna um dataframe com o resumo estatístico dos dados de espectro\n",
    "\n",
    "    Args:\n",
    "        filename (str): Caminho para o arquivo bin\n",
    "        time_start (str): Timestamp de início. Se None filtra desde o início do arquivo\n",
    "        time_stop (str): Timestamp de fim. Se None filtra até o fim do arquivo\n",
    "        freq_start (str): Filtro inicial de frequência. Se None retorna desde a menor frequências\n",
    "        freq_stop (str): Filtro Final de frequência. Se None retorna até a maior frequência.\n",
    "        cache (str, optional): Caminho para a pasta de cache. Default é criar uma pasta oculta .cache no diretório atual.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe contendo o resumo estatístico do arquivo\n",
    "    \"\"\"\n",
    "\n",
    "    cache = Path(cache)\n",
    "    cache.mkdir(exist_ok=True, parents=True)\n",
    "    filename = Path(filename)\n",
    "    if filename.is_dir():\n",
    "        filenames = get_files(filename, extensions=[\".bin\"])\n",
    "    else:\n",
    "        filenames = listify(filename)\n",
    "\n",
    "    cached_files = get_files(cache / \"levels\")\n",
    "    files = L()\n",
    "    for filename in filenames:\n",
    "        while True:\n",
    "            # TODO filter based on metadata\n",
    "            subset = cached_files.filter(lambda name: filename.stem in str(name))\n",
    "            if not len(subset):\n",
    "                process_bin(entrada=filename, saida=cache, levels=True)\n",
    "            else:\n",
    "                break\n",
    "        files += subset\n",
    "        subset = L()\n",
    "\n",
    "    dfs = files.map(pd.read_feather)\n",
    "    tids = files.map(lambda x: x.stem.split(\"_\")[-1])\n",
    "    spectra = dfs.map(\n",
    "        filter_spectrum,\n",
    "        time_start=time_start,\n",
    "        time_stop=time_stop,\n",
    "        freq_start=freq_start,\n",
    "        freq_stop=freq_stop,\n",
    "    )\n",
    "    spectra = [(i, s) for i, s in zip(tids, spectra) if s is not None]\n",
    "    columns = [\"Tid\", \"Frequency\", \"Min\", \"Max\", \"Mean\"]\n",
    "    out = pd.DataFrame(columns=columns)\n",
    "    if not spectra:\n",
    "        log.warning(\n",
    "            f\"Os parâmetros repassados não correspondem a nenhum dado espectral do arquivo\",\n",
    "            exc_info=True,\n",
    "        )\n",
    "        return out\n",
    "    for i, df in spectra:\n",
    "        df[\"Tid\"] = i\n",
    "    spectra = [s for i, s in spectra]\n",
    "    spectra = pd.concat(spectra)\n",
    "    if len(spectra.Frequency) == len(spectra.Frequency.unique()):\n",
    "        return spectra[columns]\n",
    "    gb = spectra.groupby([\"Tid\", \"Frequency\"])\n",
    "    out = gb.apply(appended_mean)\n",
    "    Min = gb.min()[\"Min\"]\n",
    "    Max = gb.max()[\"Max\"]\n",
    "    Mean = gb.apply(appended_mean)\n",
    "    out = pd.concat([Min, Max, Mean], axis=1).reset_index()\n",
    "    out.columns = columns\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chamada da função somente fornecendo o caminho do arquivo `.bin`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pela saída do código acima, vemos que o arquivo `.bin` foi processado, seus metadados e espectro extraídos e salvos. Como não passamos uma pasta de saída uma pasta local `.cache` é criada e os arquivos são salvos nela. Posteriormente o arquivo de espectro no cache é lido e o resumo estatístico das frequências no tempo é retornado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se chamarmos novamente a função com os mesmos argumentos, dessa vez a execução será mais rápida por conta do cache e assim o arquivo `.bin` não precisa ser processado novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_bin_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16540/663480257.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_bin_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinfile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m;\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_bin_stats' is not defined"
     ]
    }
   ],
   "source": [
    "dados = extract_bin_stats(binfile) ; dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def appended_mean(df: pd.Series) -> float:\n",
    "    \"\"\"Recebe um agrupamento do DataFrame e retorna sua média ponderada pela coluna Count\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Groupby do DataFrame\n",
    "\n",
    "    Returns:\n",
    "        float: Média Ponderada da linha pela coluna Count\n",
    "    \"\"\"\n",
    "    return (df[\"Count\"] * df[\"Mean\"]).sum() / df[\"Count\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que o arquivo possui frequências de 70MHz a 110MHz. Se tivermos interessados em faixas menos, podemos filtrá-las. Por exemplo, vamos filtrar pela faixa de FM somente `88 a 108`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_bin_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16540/3046342232.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_bin_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m88\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreq_stop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m108\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m;\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_bin_stats' is not defined"
     ]
    }
   ],
   "source": [
    "dados = extract_bin_stats(binfile, freq_start=88, freq_stop=108) ; dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para filtrarmos os dados estatísticos relativo a um tempo específico, precisamos saber de antemão qual o período específico o arquivo `.bin` compreende, se passarmos um período de tempo inválido, é retornado um DataFrame vazio e uma mensagem de aviso é salva no log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_bin_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16540/1299479843.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_bin_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2021-05-21'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m;\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_bin_stats' is not defined"
     ]
    }
   ],
   "source": [
    "dados = extract_bin_stats(binfile, time_start='2021-05-21') ; dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_bin_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16540/1602464370.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_bin_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_stop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2020-05-12'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m;\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_bin_stats' is not defined"
     ]
    }
   ],
   "source": [
    "dados = extract_bin_stats(binfile, time_stop='2020-05-12') ; dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse arquivo específico compreende o período de `Timestamp('2020-12-01 15:34:21.578869') a Timestamp('2020-12-01 16:13:53.920250')`, um período de menos de uma hora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basta passarmos uma string de data válida, as horas, minutos e segundos são opcionais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_bin_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16540/1291844773.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_bin_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2020-12-01 16:00'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m;\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_bin_stats' is not defined"
     ]
    }
   ],
   "source": [
    "dados = extract_bin_stats(binfile, time_start='2020-12-01 16:00') ; dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_bin_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16540/3862235263.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_bin_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'01/12/2020 16:00'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m;\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_bin_stats' is not defined"
     ]
    }
   ],
   "source": [
    "dados = extract_bin_stats(binfile, time_start='01/12/2020 16:00') ; dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_bin_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16540/4139374052.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_bin_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_stop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2020-12-01 16:00'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m;\u001b[0m \u001b[0mdados\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_bin_stats' is not defined"
     ]
    }
   ],
   "source": [
    "dados = extract_bin_stats(binfile, time_stop='2020-12-01 16:00') ; dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se quisermos filtrar para constar somente a faixa de FM e somente os 15 minutos de 15:45 a 16:00 do dia 01/12/2020 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_bin_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16540/740508017.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m dados = extract_bin_stats(binfile, \n",
      "\u001b[0m\u001b[0;32m      2\u001b[0m                           \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'01/12/2020 15:45'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m      3\u001b[0m                           \u001b[0mtime_stop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2020-12-01 16:00'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m      4\u001b[0m                           \u001b[0mfreq_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m88\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m      5\u001b[0m                           freq_stop=108) \n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_bin_stats' is not defined"
     ]
    }
   ],
   "source": [
    "dados = extract_bin_stats(binfile, \n",
    "                          time_start='01/12/2020 15:45',\n",
    "                          time_stop='2020-12-01 16:00',\n",
    "                          freq_start=88,\n",
    "                          freq_stop=108) \n",
    "dados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
