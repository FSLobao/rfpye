{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2297001",
   "metadata": {},
   "source": [
    "# Leitura de dados binários - um exemplo de otimização em Python\n",
    "> As atividades de monitoramento do espectro de radiofrequência na ANATEL, especificamente aquelas que utilizam estações remotas de monitoramento, geram centenas de GB de dados. Um dos primeiros desafios para a utilização mais eficiente desses dados é a sua leitura eficiente. Nesse artigo é detalhada as iterações realizadas para resolver esse problema, primeiramente tornar essa leitura viável e posteriormente os passos de otimização aplicados no algoritmo para decodificar os dados de arquivos comprimidos \n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [spectrum monitoring, profiling, numpy, cython]\n",
    "- image: images/multiplication.jpg\n",
    "- hide_binder_badge: true\n",
    "- author: Ronaldo S.A. Batista"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5557ce6b",
   "metadata": {},
   "source": [
    "![](images/knuth.jpeg \"Crédito: https://twitter.com/lpolovets/status/816117631572807680\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe88942",
   "metadata": {},
   "source": [
    "O objeto desse artigo são arquivos binários com extensão `.bin` - gerados pela aplicação `Logger` embarcada nas estações de monitoramento do tipo [Rfeye Node 20-6](http://agc.com.br/produto/rfeye-node/).\n",
    "\n",
    "Estes arquivos armazenam diversos metadados sobre a medição e blocos com informação numérica, que são as medidas em si, chamadas aqui de _dados de espectro_ ou _dados espectrais_. \n",
    "\n",
    "A versão recente da aplicação `Logger` gera dados comprimidos de maneira muito eficiente, o que torna a descompressão desafiadora para arquivos com muitos dados e bastante demorada caso seja feita de maneira \"ingênua\".\n",
    "\n",
    "Mesmo que essa o problema apresentado aqui pareça obscuro, as técnicas de otimização podem ser aplicadas em outros contextos que sejam relevantes para quem lê."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f35e9",
   "metadata": {},
   "source": [
    "> Note: Nos parágrafos a seguir irei passar por cima deliberadamente ( por não serem relevantes para a otimização e por pouco conhecimento no assunto ) de explicações sobre a parte de física / engenharia de telecomunicações e irei focar mais no problema específico de decodificação dos arquivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87792ba3",
   "metadata": {},
   "source": [
    "## Explorando o arquivo `.bin`\n",
    "\n",
    "Cada arquivo `.bin` possui dados distintos em um mesmo arquivo, em dois níveis `blocos` e `thread_id`.\n",
    "\n",
    "* Um `bloco` determina o tipo de dado: espectro, gps, dados textuais etc...\n",
    "* O `thread_id` nada mais é que um identificador da faixa específica de varredura armazenada naquele bloco.\n",
    "\n",
    "Com alguns exemplos fica muito mais fácil.\n",
    "\n",
    "A função a seguir encapsula a leitura do arquivo e seus metadados e retorna um dicionário cujas chaves são as diferentes combinações de `blocos` e `thread_id` e os valores são as listas com os blocos. \n",
    "\n",
    "Cada bloco é uma classe python contendo seus atributos.Os detalhes de implementação dessa função podem ser ignorados.\n",
    "\n",
    "> Tip: A biblioteca `rfpy` criada para o processamento desses arquivos faz amplo uso da biblioteca [fastcore](https://fastcore.fast.ai/). Esta expande as funcionalidades da linguagem python inspirada em atributos muito úteis de outras linguagens. Recomendo fortemente para quem deseja expandir o seu inventário de ferramentas python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b6607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%load_ext line_profiler\n",
    "%load_ext cython\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd14131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from tqdm.notebook import tqdm\n",
    "from fastcore.xtras import Path\n",
    "# Insert in Path Project Directory\n",
    "sys.path.insert(0, str(Path().cwd().parent))\n",
    "from multiprocessing import set_start_method, Pool\n",
    "try:\n",
    "    set_start_method(\"spawn\")\n",
    "except RuntimeError:\n",
    "    pass\n",
    "import gc\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "from rfpy.parser import parse_bin\n",
    "from rfpy.utils import public_attrs\n",
    "from fastcore.foundation import L\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint as pp\n",
    "from IPython.display import display\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16982ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de Bloco: 21, Thread_ID: 0, Nº de blocos 1, Exemplo de Blocos: [<rfpy.blocks.DType21 object at 0x000001FEE0073DC8>]\n",
      "Tipo de Bloco: 42, Thread_ID: 0, Nº de blocos 2, Exemplo de Blocos: [<rfpy.blocks.DType42 object at 0x000001FEDDB88348>, <rfpy.blocks.DType42 object at 0x000001FEDDB88648>]\n",
      "Tipo de Bloco: 42, Thread_ID: 301, Nº de blocos 1, Exemplo de Blocos: [<rfpy.blocks.DType42 object at 0x000001FEE0100448>]\n",
      "Tipo de Bloco: 42, Thread_ID: 311, Nº de blocos 1, Exemplo de Blocos: [<rfpy.blocks.DType42 object at 0x000001FEE0100848>]\n",
      "Tipo de Bloco: 42, Thread_ID: 321, Nº de blocos 1, Exemplo de Blocos: [<rfpy.blocks.DType42 object at 0x000001FEE0100A48>]\n",
      "Tipo de Bloco: 42, Thread_ID: 331, Nº de blocos 1, Exemplo de Blocos: [<rfpy.blocks.DType42 object at 0x000001FEE0100BC8>]\n",
      "Tipo de Bloco: 68, Thread_ID: 331, Nº de blocos 734, Exemplo de Blocos: [<rfpy.blocks.DType68 object at 0x000001FEE0100D08>, <rfpy.blocks.DType68 object at 0x000001FEDF14F388>]\n",
      "Tipo de Bloco: 42, Thread_ID: 341, Nº de blocos 1, Exemplo de Blocos: [<rfpy.blocks.DType42 object at 0x000001FEE0100808>]\n",
      "Tipo de Bloco: 42, Thread_ID: 351, Nº de blocos 1, Exemplo de Blocos: [<rfpy.blocks.DType42 object at 0x000001FEE01009C8>]\n",
      "Tipo de Bloco: 42, Thread_ID: 361, Nº de blocos 1, Exemplo de Blocos: [<rfpy.blocks.DType42 object at 0x000001FEE0100C48>]\n",
      "Tipo de Bloco: 42, Thread_ID: 371, Nº de blocos 1, Exemplo de Blocos: [<rfpy.blocks.DType42 object at 0x000001FEDDADAD88>]\n",
      "Tipo de Bloco: 42, Thread_ID: 381, Nº de blocos 1, Exemplo de Blocos: [<rfpy.blocks.DType42 object at 0x000001FEE00648C8>]\n",
      "Tipo de Bloco: 42, Thread_ID: 391, Nº de blocos 1, Exemplo de Blocos: [<rfpy.blocks.DType42 object at 0x000001FEE0064DC8>]\n",
      "Tipo de Bloco: 68, Thread_ID: 301, Nº de blocos 133932, Exemplo de Blocos: [<rfpy.blocks.DType68 object at 0x000001FEE0060C48>, <rfpy.blocks.DType68 object at 0x000001FEDFEA8B48>]\n",
      "Tipo de Bloco: 68, Thread_ID: 311, Nº de blocos 11464, Exemplo de Blocos: [<rfpy.blocks.DType68 object at 0x000001FEDDFBD948>, <rfpy.blocks.DType68 object at 0x000001FEF63972C8>]\n",
      "Tipo de Bloco: 40, Thread_ID: 1, Nº de blocos 18462, Exemplo de Blocos: [<rfpy.blocks.DType40 object at 0x000001FEDDFA9488>, <rfpy.blocks.DType40 object at 0x000001FEDF1E65C8>]\n",
      "Tipo de Bloco: 42, Thread_ID: 1, Nº de blocos 307, Exemplo de Blocos: [<rfpy.blocks.DType42 object at 0x000001FEF6432488>, <rfpy.blocks.DType42 object at 0x000001FEF64CA9C8>]\n",
      "Tipo de Bloco: 68, Thread_ID: 341, Nº de blocos 44, Exemplo de Blocos: [<rfpy.blocks.DType68 object at 0x000001FEF6B15CC8>, <rfpy.blocks.DType68 object at 0x000001FEF6E03948>]\n",
      "Tipo de Bloco: 68, Thread_ID: 321, Nº de blocos 46, Exemplo de Blocos: [<rfpy.blocks.DType68 object at 0x000001FEF8FDDF48>, <rfpy.blocks.DType68 object at 0x000001FEF9017948>]\n"
     ]
    }
   ],
   "source": [
    "blocks = parse_bin('binfiles/rfeye002092_210223_T163131_MaskBroken.bin')\n",
    "blocks = blocks['blocks']\n",
    "\n",
    "for k,v in blocks.items():\n",
    "    print(f'Tipo de Bloco: {k[0]}, Thread_ID: {k[1]}, Nº de blocos {len(v)}, Exemplo de Blocos: {v[:2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d33142c",
   "metadata": {},
   "source": [
    "Vemos que esse arquivo tem diferentes tipos de blocos, o que nos interessa aqui são os blocos de espectro, blocos do tipo 68. \n",
    "Temos diferentes blocos do tipo 68, vamos observar o que os diferencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872083eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "b301 = blocks[(68,301)][0] \n",
    "b321 = blocks[(68,321)][0]\n",
    "b331 = blocks[(68,331)][0]\n",
    "b341 = blocks[(68,341)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696b0e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 137)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b301.start_mega, b301.stop_mega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1cd697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 340)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b321.start_mega, b321.stop_mega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac07a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 410)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b331.start_mega, b331.stop_mega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c413d5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 1219)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b341.start_mega, b341.stop_mega"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74443318",
   "metadata": {},
   "source": [
    "Vemos portanto que o quê diferencia diferentes blocos do mesmo tipo mas com diferentes `thread_id` é a faixa de frequência de varredura. \n",
    "\n",
    "O primeiro tipo de bloco mostrado, o bloco do tipo `68` e thread_id `301`, é o mais numeroso do arquivo com 133932 blocos. \n",
    "\n",
    "A faixa desse arquivo é muito importante e de grande enfoque nas monitorações da Anatel - 108MHz a 137MHz. Essa faixa é a do Serviço Limitado Móvel Aeronáutico, dedicada a comunicações entre aeronaves com as torres de comando e entre si."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fcee6d",
   "metadata": {},
   "source": [
    "Cada bloco é uma medição num intervalo de tempo específico de diversos pontos nessa faixa de 108MHz a 137MHz. Portanto temos `133932` medições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734743ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xff\\xfaF\\xff\\xfaH\\xff\\xfaH\\xff\\xfaE\\xff\\xfaA\\xff\\xfaB\\xff\\xfaA\\xff\\xfa>\\xff\\xfa>\\xff\\xfa=\\xff\\xfa<\\xff\\xfa;\\xff\\xfa;\\xff\\xfa;\\xff\\xfa;\\xff\\xfa;\\xff\\xfa5\\xff\\xfa5\\xff\\xfa6\\xff\\xfa7\\xff\\xfa8\\xff\\xfa7\\xff\\xfa6\\xff\\xfa4\\xffv`d`\\xff\\xfa6\\xff\\x9bamm`\\xff\\xfa6\\xff\\xfa8\\xff\\xfa8\\xff\\xfa8\\xff\\xfa8\\xff\\xfa7\\xff\\xfa6\\xff\\xfa5\\xff\\x8ba\\xff\\xfa4\\xff\\xfa6\\xff\\xfa4\\xff\\xfa5\\xff\\xfa5\\xff\\x97g|\\x82{f\\xff\\xfa5\\xff\\xfa5\\xff\\xfa7\\xff\\xfa7\\xff\\xfa8\\xff\\xfa6\\xff\\xfa6\\xff\\xfa6\\xff\\xfa8\\xff\\xfa7\\xff\\xfa8\\xff\\xfa8\\xff\\xfa9\\xff\\xfa<\\xff\\xfa>\\xff\\xfa>\\xff\\xfaA\\xff\\xfaAB'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b301.data[b301.start:b301.stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af12e1",
   "metadata": {},
   "source": [
    "O Atributo `data` são os bytes brutos, i.e. não decodificados mas somente lidos. Os atributos `start` e `stop` recortam os bytes nos pontos correspondente às medidas de nível do arquivo binário, ignorando os demais pontos do arquivo que constituem metadados. O restante desse artigo é dedicado a decodificação dessas medidas de nível."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124d4985",
   "metadata": {},
   "source": [
    "## Codificação Espectral\n",
    "Dada estação faz uma medição de potência, para dada frequência, em dBm ( lê-se 'de-bê-eme' ), uma escala logarítmica com valores tipicamente negativos. A escala de valores que a estação armazena é a seguinte `Intervalo = [offset - 127.5, offset]`, onde `offset` (*deslocamento*) é um valor pré-estabelecido. Se a medida estiver fora desse intervalo, os valores são truncados. Um típico valor de `offset` é -*20dBm*\n",
    "\n",
    "Assim tendo o valor medido `d` em dBm ele é codificado, da seguinte maneira:\n",
    "\n",
    "$$b = 2(d - offset) + 255$$\n",
    "\n",
    "Ao inserir os valores extremos do intervalo acima nessa fórmula:\n",
    "\n",
    "Para `d = offset - 127.5`:\n",
    "\n",
    "$$ \\therefore b = 2[(offset - 127.5) - offset] + 255 = 2 (-127.5) + 255 \\implies b = 0$$\n",
    "\n",
    "Para `d = offset`:\n",
    "$$\\therefore b = 2(offset - offset) + 255 = 2 * 0 + 255 \\implies b = 255$$\n",
    "\n",
    "Portanto o intervalo de valores possíveis ao serem codificados com a fórmula acima é `[0,255]`, justamente o intervalo de valores possíveis em 8 bits ou 1 byte, sem sinal. Assim, os dados de espectro truncados e codificados dessa maneira permitem um armazenamento extremamente econômico, ocupando somente 1 byte (`uint8` em python ou `unsigned char` na linguagem C.)\n",
    "\n",
    "Para decodificar tal valor, basta fazer o procedimento inverso  da fórmula acima. Ao isolar o valor `d` temos:\n",
    "$$d = \\frac{b}{2} + offset - 127.5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3f2b51",
   "metadata": {},
   "source": [
    "## Compressão de Dados\n",
    "Como dados de espectro são extremamente ruidosos ( índice sinal-ruído muito baixo ), isto é, a maioria do que observamos numa dada \"janela\" do espectro é simplesmente ruído. A aplicação `Logger` comprime esses dados de maneira engenhosa. Como mencionado, a cada instante de tempo a estação faz a medição dos níveis de determinada faixa, para tal ela divide a faixa em diversos intervalos e mede o nível da frequência central daquele intervalo. Quanto maior o número de intervalos mais granulosa ou detalhada serão essas medidas.\n",
    "\n",
    "**Algoritmo de Compressão**\n",
    "\n",
    "* No script é definido um limiar `threshold`, abaixo do qual tudo é considerado ruído\n",
    "* Para cada intervalo medido `i`, é verificado se o valor está abaixo do limiar\n",
    "* Caso afirmativo esse processo se repete para os intervalos vizinhos `i+1, i+2, etc...`\n",
    "* Esses intervalos são contados, até que apareça um ponto acima do limiar ou o máximo de `250` pontos seja atingido\n",
    "  * Nesse ponto é gravado no arquivo um byte marcador `RUN=255` indicando que o próximo byte armazena a contagem de pontos abaixo do limiar\n",
    "  * Nesse procedimento é ocupado somente 2 bytes, podendo ter sido comprimido o limite de 250 bytes no melhor dos casos.\n",
    "\n",
    "Um problema que pode ocorrer no algoritmo acima é se nos dados de medição tivermos o valor máximo medido `d=offset` assim o valor a ser gravado será `b=255`, o mesmo valor usado como marcador. \n",
    "\n",
    "Nesses casos temos o valor literal no ponto e não queremos que isso seja interpretado como marcador. \n",
    "\n",
    "Para lidar com esse caso é definido um segundo marcador `ESC=254`, esse marcador informa o algoritmo de decodificação que a medida é literal e não se trata de um marcador.\n",
    "\n",
    "Com alguns exemplos a seguir ficará mais claro o funcionamento do algoritmo. O algoritmo original de codificação ( escrito em C ) é apresentado a seguir:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09307a16",
   "metadata": {},
   "source": [
    "```c\n",
    "int run_length_encode(unsigned char *dest, unsigned char *src, int nsrc, int thresh) { \n",
    "    unsigned char ib; \n",
    "    int di = 0, si, nunder = 0; \n",
    "    for(si = 0; si < nsrc; si++){ \n",
    "        ib = src[si]; \n",
    "        if ((ib < thresh) && (si < (nsrc-1)) && (nunder < 250)) { \n",
    "            nunder += 1; \n",
    "        } else { \n",
    "            if (nunder > 0) { \n",
    "                dest[di++] = RUN; \n",
    "                dest[di++] = nunder; \n",
    "                nunder = 0; \n",
    "            } if ((ib == RUN) || (ib == ESC)) {\n",
    "                dest[di++] = ESC; \n",
    "                dest[di++] = ib; \n",
    "            } else { \n",
    "                dest[di++] = ib; \n",
    "            } \n",
    "        } \n",
    "    } return di; \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c8d857",
   "metadata": {},
   "source": [
    "O algoritmo é bastante legível mesmo para quem não conhece C, exceto talvez por algumas coisas estranhas como ponteiros `*` e a incrementação de variáveis dentro dos arrays. \n",
    "Vamos escrevê-lo em python tentando manter o estilo em C e comentando para decifrarmos melhor seu propósito. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be610d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = 255\n",
    "ESC = 254\n",
    "def run_length_encode(destino, origem, n_origem, limiar):\n",
    "    \n",
    "    conta_origem, conta_destino = 0,0 # si, and di\n",
    "    \n",
    "    num_under = 0\n",
    "    for si in range(n_origem): # percorro as posições do arquivo de origem\n",
    "        \n",
    "        byte_atual = origem[si] # leio o byte do arquivo fonte correspondente à posição si\n",
    "        \n",
    "        # Se o byte está abaixo do limiar e não atingi o fim do arquivo ou a contagem máxima\n",
    "        if (byte_atual < limiar) and (si < n_origem - 1) and (num_under < 250):\n",
    "            \n",
    "            num_under += 1 # incremento o contador de valor abaixo do limiar\n",
    "        else:\n",
    "            if num_under > 0: # valor atual está acima do limiar mas até o momento estávamos contando valores abaixo do limiar\n",
    "                \n",
    "                destination[conta_destino] = RUN # insiro o marcador de contagem de valores abaixo do limiar na posição atual do arquivo de destino\n",
    "                \n",
    "                conta_destino += 1 # incremento o contador do arquivo de destino\n",
    "                \n",
    "                destination[conta_destino] = num_under # coloco a contagem em si na próxima posição\n",
    "                \n",
    "                conta_destino += 1 # incremento o contador do arquivo de destino\n",
    "                \n",
    "                num_under = 0 # zero o contador de valores abaixo do limiar\n",
    "                \n",
    "            if (byte_atual == RUN) or (byte_atual == ESC): # checo se o valor lido atual corresponde a um dos valores utilizados como marcador\n",
    "                \n",
    "                destination[conta_destino] = ESC # coloco o marcador que o valor a seguir lido é literal\n",
    "                \n",
    "                conta_destino += 1 # incremento o contador do arquivo de destino\n",
    "                \n",
    "                destination[conta_destino] = byte_atual\n",
    "                \n",
    "                conta_destino += 1 # incremento o contador do arquivo de destino\n",
    "                \n",
    "            else: # caso o valor medido não corresponda a um dos valores reservador de marcador eu simplesmente guardo esse valor na posição atual\n",
    "                \n",
    "                destination[conta_destino] = byte_atual\n",
    "                \n",
    "                conta_destino += 1 # incremento o contador do arquivo de destino\n",
    "                \n",
    "    return destination            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ce209d",
   "metadata": {},
   "source": [
    "O algoritmo está propositalmente \"não-pythônico\", mais ao estilo de C para ficar o mais próximo do original e espaçado por conta dos vários comentários.  \n",
    "\n",
    "Como sempre as coisas ficam mais claras com um exemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b99e4a6",
   "metadata": {},
   "source": [
    "**Exemplo 1 - Somente valores abaixo do limiar, i.e. somente ruído**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388bf8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination = [0] * 10 #lista com 10 valores 0\n",
    "offset = -20\n",
    "limiar = -80\n",
    "medidas = [-100] * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ed29ce",
   "metadata": {},
   "source": [
    "Como vimos acima esses valores de medida antes de serem codificados são transformados com seguinte fórmula: $b = 2(d - offset) + 255$. Portanto nosso arquivo de origem fica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922b052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[95, 95, 95, 95, 95, 95, 95, 95, 95, 95]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origem = [int(2 * (d - offset) + 255) for d in medidas] ; origem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd19b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "limiar = 2 * (limiar - offset) + 255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab144ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[255, 9, 95, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_length_encode(destination, origem, len(origem), limiar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c21d5a",
   "metadata": {},
   "source": [
    "Temos 10 valores, todos abaixo do limiar, então o algoritmo armazena o marcador `RUN=255` mais a contagem de valores a seguir. Era esperado que a contagem fosse 10 e não 9. No entanto pela implementação do algoritmo o último valor é armazenado literalmente, mesmo estando abaixo do limiar. Esse é um caso limite no qual todos os valores do espectro estão abaixo do limiar. Perceba que nesse caso limite 3 bytes foram ocupados dos 10 originais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810711b5",
   "metadata": {},
   "source": [
    "**Exemplo 2 - Ruído mais valores normais**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf1511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[95, 95, 95, 95, 95, 145, 171, 251, 235, 139]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination = [0] * 10 #lista com 10 valores 0\n",
    "offset = -20\n",
    "limiar = -80\n",
    "medidas = [-100, -100, -100, -100, -100, -75, -62, -22, -30, -78]\n",
    "origem = [int(2 * (d - offset) + 255) for d in medidas]\n",
    "limiar = 2 * (limiar - offset) + 255 \n",
    "origem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d64e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[255, 5, 145, 171, 251, 235, 139, 0, 0, 0]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_length_encode(destination, origem, len(origem), limiar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ffa649",
   "metadata": {},
   "source": [
    "Temos 5 valores abaixo do limiar então é armazenado o marcador `RUN=255` seguido da contagem `[255,5...] e em seguida são armazenados os valores literais que estão acima do limiar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efb43b0",
   "metadata": {},
   "source": [
    "**Exemplo 3 - Ruído, Valores Normais e valores extremos igual ao `offset`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465871fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[95, 95, 95, 95, 95, 255, 254, 251, 235, 139]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination = [0] * 10 #lista com 10 valores 0\n",
    "offset = -20\n",
    "limiar = -80\n",
    "medidas = [-100, -100, -100, -100, -100, -20, -20.5, -22, -30, -78]\n",
    "origem = [int(2 * (d - offset) + 255) for d in medidas]\n",
    "limiar = 2 * (limiar - offset) + 255 \n",
    "origem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d1a605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[255, 5, 254, 255, 254, 254, 251, 235, 139, 0]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_length_encode(destination, origem, len(origem), limiar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9365e14",
   "metadata": {},
   "source": [
    "Os valores medidos igual ou próximos ao offset `-20, -20.5` ao serem transformados viram `255 e 254`, os valores utilizados como marcador. Nesse caso teremos duas sinalizações de valor literal com o marcador `ESC=254`. \n",
    "* `[255,5...]` temos 5 valores abaixo do limiar\n",
    "* `[...254,255...]` temos o valor literal `255`\n",
    "* `[...254,254...]` temos o valor literal `254`\n",
    "* `[...251,235,139]` valores de medição literal\n",
    "\n",
    "Nesse caso economizamos somente 1 byte, denotado pelo valor 0 ao final da lista. Esses exemplos com poucos valores não fazem jus ao algoritmo, o poder de compressão aparece quando temos milhares de dados como veremos a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b9e3b1",
   "metadata": {},
   "source": [
    "**Algoritmo de Descompressão**\n",
    "\n",
    "O Algoritmo de descompressão original em C é mostrado a seguir:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6130f426",
   "metadata": {},
   "source": [
    "```c\n",
    "#define RUN 255 \n",
    "#define ESC 254 \n",
    "int run_length_decode(unsigned char *dest, unsigned char *src, int nsrc, int thresh) { \n",
    "    int si=0,di=0,nrun; \n",
    "    unsigned char ib; \n",
    "    while (si < nsrc) { \n",
    "        ib = src[si++]; \n",
    "        if (ib == RUN) { \n",
    "            nrun = src[si++];\n",
    "            while(nrun-- >0){ \n",
    "                dest[di++] = thresh; }\n",
    "        } else if (ib == ESC) {\n",
    "            /* next value is literal */ \n",
    "            dest[di++] = src[si++];\n",
    "        } else {\n",
    "            /* value */ \n",
    "            dest[di++] = ib; \n",
    "        } \n",
    "    } return di; \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d344e2cd",
   "metadata": {},
   "source": [
    "Vamos escrevê-lo em python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14daaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_decode(src, nsrc, thresh, offset):\n",
    "    dest = [] # creates an empty destination list\n",
    "    si = 0 #counter source\n",
    "    di = 0 #counter destination \n",
    "    while si < nsrc: #while we didn't read the whole file\n",
    "        ib = src[si] # read current position\n",
    "        si+=1 # counter go to the next position\n",
    "        if ib == RUN: # if current position is equal to marker RUN\n",
    "            nrun = src[si] # next position indicates number of points below thresh\n",
    "            si+=1\n",
    "            while nrun > 0:\n",
    "                dest.append(thresh) # we keep thresh in the destination nrun times\n",
    "                di+=1\n",
    "                nrun-=1\n",
    "        elif ib == ESC: # next value is literal\n",
    "            dest.append(src[di]/2 + offset - 127.5)\n",
    "            di+=1 ; si+=1\n",
    "        else:\n",
    "            # value\n",
    "            dest.append(ib/2 + offset - 127.5) # If there isn't a marker I'll just keep the current value\n",
    "            di+=1\n",
    "    return dest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d122e47",
   "metadata": {},
   "source": [
    "O algoritmo basicamente faz:\n",
    "* Percorre o arquivo codificado fonte e lê byte a byte\n",
    "* Se o byte é igual ao marcador `RUN=255` é sabido que o byte seguinte armazena a contagem de quantas vezes foi medido um valor abaixo do limiar\n",
    "* Um loop com essa contagem é efetuado e a cada rodada é armazenado o valor do limiar na lista de destino\n",
    "* Caso seja identificado o outro marcador `ESC=254` é armazenado o valor seguinte\n",
    "* Caso nenhum dos casos anteriores ocorra simplesmente é armazenado o valor atual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51942e3b",
   "metadata": {},
   "source": [
    "## Teste de Velocidade do Algoritmo Original\n",
    "A motivação para a otimização da leitura desses arquivos comprimidos foi por conta de arquivos da ordem de 100MB, que ao serem descomprimidos geram por volta de 8GB de dados. \n",
    "Utilizamos um desses arquivos como exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0afff4",
   "metadata": {},
   "source": [
    "Eu li e ouvi de mais de uma vez que não se faz otimização sem \"profiling\", isto é, não comece a otimizar as coisas antes de saber exatamente o quê  toma o tempo do seu código. \n",
    "\n",
    "Para nos ajudar nisso vamos usar a extensão da biblioteca `line_profiler` que mostra a execução linha a linha de dada função que passarmos como argumento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbddd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_blocks = blocks[(68,301)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa65669",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = 255\n",
    "ESC = 254    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3ed659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_in_gb(obj):\n",
    "    print(f'{sys.getsizeof(obj)/1e6:.2f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fe54b2",
   "metadata": {},
   "source": [
    "A função a seguir testa o algoritmo original acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c5bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "def test_orig(blocks, debug=False):\n",
    "    decoded = []\n",
    "    if debug:\n",
    "        blocks = blocks[:1]\n",
    "    for block in tqdm(blocks):\n",
    "        src = block.data[block.start:block.stop]\n",
    "        nsrc = len(src) #block.stop - block.start\n",
    "        thresh = block.thresh       \n",
    "        offset = block.offset\n",
    "        decoded.append(run_length_decode(src, nsrc, thresh, offset))\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c4e225",
   "metadata": {},
   "source": [
    "Vamos checar o perfil de uma chamada da função `run_length_decode`, isso é alcançado chamando a função acima com o argumento `debug=True`. \n",
    "Assim executamos somente 1 bloco em vez de 133932."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff1b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8c70f44cb6413f87c2cb183bbfa5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 3.52617e-07 s\n",
       "\n",
       "Total time: 0.0316763 s\n",
       "File: <ipython-input-19-0e35b2a102ae>\n",
       "Function: run_length_decode at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def run_length_decode(src, nsrc, thresh, offset):\n",
       "     2         1          4.0      4.0      0.0      dest = [] # creates an empty destination list\n",
       "     3         1          2.0      2.0      0.0      si = 0 #counter source\n",
       "     4         1          1.0      1.0      0.0      di = 0 #counter destination \n",
       "     5       131        188.0      1.4      0.2      while si < nsrc: #while we didn't read the whole file\n",
       "     6       130        230.0      1.8      0.3          ib = src[si] # read current position\n",
       "     7       130        181.0      1.4      0.2          si+=1 # counter go to the next position\n",
       "     8       130        225.0      1.7      0.3          if ib == RUN: # if current position is equal to marker RUN\n",
       "     9        60         84.0      1.4      0.1              nrun = src[si] # next position indicates number of points below thresh\n",
       "    10        60         79.0      1.3      0.1              si+=1\n",
       "    11     14623      20484.0      1.4     22.8              while nrun > 0:\n",
       "    12     14563      24654.0      1.7     27.4                  dest.append(thresh) # we keep thresh in the destination nrun times\n",
       "    13     14563      21605.0      1.5     24.1                  di+=1\n",
       "    14     14563      21576.0      1.5     24.0                  nrun-=1\n",
       "    15        70        102.0      1.5      0.1          elif ib == ESC: # next value is literal\n",
       "    16                                                       dest.append(src[di]/2 + offset - 127.5)\n",
       "    17                                                       di+=1 ; si+=1\n",
       "    18                                                   else:\n",
       "    19                                                       # value\n",
       "    20        70        305.0      4.4      0.3              dest.append(ib/2 + offset - 127.5) # If there isn't a marker I'll just keep the current value\n",
       "    21        70        110.0      1.6      0.1              di+=1\n",
       "    22         1          2.0      2.0      0.0      return dest"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f run_length_decode test_orig(compressed_blocks, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c4370",
   "metadata": {},
   "source": [
    "Vemos que 98.3% do tempo a função passa somente no loop `while` interno. Vamos ver o que isso significa para 133932 blocos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a293f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2751341b6abd4e39942c6fe6547e4446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133932 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = test_orig(compressed_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae7b1d9",
   "metadata": {},
   "source": [
    "Isso no contexto de uso do dia a dia do fiscal da Anatel é um tempo extenso, porque pode haver vários arquivos e essas análises podem ser recorrentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ab14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133932, 14633)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d), len(d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0920e6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17 GB\n"
     ]
    }
   ],
   "source": [
    "size_in_gb(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b6441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del d\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465b246a",
   "metadata": {},
   "source": [
    "### Loop `while` Eliminado\n",
    "Vemos que o loop while acima simplesmente adiciona o mesmo valor `thresh` por `nrun` vezes. Para eliminarmos o loop basta extendermos a lista de uma só vez, adicionando a ela uma outra lista de tamanho `nrun` povoada com valores `thresh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a5529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_decode2(dest, src, nsrc, thresh, offset):\n",
    "    si = 0 #counter source\n",
    "    di = 0 #counter destination \n",
    "    while si < nsrc: #while we didn't read the whole file\n",
    "        ib = src[si] # read current position\n",
    "        si+=1 # counter go to the next position\n",
    "        if ib == RUN: # if current position is equal to marker RUN\n",
    "            nrun = src[si] # next position indicates number of points below thresh\n",
    "            si+=1\n",
    "            di+=nrun # Full incremental\n",
    "            dest.extend([thresh]*nrun) #Extend the resulted list in a pythonic way \n",
    "        elif ib == ESC: # next value is literal\n",
    "            dest.append(src[di]/2 + offset - 127.5)\n",
    "            di+=1 ; si+=1\n",
    "        else:\n",
    "            # value\n",
    "            dest.append(ib/2 + offset - 127.5) # If there isn't a marker I'll just keep the current value\n",
    "            di+=1\n",
    "    return dest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c11c91c",
   "metadata": {},
   "source": [
    "Substituímos:\n",
    "\n",
    "```python\n",
    "while nrun > 0:\n",
    "    dest.append(thresh)\n",
    "    di+=1\n",
    "    nrun-=1\n",
    "```\n",
    "por\n",
    "```python\n",
    "di+=nrun\n",
    "dest.extend([thresh]*nrun)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c22ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_no_while(blocks, debug=False):\n",
    "    decoded = []\n",
    "    if debug:\n",
    "        blocks= blocks[:1]\n",
    "    for block in tqdm(blocks):\n",
    "        dest = []\n",
    "        src = block.data[block.start:block.stop]\n",
    "        nsrc = len(src) #block.stop - block.start\n",
    "        thresh = block.thresh       \n",
    "        offset = block.offset\n",
    "        decoded.append(run_length_decode2(dest, src, nsrc, thresh, offset))\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c7293a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba9b952cae640d5aac04c0c579f0901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 3.52617e-07 s\n",
       "\n",
       "Total time: 0.00457802 s\n",
       "File: <ipython-input-29-d484ae5f5462>\n",
       "Function: run_length_decode2 at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def run_length_decode2(dest, src, nsrc, thresh, offset):\n",
       "     2         1          5.0      5.0      0.0      si = 0 #counter source\n",
       "     3         1        604.0    604.0      4.7      di = 0 #counter destination \n",
       "     4       131        207.0      1.6      1.6      while si < nsrc: #while we didn't read the whole file\n",
       "     5       130        318.0      2.4      2.4          ib = src[si] # read current position\n",
       "     6       130        145.0      1.1      1.1          si+=1 # counter go to the next position\n",
       "     7       130        204.0      1.6      1.6          if ib == RUN: # if current position is equal to marker RUN\n",
       "     8        60        114.0      1.9      0.9              nrun = src[si] # next position indicates number of points below thresh\n",
       "     9        60         68.0      1.1      0.5              si+=1\n",
       "    10        60        156.0      2.6      1.2              di+=nrun # Full incremental\n",
       "    11        60      10751.0    179.2     82.8              dest.extend([thresh]*nrun) #Extend the resulted list in a pythonic way \n",
       "    12        70        155.0      2.2      1.2          elif ib == ESC: # next value is literal\n",
       "    13                                                       dest.append(src[di]/2 + offset - 127.5)\n",
       "    14                                                       di+=1 ; si+=1\n",
       "    15                                                   else:\n",
       "    16                                                       # value\n",
       "    17        70        120.0      1.7      0.9              dest.append(ib/2 + offset - 127.5) # If there isn't a marker I'll just keep the current value\n",
       "    18        70        134.0      1.9      1.0              di+=1\n",
       "    19         1          2.0      2.0      0.0      return dest"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f run_length_decode2 test_no_while(compressed_blocks, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a63b967",
   "metadata": {},
   "source": [
    "O tempo caiu de `0.0316763s` para `0.00457802s`, ainda passamos a maior parte do tempo, `82.8%`, extendendo a lista original, no entanto isso é feito uma única vez por byte.\n",
    "\n",
    "Vamos ver como isso se traduz ao executarmos a função para todos os blocos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d1afbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec31d7b30f384714b01c16b8f3b38bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133932 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = test_no_while(compressed_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66845c86",
   "metadata": {},
   "source": [
    "Passamos de 4min e 39s para 1min e 12s. Melhoria de `279s / 72s = 3,875 vezes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e0d0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133932, 14633)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d), len(d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b2fd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17 GB\n"
     ]
    }
   ],
   "source": [
    "size_in_gb(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0a608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del d\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d6b86",
   "metadata": {},
   "source": [
    "### Trocar de Listas para arrays pré-alocados\n",
    "Como a maioria do tempo dispendido na função anterior ainda é na extensão da lista original com a lista de valores threshold. \n",
    "Para cada bloco a lista é extendida com uma sublista povoada com os valores de limiar `thresh`. Isso demanda que a memória seja alocada toda vez que extendemos a lista. \n",
    "\n",
    "Nessa alocação os endereços de memória não necessariamente estão adjacentes, isso certamente gera um gargalo no tempo de execução. \n",
    "\n",
    "Esse problema também aparece na função externa `test_no_while`.\n",
    "\n",
    "Para sanarmos isso vamos declarar um numpy array já com os valores de `thresh` preenchidos, assim realizamos uma pré-alocação de memória eficiente ( valores adjacentes ) e para os valores lidos abaixo do limiar não precisamos fazer nenhuma atribuição visto que o numpy array já está povoado com valores `thresh`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b3c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_decode3(dest, src, nsrc, thresh, offset):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < nsrc:\n",
    "        ib = src[i] \n",
    "        i+=1\n",
    "        if ib == RUN:\n",
    "            nrun = src[i] \n",
    "            i+=1\n",
    "            dest[j:j+nrun] = thresh #dest is now a numpy array\n",
    "            j+=nrun\n",
    "        elif ib == ESC:\n",
    "            # next value is literal\n",
    "            dest[j] = src[i]/2. + offset - 127.5\n",
    "            i+=1 ; j+=1\n",
    "        else:\n",
    "            # value\n",
    "            dest[j] = ib/2. + offset - 127.5\n",
    "            j+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d208a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "def test_prealloc_np(blocks):\n",
    "    decoded = np.empty((len(blocks), blocks[0].norig), dtype=np.float16)\n",
    "    decoded.fill(blocks[0].thresh)\n",
    "    for b, block in enumerate(tqdm(blocks)):\n",
    "        src = block.data[block.start:block.stop]\n",
    "        nsrc = len(src)\n",
    "        thresh = block.thresh\n",
    "        offset = block.offset\n",
    "        dest = np.empty(block.norig, dtype=np.float16)\n",
    "        dest.fill(thresh)\n",
    "        decoded[b] = run_length_decode3(dest, src, nsrc, thresh, offset)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa18016",
   "metadata": {},
   "source": [
    "Também declaramos os dados como sendo do tipo, `np.float16`, dado que os valores de nível do espectro possuem precisão de no máximo 1 casa decimal, o valor`np.float16` é o suficiente para armazená-los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c80a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59afb51699d947ee809f9c331b997d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 3.52617e-07 s\n",
       "\n",
       "Total time: 0.000689366 s\n",
       "File: <ipython-input-23-be56a10ab4a1>\n",
       "Function: run_length_decode3 at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def run_length_decode3(dest, src, nsrc, thresh, offset):\n",
       "     2         1          5.0      5.0      0.3      i = 0\n",
       "     3         1          2.0      2.0      0.1      j = 0\n",
       "     4       131        167.0      1.3      8.5      while i < nsrc:\n",
       "     5       130        257.0      2.0     13.1          ib = src[i] \n",
       "     6       130        192.0      1.5      9.8          i+=1\n",
       "     7       130        201.0      1.5     10.3          if ib == RUN:\n",
       "     8        60        118.0      2.0      6.0              nrun = src[i] \n",
       "     9        60        163.0      2.7      8.3              i+=1\n",
       "    10        60        225.0      3.8     11.5              dest[j:j+nrun] = thresh #dest is now a numpy array\n",
       "    11        60        116.0      1.9      5.9              j+=nrun\n",
       "    12        70        134.0      1.9      6.9          elif ib == ESC:\n",
       "    13                                                       # next value is literal\n",
       "    14                                                       dest[j] = src[i]/2. + offset - 127.5\n",
       "    15                                                       i+=1 ; j+=1\n",
       "    16                                                   else:\n",
       "    17                                                       # value\n",
       "    18        70        239.0      3.4     12.2              dest[j] = ib/2. + offset - 127.5\n",
       "    19        70        136.0      1.9      7.0              j+=1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f run_length_decode3 test_prealloc_np(compressed_blocks[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa6cd99",
   "metadata": {},
   "source": [
    "Usando um array pré-alocado o tempo do algoritmo para decodificar um bloco caiu de `0.00457802s` para `0.000689366s`. O efeito mais significativo será na decodificação de todos os blocos, onde também é usada pré-alocação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a98ef4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9f0d76ed3a49a49580e9b0c6db483f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133932 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = test_prealloc_np(compressed_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d8c473",
   "metadata": {},
   "source": [
    "Temos uma queda de `1min e 12s` para `29.5s`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef966fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del d\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fbf6d4",
   "metadata": {},
   "source": [
    "Algumas melhorias mais sutis podem ser feitas para reduzir o número de operações redundantes efetuadas.\n",
    "* O valor de `thresh` e `offset` é determinado no script, então é o mesmo para todos os blocos. \n",
    "Então não precisamos extraí-los toda vez, basta armazená-los uma única vez e repassá-los para a função.\n",
    "* A operação `+ offset - 127.5` constitui uma soma e subtração de valores fixos então pode ser reduzida a somente 1 operação com valor fixo: `MIN = offset - 127.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e16725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_decode4(dest, src, nsrc, thresh, MIN):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < nsrc:\n",
    "        ib = src[i] \n",
    "        i+=1\n",
    "        if ib == RUN:\n",
    "            nrun = src[i] \n",
    "            i+=1\n",
    "            dest[j:j+nrun] = thresh #dest is now a numpy array\n",
    "            j+=nrun\n",
    "        elif ib == ESC:\n",
    "            # next value is literal\n",
    "            dest[j] = src[i]/2. + MIN\n",
    "            i+=1 ; j+=1\n",
    "        else:\n",
    "            # value\n",
    "            dest[j] = ib/2. + MIN\n",
    "            j+=1  \n",
    "    return dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab6a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "def test_prealloc_np2(blocks):\n",
    "    decoded = np.empty((len(blocks), blocks[0].norig), dtype=np.float16)\n",
    "    decoded.fill(blocks[0].thresh)\n",
    "    thresh = blocks[0].thresh\n",
    "    offset = blocks[0].offset \n",
    "    MIN = offset - 127.5\n",
    "    for b, block in enumerate(tqdm(blocks)):\n",
    "        src = block.data[block.start:block.stop]\n",
    "        nsrc = len(src)\n",
    "        dest = np.empty(block.norig, dtype=np.float16)\n",
    "        dest.fill(thresh)\n",
    "        decoded[b] = run_length_decode4(dest, src, nsrc, thresh, MIN)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26f7ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11957d237e040f9b4a29e0f92e96859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 3.52617e-07 s\n",
       "\n",
       "Total time: 0.000672088 s\n",
       "File: <ipython-input-26-bf6ce6499759>\n",
       "Function: run_length_decode4 at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def run_length_decode4(dest, src, nsrc, thresh, MIN):\n",
       "     2         1          5.0      5.0      0.3      i = 0\n",
       "     3         1          2.0      2.0      0.1      j = 0\n",
       "     4       131        182.0      1.4      9.5      while i < nsrc:\n",
       "     5       130        264.0      2.0     13.9          ib = src[i] \n",
       "     6       130        214.0      1.6     11.2          i+=1\n",
       "     7       130        235.0      1.8     12.3          if ib == RUN:\n",
       "     8        60         68.0      1.1      3.6              nrun = src[i] \n",
       "     9        60        100.0      1.7      5.2              i+=1\n",
       "    10        60        283.0      4.7     14.8              dest[j:j+nrun] = thresh #dest is now a numpy array\n",
       "    11        60         67.0      1.1      3.5              j+=nrun\n",
       "    12        70         80.0      1.1      4.2          elif ib == ESC:\n",
       "    13                                                       # next value is literal\n",
       "    14                                                       dest[j] = src[i]/2. + MIN\n",
       "    15                                                       i+=1 ; j+=1\n",
       "    16                                                   else:\n",
       "    17                                                       # value\n",
       "    18        70        217.0      3.1     11.4              dest[j] = ib/2. + MIN\n",
       "    19        70        188.0      2.7      9.9              j+=1  \n",
       "    20         1          1.0      1.0      0.1      return dest"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f run_length_decode4 test_prealloc_np2(compressed_blocks[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a631d653",
   "metadata": {},
   "source": [
    "O efeito para 1 bloco somente é muito pequeno, vamos ver o efeito na decodificação de todos os blocos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2724d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7e057584be4172b0682dc86fee26e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133932 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = test_prealloc_np2(compressed_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04a631",
   "metadata": {},
   "source": [
    "Diminuímos de 29.5s para 23s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9471505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del d\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1574d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_length_decode5(dest, src, nsrc, thresh, MIN):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < nsrc:\n",
    "        ib = src[i] \n",
    "        i+=1\n",
    "        if ib == RUN:\n",
    "            nrun = src[i] \n",
    "            i+=1\n",
    "            dest[j:j+nrun] = thresh #dest is now a numpy array\n",
    "            j+=nrun\n",
    "        elif ib == ESC:\n",
    "            # next value is literal\n",
    "            dest[j] = src[i]/2. + MIN\n",
    "            i+=1 ; j+=1\n",
    "        else:\n",
    "            # value\n",
    "            dest[j] = ib/2. + MIN\n",
    "            j+=1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d97c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "def test_prealloc_np3(blocks):\n",
    "    thresh = blocks[0].thresh\n",
    "    decoded = np.full((len(blocks), blocks[0].norig), thresh, dtype=np.float16)\n",
    "    offset = blocks[0].offset \n",
    "    MIN = offset - 127.5\n",
    "    for b, block in enumerate(tqdm(blocks)):\n",
    "        src = block.data[block.start:block.stop]\n",
    "        nsrc = len(src)\n",
    "        #dest = np.empty(block.norig, dtype=np.float16)\n",
    "        #dest.fill(thresh)\n",
    "        run_length_decode5(decoded[b, :], src, nsrc, thresh, MIN)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3976c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 3.52617e-07 s\n",
       "\n",
       "Total time: 0.000476738 s\n",
       "File: <ipython-input-37-5c3575d407da>\n",
       "Function: run_length_decode5 at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def run_length_decode5(dest, src, nsrc, thresh, MIN):\n",
       "     2         1         41.0     41.0      3.0      i = 0\n",
       "     3         1          3.0      3.0      0.2      j = 0\n",
       "     4       131        137.0      1.0     10.1      while i < nsrc:\n",
       "     5       130        141.0      1.1     10.4          ib = src[i] \n",
       "     6       130        135.0      1.0     10.0          i+=1\n",
       "     7       130        140.0      1.1     10.4          if ib == RUN:\n",
       "     8        60         65.0      1.1      4.8              nrun = src[i] \n",
       "     9        60         62.0      1.0      4.6              i+=1\n",
       "    10        60        230.0      3.8     17.0              dest[j:j+nrun] = thresh #dest is now a numpy array\n",
       "    11        60         70.0      1.2      5.2              j+=nrun\n",
       "    12        70        117.0      1.7      8.7          elif ib == ESC:\n",
       "    13                                                       # next value is literal\n",
       "    14                                                       dest[j] = src[i]/2. + MIN\n",
       "    15                                                       i+=1 ; j+=1\n",
       "    16                                                   else:\n",
       "    17                                                       # value\n",
       "    18        70        129.0      1.8      9.5              dest[j] = ib/2. + MIN\n",
       "    19        70         82.0      1.2      6.1              j+=1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1e5a47aa6741bea9ce290294716a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f run_length_decode5 test_prealloc_np3(compressed_blocks[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a338d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f806f5a0812d46a3be5d66cd3fcd400f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133932 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = test_prealloc_np3(compressed_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f659354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del d\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcece64",
   "metadata": {},
   "source": [
    "### Processamento Paralelo dos Blocos\n",
    "Como estamos iterando os vários blocos e aplicando a função de decodificação, outra otimização que vêm em mente é paralelizar essa chamada de função.\n",
    "\n",
    "Para isso precisamos adaptar a função para podermos dividir não somente o bloco como o array de destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30506709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "from rfpy.parser import run_length_decode5\n",
    "def test_prealloc_mp(blocks):\n",
    "    thresh = blocks[0].thresh\n",
    "    decoded = np.full((len(blocks), blocks[0].norig), thresh, dtype=np.float16)\n",
    "    with Pool(processes=os.cpu_count()) as pool:\n",
    "        pool.map(run_length_decode5, decoded)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b931f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run_length_decode5() missing 4 required positional arguments: 'src', 'nsrc', 'thresh', and 'MIN'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\rsilva\\Miniconda3\\envs\\rfpy\\lib\\multiprocessing\\pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\rsilva\\Miniconda3\\envs\\rfpy\\lib\\multiprocessing\\pool.py\", line 44, in mapstar\n    return list(map(*args))\nTypeError: run_length_decode5() missing 4 required positional arguments: 'src', 'nsrc', 'thresh', and 'MIN'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-e93b67dea4c4>\u001b[0m in \u001b[0;36mtest_prealloc_mp\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdecoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_length_decode5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\rfpy\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         '''\n\u001b[1;32m--> 268\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\rfpy\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: run_length_decode5() missing 4 required positional arguments: 'src', 'nsrc', 'thresh', and 'MIN'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = test_prealloc_mp(compressed_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6568dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "def test_prealloc_fill(blocks):\n",
    "    decoded = np.full((len(blocks), blocks[0].norig), MIN, dtype=np.float16)\n",
    "\n",
    "    for b, block in enumerate(tqdm(blocks)):\n",
    "        src = block.data[block.start:block.stop]\n",
    "        nsrc = len(src)\n",
    "        thresh = block.thresh\n",
    "        dest = np.full(block.norig, MIN, dtype=np.float16)\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while i < nsrc:\n",
    "            ib = src[i] \n",
    "            i+=1\n",
    "            if ib == RUN:\n",
    "                nrun = src[i] \n",
    "                i+=1\n",
    "                dest[j:j+nrun] = MIN + thresh/2.\n",
    "                j+=nrun\n",
    "            elif ib == ESC:\n",
    "                # next value is literal\n",
    "                dest[j] = MIN + src[i]/2.\n",
    "                i+=1 ; j+=1\n",
    "            else:\n",
    "                # value\n",
    "                dest[j] = MIN + ib/2.\n",
    "                j+=1\n",
    "        decoded[b] = dest\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44869e5",
   "metadata": {},
   "source": [
    "## Functional Programming - Much Worse\n",
    "Elimination of loops doesn't necessarily really eliminates them. `filter` and `map` run along the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a76593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slow\n",
    "def test_prealloc_functional(blocks):\n",
    "    decoded = np.full((len(blocks), blocks[0].norig), MIN, dtype=np.float16)\n",
    "    MAX = blocks[0].norig\n",
    "    for b, block in enumerate(tqdm(blocks)):\n",
    "        src = block.data[block.start:block.stop]\n",
    "        threshold = block.thresh\n",
    "        dest = np.concatenate(L(src.split(b'\\xff')).filter(lambda o: o != b'').map(lambda o: np.concatenate([np.repeat(threshold,o[0]),  np.fromiter(o[1:].replace(b'\\xfe', b''), dtype=np.float16, count=len(o[1:]))])))\n",
    "        decoded[b][:dest.shape[0]] = dest[:MAX]\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fbcffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# decoded = test_prealloc_mp(compressed_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a04ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047599fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cython\n",
    "\n",
    "# cimport cython\n",
    "\n",
    "# import numpy as np\n",
    "# cimport numpy as np\n",
    "# #from cython.parallel import prange\n",
    "\n",
    "# #ctypedef np.double_t DTYPE_t\n",
    "\n",
    "# @cython.boundscheck(False)\n",
    "# @cython.wraparound(False)\n",
    "# cpdef object cy_decode_block(block):\n",
    "#     cdef float MIN = block.offset - 127.5\n",
    "#     cdef int RUN = 255\n",
    "#     cdef int ESC = 254\n",
    "#     cdef const unsigned char[:] src = block.data[block.start:block.stop]\n",
    "#     src = block.data[block.start:block.stop]\n",
    "#     cdef int nsrc = len(src)\n",
    "#     cdef int thresh = block.thresh\n",
    "#     cdef np.ndarray dest =  np.full(block.norig, MIN, dtype=np.float16)\n",
    "#     cdef int i = 0\n",
    "#     cdef int j = 0\n",
    "#     while i < nsrc:\n",
    "#         ib = src[i] \n",
    "#         i+=1\n",
    "#         if ib == RUN:\n",
    "#             nrun = src[i] \n",
    "#             i+=1\n",
    "#             dest[j:j+nrun] = MIN + thresh/2.\n",
    "#             j+=nrun\n",
    "#         elif ib == ESC:\n",
    "#             # next value is literal\n",
    "#             dest[j] = MIN + src[i]/2.\n",
    "#             i+=1 ; j+=1\n",
    "#         else:\n",
    "#             # value\n",
    "#             dest[j] = MIN + ib/2.\n",
    "#             j+=1\n",
    "#     return dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d660eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cython --annotate\n",
    "\n",
    "# cimport cython\n",
    "\n",
    "# import numpy as np\n",
    "# cimport numpy as np\n",
    "# #from cython.parallel import prange\n",
    "\n",
    "# #ctypedef np.double_t DTYPE_t\n",
    "\n",
    "# @cython.boundscheck(False)\n",
    "# @cython.wraparound(False)\n",
    "# cpdef object cy_decode_blocks(list blocks):\n",
    "#     cdef float offset = blocks[0].offset\n",
    "#     cdef float MIN = offset - 127.5\n",
    "#     cdef int rows = len(blocks)\n",
    "#     cdef int columns = blocks[0].norig\n",
    "#     cdef np.ndarray decoded = np.full((rows, columns), MIN, dtype=np.float16)\n",
    "#     cdef int RUN = 255\n",
    "#     cdef int ESC = 254\n",
    "#     cdef object block\n",
    "#     cdef int row\n",
    "#     cdef const unsigned char[:] src\n",
    "#     cdef int nsrc\n",
    "#     cdef int thresh = blocks[0].thresh\n",
    "#     #cdef np.ndarray dest\n",
    "#     cdef int i\n",
    "#     cdef int j\n",
    "#     for row, block in enumerate(blocks):\n",
    "#         src = block.data[block.start:block.stop]\n",
    "#         nsrc = len(src)\n",
    "#         i = 0\n",
    "#         j = 0\n",
    "#         while i < nsrc:\n",
    "#             ib = src[i] \n",
    "#             i+=1\n",
    "#             if ib == RUN:\n",
    "#                 nrun = src[i] \n",
    "#                 i+=1\n",
    "#                 decoded[row, j:j+nrun] = MIN + thresh/2.\n",
    "#                 j+=nrun\n",
    "#             elif ib == ESC:\n",
    "#                 # next value is literal\n",
    "#                 decoded[row, j] = MIN + src[i]/2.\n",
    "#                 i+=1 ; j+=1\n",
    "#             else:\n",
    "#                 # value\n",
    "#                 decoded[row, j] = MIN + ib/2.\n",
    "#                 j+=1\n",
    "#     return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264f1d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cython --annotate\n",
    "\n",
    "# cimport cython\n",
    "\n",
    "# import numpy as np\n",
    "# cimport numpy as np\n",
    "# #from cython.parallel import prange\n",
    "\n",
    "# #ctypedef np.double_t DTYPE_t\n",
    "\n",
    "# @cython.boundscheck(False)\n",
    "# @cython.wraparound(False)\n",
    "# cpdef object cy_decode_blocks(list blocks):\n",
    "#     cdef float offset = blocks[0].offset\n",
    "#     cdef float MIN = offset - 127.5\n",
    "#     cdef int rows = len(blocks)\n",
    "#     cdef int columns = blocks[0].norig\n",
    "#     cdef np.ndarray decoded = np.full((rows, columns), MIN, dtype=np.float16)\n",
    "#     cdef list data = [block.data[block.start:block.stop] for block in blocks]\n",
    "#     cdef int RUN = 255\n",
    "#     cdef int ESC = 254\n",
    "#     cdef int row\n",
    "#     cdef const unsigned char[:] src\n",
    "#     cdef int nsrc\n",
    "#     cdef int thresh = blocks[0].thresh\n",
    "#     cdef int i\n",
    "#     cdef int j\n",
    "#     for row in range(rows):\n",
    "#         src = data[row]\n",
    "#         nsrc = len(src)\n",
    "#         i = 0\n",
    "#         j = 0\n",
    "#         while i < nsrc:\n",
    "#             ib = src[i] \n",
    "#             i+=1\n",
    "#             if ib == RUN:\n",
    "#                 nrun = src[i] \n",
    "#                 i+=1\n",
    "#                 decoded[row, j:j+nrun] = MIN + thresh/2.\n",
    "#                 j+=nrun\n",
    "#             elif ib == ESC:\n",
    "#                 # next value is literal\n",
    "#                 decoded[row, j] = MIN + src[i]/2.\n",
    "#                 i+=1 ; j+=1\n",
    "#             else:\n",
    "#                 # value\n",
    "#                 decoded[row, j] = MIN + ib/2.\n",
    "#                 j+=1\n",
    "#     return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb95e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cython --annotate\n",
    "\n",
    "# cimport cython\n",
    "\n",
    "# import numpy as np\n",
    "# cimport numpy as np\n",
    "# #from cython.parallel import prange\n",
    "\n",
    "# #ctypedef np.float_t DTYPE_t\n",
    "\n",
    "# @cython.boundscheck(False)\n",
    "# @cython.wraparound(False)\n",
    "# cpdef object cy_decode_blocks(list blocks):\n",
    "#     cdef float offset = blocks[0].offset\n",
    "#     cdef float MIN = offset - 127.5\n",
    "#     cdef int rows = len(blocks)\n",
    "#     cdef int columns = blocks[0].norig\n",
    "#     cdef np.ndarray decoded = np.full((rows, columns), MIN, dtype=np.float16)\n",
    "#     #cdef DTYPE_t [:, :] decoded_v = decoded\n",
    "#     cdef list data = [b.data[b.start:b.stop] for b in blocks]\n",
    "#     cdef int RUN = 255\n",
    "#     cdef int ESC = 254\n",
    "#     cdef const unsigned char[:] src\n",
    "#     cdef int NRSC\n",
    "#     cdef float thresh = blocks[0].thresh\n",
    "#     cdef int i\n",
    "#     cdef int j\n",
    "#     cdef int ib\n",
    "#     cdef int nrun\n",
    "#     cdef Py_ssize_t row   \n",
    "#     for row in range(rows):\n",
    "#         src = data[row]\n",
    "#         nsrc = len(src)\n",
    "#         i = 0\n",
    "#         j = 0\n",
    "#         while i < nsrc:\n",
    "#             ib = src[i] \n",
    "#             i+=1\n",
    "#             if ib == RUN:\n",
    "#                 nrun = src[i] \n",
    "#                 i+=1\n",
    "#                 decoded[row, j:j+nrun] = MIN + thresh/2.\n",
    "#                 j+=nrun\n",
    "#             elif ib == ESC:\n",
    "#                 # next value is literal\n",
    "#                 decoded[row, j] = MIN + src[i]/2.\n",
    "#                 i+=1 ; j+=1\n",
    "#             else:\n",
    "#                 # value\n",
    "#                 decoded[row, j] = MIN + ib/2.\n",
    "#                 j+=1\n",
    "#     return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdd94ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cython --annotate\n",
    "\n",
    "# cimport cython\n",
    "\n",
    "# import numpy as np\n",
    "# cimport numpy as np\n",
    "# #from cython.parallel import prange\n",
    "\n",
    "# #DTYPE = np.float32\n",
    "\n",
    "# ctypedef np.float32_t DTYPE_t\n",
    "\n",
    "# @cython.boundscheck(False)\n",
    "# @cython.wraparound(False)\n",
    "# cpdef object cy_decode_blocks(list blocks):\n",
    "#     cdef float offset = blocks[0].offset\n",
    "#     cdef float MIN = offset - 127.5\n",
    "#     cdef int rows = len(blocks)\n",
    "#     cdef int columns = blocks[0].norig\n",
    "#     cdef np.ndarray[DTYPE_t, ndim=2] decoded = np.full((rows, columns), MIN, np.float32)\n",
    "#     cdef list data = [b.data[b.start:b.stop] for b in blocks]\n",
    "#     cdef int RUN = 255\n",
    "#     cdef int ESC = 254\n",
    "#     cdef const unsigned char[:] src\n",
    "#     cdef int NRSC\n",
    "#     cdef int thresh = blocks[0].thresh\n",
    "#     cdef int i\n",
    "#     cdef int j\n",
    "#     cdef int ib\n",
    "#     cdef int nrun\n",
    "#     cdef Py_ssize_t row   \n",
    "#     for row in range(rows):\n",
    "#         src = data[row]\n",
    "#         nsrc = len(src)\n",
    "#         i = 0\n",
    "#         j = 0\n",
    "#         while i < nsrc:\n",
    "#             ib = src[i]\n",
    "#             i+=1\n",
    "#             if ib == RUN:\n",
    "#                 nrun = src[i] \n",
    "#                 i+=1\n",
    "#                 #decoded[row, j:j+nrun] = thresh # MIN + thresh/2.\n",
    "#                 for _ in range(nrun):\n",
    "#                     decoded[row, j] = MIN + thresh / 2.\n",
    "#                     #decoded[row, j] = thresh                    \n",
    "#                     j+=1\n",
    "#                 #j+=nrun\n",
    "#             elif ib == ESC:\n",
    "#                 # next value is literal\n",
    "#                 decoded[row, j] = MIN + src[i]/2.\n",
    "#                 i+=1 ; j+=1\n",
    "#             else:\n",
    "#                 # value\n",
    "#                 decoded[row, j] = MIN + ib/2.\n",
    "#                 j+=1\n",
    "#     return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d65c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "cimport cython\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "#from cython.parallel import prange\n",
    "\n",
    "#DTYPE = np.float32\n",
    "\n",
    "ctypedef np.float32_t DTYPE_t\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "cpdef np.ndarray[DTYPE_t, ndim=2] cy_decode_blocks(list data, int rows, int cols, int thresh, float MIN):\n",
    "    cdef np.ndarray[DTYPE_t, ndim=2] decoded = np.full((rows, cols), thresh, np.float32)\n",
    "    cdef const unsigned char[:] src\n",
    "    cdef int RUN = 255\n",
    "    cdef int ESC = 254\n",
    "    cdef int NRSC\n",
    "    cdef int i\n",
    "    cdef int j\n",
    "    cdef int ib\n",
    "    cdef int nrun\n",
    "    cdef Py_ssize_t row   \n",
    "    for row in range(rows):\n",
    "        src = data[row]\n",
    "        nsrc = len(src)\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while i < nsrc:\n",
    "            ib = src[i]\n",
    "            i+=1\n",
    "            if ib == RUN:\n",
    "                nrun = src[i] \n",
    "                i+=1\n",
    "                for _ in range(nrun):\n",
    "                    decoded[row, j] = thresh\n",
    "                    j+=1\n",
    "            elif ib == ESC:\n",
    "                # next value is literal\n",
    "                decoded[row, j] = MIN + src[i]/2.\n",
    "                i+=1 ; j+=1\n",
    "            else:\n",
    "                # value\n",
    "                decoded[row, j] = MIN + ib/2.\n",
    "                j+=1\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575c7617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cython(blocks):\n",
    "    return cy_decode_blocks(list(blocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a44479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mp_cy(blocks):\n",
    "    MIN = blocks[0].offset - 127.5\n",
    "    decoded = np.full((len(blocks), blocks[0].norig), MIN, dtype=np.float16)\n",
    "    block_array = [(a,b) for a,b in zip(decoded, blocks)]\n",
    "    with Pool(processes=os.cpu_count()) as pool:\n",
    "        pool.map(decode_blocks, block_array)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7928c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = compressed_blocks[0].offset\n",
    "MIN = offset - 127.5\n",
    "cols = compressed_blocks[0].norig\n",
    "thresh = compressed_blocks[0].thresh - 1\n",
    "rows = len(compressed_blocks)\n",
    "data_blocks = [b.data[b.start:b.stop] for b in compressed_blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = np.linspace(108,137, num=14848)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ca950",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "decoded = pd.DataFrame(cy_decode_blocks(data_blocks, rows, cols, thresh, MIN), columns=frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9470c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# decoded = cy_decode_blocks(data_blocks, rows, cols, thresh, MIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f2b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(decoded[:5, :5])\n",
    "display(decoded[-5:, -5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b152dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{sys.getsizeof(decoded)/1e9:.2f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecac404",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a6d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TH = -80\n",
    "dict_freq = {}\n",
    "for c in tqdm(decoded.columns):\n",
    "    d = decoded.loc[:, c].value_counts().to_dict()\n",
    "    d = {k:v for k,v in d.items() if k > TH}\n",
    "    if d:\n",
    "        dict_freq[c] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be1d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c194df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del decoded\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f7b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "np.asarray([b.wallclock_datetime for b in compressed_blocks]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a95ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rfpy]",
   "language": "python",
   "name": "conda-env-rfpy-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
