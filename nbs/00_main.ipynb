{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rfpy - CFRS Rfeye Node Logger binaries parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2            #Reload the code automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import *\n",
    "import os\n",
    "from fastcore.xtras import Path\n",
    "from fastcore.script import *\n",
    "from fastcore.utils import parallel, partial\n",
    "from rfpy.parser import *\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def _export_meta(bin_path: Union[str, Path],\n",
    "                saida: Union[str, Path],\n",
    "                ext: str = '.csv',\n",
    "                return_df: bool = False)->Union[None, pd.DataFrame]:\n",
    "\n",
    "    meta_items = extract_metadata(parse_bin(bin_path))\n",
    "    for (tipo, tid), df in meta_items:\n",
    "        dt_features = isinstance(df.index, pd.DatetimeIndex)\n",
    "        if dt_features:\n",
    "            start = df.index.min().strftime(\"%Y%m%d-%H%M%S\")\n",
    "            end = df.index.max().strftime(\"%Y%m%d-%H%M%S\")\n",
    "            name = f'{bin_path.stem}_Bloco_{tipo}_ThreadId_{tid}_{start}_{end}'\n",
    "        else:\n",
    "            name = f'{bin_path.stem}_Bloco_{tipo}_ThreadId_{tid}'\n",
    "        if ext == '.csv':\n",
    "            df.to_csv(Path(saida) / f'{name}{ext}', index=bool(dt_features))\n",
    "        elif ext == '.fth':\n",
    "            df.reset_index().to_feather(Path(saida) / f'{name}{ext}')\n",
    "        else:\n",
    "            raise ValueError(f\"Extension {ext} not implemented\")\n",
    "        if return_df:\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def export_metadata(entrada:Param(\"Diretório contendo arquivos .bin\", str),\n",
    "                saida:Param(\"Diretório para salvar os arquivos de saída\", str),\n",
    "                recursivo:Param(\"Buscar arquivos de maneira recursiva?\", bool_arg)=True,\n",
    "                pastas:Param(\"Limita a busca às pastas\", Iterable[str]) = None,\n",
    "                ext:Param(\"Qual extensão salvar os arquivos\", str) = '.csv',\n",
    "                verbose:Param(\"Imprimir mensagens de execução?\", bool_arg) = False):\n",
    "\n",
    "        lista_bins = get_files(entrada, extensions=['.bin'], recurse=recursivo, folders=pastas)\n",
    "        if verbose:\n",
    "            print(lista_bins)\n",
    "        export_func = partial(_export_meta, saida=saida, ext=ext)\n",
    "        parallel(export_func, lista_bins, n_workers=os.cpu_count(), pause=0.5)\n",
    "#         for bin_path, bin_block in tqdm(zip(lista_bins, bin_blocks), total=len(lista_bins)):\n",
    "#             _export_meta(bin_path, bin_block, saida, ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def export_spectrum(entrada:Param(\"Diretório contendo arquivos .bin\", str),\n",
    "                saida:Param(\"Diretório para salvar os arquivos de saída\", str),\n",
    "                recursivo:Param(\"Buscar arquivos de maneira recursiva?\", bool_arg)=True,\n",
    "                pastas:Param(\"Limita a busca às pastas\", Iterable[str]) = None,\n",
    "                ext:Param(\"Qual extensão salvar os arquivos\", str) = '.csv',\n",
    "                verbose:Param(\"Imprimir mensagens de execução?\", bool_arg) = False):\n",
    "\n",
    "        lista_bins = get_files(entrada, extensions=['.bin'], recurse=recursivo, folders=pastas)\n",
    "        if verbose:\n",
    "            print(lista_bins)\n",
    "        export_func = partial(_export_meta, saida=saida, ext=ext)\n",
    "        parallel(export_func, lista_bins, n_workers=os.cpu_count(), pause=0.5)\n",
    "#         for bin_path, bin_block in tqdm(zip(lista_bins, bin_blocks), total=len(lista_bins)):\n",
    "#             _export_meta(bin_path, bin_block, saida, ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_main.ipynb.\n",
      "Converted 01_parser.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_blocks.ipynb.\n",
      "Converted 04_constants.ipynb.\n",
      "No export destination, ignored:\n",
      "#export   \n",
      "import warnings\n",
      "with warnings.catch_warnings():\n",
      "    warnings.simplefilter(\"ignore\")\n",
      "from pprint import pprint\n",
      "import rfpy\n",
      "from rfpy.parser import *\n",
      "from nbdev.showdoc import *\n",
      "from fastcore.xtras import Path\n",
      "Warning: Exporting to \"None.py\" but this module is not part of this build\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rfpy]",
   "language": "python",
   "name": "conda-env-rfpy-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
