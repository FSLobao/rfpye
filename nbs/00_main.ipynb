{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rfpy - CFRS Rfeye Node Logger binaries parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2            #Reload the code automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import *\n",
    "import os\n",
    "from fastcore.xtras import Path\n",
    "from fastcore.script import *\n",
    "from fastcore.utils import parallel, partial\n",
    "from rfpy.parser import *\n",
    "import pandas as pd\n",
    "from rfpy.utils import *\n",
    "from rich.progress import track, Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_meta(filename):\n",
    "    ext = filename.suffix\n",
    "    if ext == '.csv':\n",
    "        df = pd.read_csv(filename)\n",
    "    elif ext == '.xlsx':\n",
    "        df = pd.read_excel(filename, engine='openpyxl')\n",
    "    elif ext == '.fth':\n",
    "        df = pd.read_feather(filename)\n",
    "        if \"wallclock_datetime\" in df.columns:\n",
    "            df.set_index('wallclock_datetime', inplace=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Extension {ext} not implemented\")\n",
    "    return df\n",
    "    \n",
    "@call_parse\n",
    "def process_bin(entrada: Param(\"Diretório contendo arquivos .bin\", str),\n",
    "                saida: Param(\"Diretório para salvar os arquivos de saída\", str),\n",
    "                recursivo: Param(\"Buscar arquivos de maneira recursiva?\", store_true)=False,\n",
    "                pastas: Param(\"Limita a busca às pastas\", Iterable[str])=None,\n",
    "                meta: Param(\"Extrair e Salvar os metadados?\", store_true)=False,\n",
    "                levels: Param(\"Extrair e Salvar os níveis de Espectro?\", store_true)=False,\n",
    "                ext: Param(\"Qual extensão salvar os arquivos\", str)='.fth', \n",
    "                substituir: Param(\"Lista de arquivos já processados\", store_true)=False):\n",
    "\n",
    "        lista_bins = get_files(entrada, extensions=['.bin'], recurse=recursivo, folders=pastas)  \n",
    "        parsed_bins = {}\n",
    "        meta_path = Path(f'{saida}/meta')\n",
    "        levels_path = Path(f'{saida}/levels')\n",
    "        meta_path.mkdir(exist_ok=True, parents=True)\n",
    "        levels_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        processed = Path(f'{saida}/processed_log.txt')\n",
    "        if substituir:\n",
    "            done = set()\n",
    "        elif processed.exists():\n",
    "            done = set(processed.read_text().split('\\n'))\n",
    "        else:\n",
    "            done = set()\n",
    "\n",
    "        console.rule(\"Lista de Arquivos a serem processados\", style='bold red')\n",
    "        console.print(lista_bins, style = \"bold white\", overflow='fold', justify='center')\n",
    "        if not lista_bins:\n",
    "            return\n",
    "        \n",
    "        erro_formato = False\n",
    "        erro_novo = False\n",
    "\n",
    "        with Progress() as progress:\n",
    "            bins = progress.track(lista_bins, total=len(lista_bins), description=\"[green]Processando Arquivos Binários\")\n",
    "            for file in bins:\n",
    "                progress.description = f'[cyan]Mapeando Blocos do arquivo {file.name}'\n",
    "                parsed_bins[file.stem] = parse_bin(file, progress=progress)\n",
    "            if meta:\n",
    "                lista = [f for f in lista_bins if f.name not in done]\n",
    "                if not lista:\n",
    "                    erro_novo = True\n",
    "                else:\n",
    "                    bins = progress.track(lista, total=len(lista), description=\"[green]Exportando Metadados\")\n",
    "                    for file in bins:\n",
    "                        export_meta(file.stem, parsed_bins[file.stem], meta_path, ext=ext)\n",
    "                        done.add(file.name)\n",
    "            if levels:\n",
    "                if ext == '.csv':\n",
    "                    erro_formato = True\n",
    "                    lista = []\n",
    "                else:\n",
    "                    lista = [f for f in lista_bins if f.name not in done]\n",
    "                    if not lista:\n",
    "                        erro_novo = True\n",
    "                    else:\n",
    "                        bins = progress.track(lista, total=len(lista), description=\"[green]Exportando Dados de Espectro\")\n",
    "                        for file in bins:\n",
    "                            meta_files = get_files(meta_path)\n",
    "                            for f in meta_files:\n",
    "                                if file.stem in str(f):\n",
    "                                    meta_file = f\n",
    "                                    break\n",
    "                            else:\n",
    "                                console.print('[red] :poop: Não foram encontrados os arquivos com os metadados, eles serão extraídos primeiro')\n",
    "                                export_meta(file.stem, parsed_bins[file.stem], meta_path, ext=ext)\n",
    "                                done.add(file.name)\n",
    "                            meta_df = read_meta(meta_file)\n",
    "                            index=meta_df.index\n",
    "                            export_level(file.stem, parsed_bins[file.stem], levels_path, ext=ext, index=index)\n",
    "                            done.add(file.name)\n",
    "        if erro_formato:\n",
    "            console.print(\":warning: Dados espectrais em .csv não são suportados pela explosão no tamanho de arquivo :exclamation:\")\n",
    "            console.print(\"Sugerimos o formato:point_right: [red].fth\")  \n",
    "        elif erro_novo:\n",
    "            console.print(\":sleeping: Nenhum arquivo novo a processar :zzz:\")\n",
    "            console.print(\":point_up: use --substituir no terminal ou substituir=True na chamada caso queira reprocessar os bins e sobrepôr os arquivos existentes :wink:\")\n",
    "        else:       \n",
    "            processed.write_text('\\n'.join(sorted(list(done))))\n",
    "            console.print(\"kbô :satisfied:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrada = Path(r'C:\\Users\\rsilva\\Downloads\\entrada\\pmec')\n",
    "# saida = Path(r'C:\\Users\\rsilva\\Downloads\\saida')\n",
    "# process_bin(entrada, saida, ext='.xlsx', levels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_main.ipynb.\n",
      "Converted 01_parser.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_blocks.ipynb.\n",
      "Converted 04_constants.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rfpy]",
   "language": "python",
   "name": "conda-env-rfpy-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
