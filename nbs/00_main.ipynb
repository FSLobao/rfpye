{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Console Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2            #Reload the code automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from datetime import datetime\n",
    "from typing import *\n",
    "import os\n",
    "import logging\n",
    "from fastcore.xtras import Path\n",
    "from fastcore.script import call_parse, Param, store_true\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rich.progress import Progress\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "from rich.logging import RichHandler\n",
    "from rfpy.utils import *\n",
    "from rfpy.constants import SPECTRAL_BLOCKS\n",
    "from rfpy.parser import *\n",
    "CACHE_FOLDER = Path(r\"C:\\Users\\rsilva\\Downloads\\saida\")\n",
    "if not CACHE_FOLDER.exists():\n",
    "    CACHE_FOLDER = Path.cwd() / 'cache'\n",
    "    CACHE_FOLDER.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "custom_theme = Theme({\"info\": \"dim cyan\", \"warning\": \"magenta\", \"danger\": \"bold red\"})\n",
    "console = Console(theme=custom_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_meta(filename):\n",
    "    ext = filename.suffix\n",
    "    if ext == \".csv\":\n",
    "        df = pd.read_csv(filename)\n",
    "    elif ext == \".xlsx\":\n",
    "        df = pd.read_excel(filename, engine=\"openpyxl\")\n",
    "    elif ext == \".fth\":\n",
    "        df = pd.read_feather(filename)\n",
    "        if \"wallclock_datetime\" in df.columns:\n",
    "            df.set_index(\"wallclock_datetime\", inplace=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Extension {ext} not implemented\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def process_bin(\n",
    "    entrada: Param(\"Arquivo .bin ou Diretório contendo arquivos .bin\", str),\n",
    "    saida: Param(\"Diretório para salvar os arquivos de saída\", str),\n",
    "    recursivo: Param(\"Buscar arquivos de maneira recursiva?\", store_true) = False,\n",
    "    pastas: Param(\"Limitar a busca às pastas\", Iterable[str]) = None,\n",
    "    levels: Param(\"Extrair e Salvar os níveis de Espectro?\", store_true) = False,\n",
    "    meta_ext: Param(\"Extensão do arquivo de metadados\", str) = \".fth\",\n",
    "    levels_ext: Param(\"Extensão do arquivo de níveis\", str) = \".fth\",\n",
    "    substituir: Param(\n",
    "        \"Reprocessar e substituir arquivos existentes?\", store_true) = False,\n",
    "    dtype: Param(\"Tipo de Dado ao salvar o arquivo de nível\", str) = 'float16'\n",
    "):\n",
    "    entrada = Path(entrada)\n",
    "    if entrada.is_file():\n",
    "        lista_bins = [entrada]\n",
    "    else:\n",
    "        lista_bins = get_files(\n",
    "            entrada, extensions=[\".bin\"], recurse=recursivo, folders=pastas\n",
    "        )\n",
    "    parsed_bins = {}\n",
    "    meta_path = Path(f\"{saida}/meta\")\n",
    "    levels_path = Path(f\"{saida}/levels\")\n",
    "    meta_path.mkdir(exist_ok=True, parents=True)\n",
    "    levels_path.mkdir(exist_ok=True, parents=True)\n",
    "    log_meta = Path(f\"{saida}/log_meta.txt\")\n",
    "    log_levels = Path(f\"{saida}/log_levels.txt\")\n",
    "    if substituir:\n",
    "        done_meta = set()\n",
    "        done_levels = set()\n",
    "    else:\n",
    "\n",
    "        done_meta = (\n",
    "            set(log_meta.read_text().split(\"\\n\")) if log_meta.exists() else set()\n",
    "        )\n",
    "        done_levels = (\n",
    "            set(log_levels.read_text().split(\"\\n\")) if log_levels.exists() else set()\n",
    "        )\n",
    "\n",
    "    console.rule(\"Lista de Arquivos a serem processados\", style=\"bold red\")\n",
    "    console.print(\n",
    "        [f.name for f in lista_bins],\n",
    "        style=\"bold white\",\n",
    "        overflow=\"fold\",\n",
    "        justify=\"left\",\n",
    "    )\n",
    "    if not lista_bins:\n",
    "        console.print(\":sleeping: Nenhum arquivo .bin a processar :zzz:\")\n",
    "        return\n",
    "\n",
    "    if not levels:\n",
    "        lista_bins = [f for f in lista_bins if f.name not in done_meta]\n",
    "    else:\n",
    "        lista_bins = [f for f in lista_bins if f.name not in done_levels]\n",
    "\n",
    "    if not lista_bins:\n",
    "        console.print(\":sleeping: Nenhum arquivo novo a processar :zzz:\")\n",
    "        console.print(\n",
    "            \":point_up: use --substituir no terminal ou substituir=True na chamada caso queira reprocessar os bins e sobrepôr os arquivos existentes :wink:\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    try:\n",
    "\n",
    "        with Progress(transient=True, auto_refresh=False) as progress:\n",
    "            bins = progress.track(\n",
    "                lista_bins,\n",
    "                total=len(lista_bins),\n",
    "                description=\"[green]Processando Blocos Binários\",\n",
    "            )\n",
    "\n",
    "            for file in bins:\n",
    "                progress.console.print(f\"[cyan]Processando Blocos de: [red]{file.name}\")\n",
    "                parsed_bins[file.name] = parse_bin(file)\n",
    "                progress.refresh()\n",
    "\n",
    "            lista_meta = [(k,v) for k,v in parsed_bins.items() if k not in done_meta]\n",
    "\n",
    "            if lista_meta:\n",
    "                blocks = progress.track(\n",
    "                    lista_meta, total=len(lista_meta), description=\"[cyan]Exportando Metadados\"\n",
    "                )\n",
    "                for file, block in blocks:\n",
    "                    progress.console.print(\n",
    "                        f\"[cyan]Extraindo Metadados de: [red]{file}\"\n",
    "                    )\n",
    "                    export_meta(\n",
    "                        file, block, meta_path, ext=meta_ext\n",
    "                    )\n",
    "                    done_meta.add(file)\n",
    "                    progress.refresh()\n",
    "            if levels:\n",
    "                lista_levels = lista_meta = [(k,v) for k,v in parsed_bins.items() if k not in done_levels]\n",
    "                if lista_levels:\n",
    "                    bins = progress.track(\n",
    "                        lista_levels,\n",
    "                        total=len(lista_levels),\n",
    "                        description=\"[grey]Exportando Dados de Espectro\",\n",
    "                    )\n",
    "                    for file, block_obj in bins:\n",
    "                        progress.console.print(\n",
    "                            f\"[grey]Extraindo Espectro de: [red]{file}\"\n",
    "                        )\n",
    "                        meta_index = []\n",
    "                        blocks = block_obj[\"blocks\"]\n",
    "                        for (tipo, tid) in blocks.keys():\n",
    "                            if tipo not in SPECTRAL_BLOCKS:\n",
    "                                continue\n",
    "                            meta_file = Path(\n",
    "                                f\"{meta_path}/{file}-B_{tipo}_TId_{tid}{meta_ext}\"\n",
    "                            )\n",
    "                            if not meta_file.exists():\n",
    "                                export_meta(\n",
    "                                    file,\n",
    "                                    block_obj,\n",
    "                                    meta_path,\n",
    "                                    ext=meta_ext,\n",
    "                                )\n",
    "                                done_meta.add(file)\n",
    "                            meta_df = read_meta(meta_file)\n",
    "                            meta_index.append(meta_df.index.tolist())\n",
    "                        export_level(\n",
    "                            file,\n",
    "                            block_obj,\n",
    "                            levels_path,\n",
    "                            ext=levels_ext,\n",
    "                            index=meta_index,\n",
    "                            dtype=dtype\n",
    "                        )\n",
    "                        done_levels.add(file)\n",
    "                        progress.refresh()\n",
    "        console.print(\"kbô :satisfied:\")\n",
    "    finally:\n",
    "        log_meta.write_text(\"\\n\".join(sorted(list(done_meta))))\n",
    "        log_levels.write_text(\"\\n\".join(sorted(list(done_levels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_main.ipynb.\n",
      "Converted 01_parser.ipynb.\n",
      "Converted 02_utils.ipynb.\n",
      "Converted 03_blocks.ipynb.\n",
      "Converted 04_constants.ipynb.\n",
      "Converted 05_filter.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rfpy]",
   "language": "python",
   "name": "conda-env-rfpy-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
