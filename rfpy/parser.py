# AUTOGENERATED! DO NOT EDIT! File to edit: 01_parser.ipynb (unless otherwise specified).

__all__ = ['path_type', 'bin_val', 'bytes_encoded', 'datetime_object', 'META', 'LEVELS', 'COLS_B', 'BLOCO_40',
           'BLOCO_63', 'get_files', 'binary_file_generator', 'file2block', 'optimize_floats', 'optimize_ints',
           'optimize_objects', 'optimize', 'export_bin_level', 'export_bin_meta']

# Cell
from collections import defaultdict
from fastcore.basics import uniqueify
from fastcore.utils import parallel
from fastcore.foundation import L
from .blocks import create_base_block, block_constructor
import pandas as pd
import numpy as np
import os
from pathlib import Path
from typing import *
from datetime import datetime

path_type = Union[str, Any]
bin_val = Union[int, bytes]
bytes_encoded = Union[int, bytes]
datetime_object = datetime

META = {'Block_Number': 'uint16',
     'Latitude': 'float32',
     'Longitude': 'float32',
     'Altitude': 'float16',
     'Initial_Time': 'datetime64[ns]',
     'Sample_Duration': 'uint16',
     'Start_Frequency': 'uint32',
     'Stop_Frequency': 'uint32',
     'Vector_Length': 'uint16',
     'Trace_Type': 'category',
     'Antenna_Type': 'category',
     'Equipement_ID': 'category'}

LEVELS = {'Block_Number': 'category', 'Frequency(MHz)': 'category', "Nivel(dBm)" : 'float16'}

COLS_B = ['Block_Number', 'Frequency(MHz)', 'Nivel(dBm)']

BLOCO_40 = ['latitude', 'longitude', 'altitude']

BLOCO_63 = ['datetime_stamp',
           'spent_time_microsecs', 'start_mega', 'stop_mega', 'data_points',
           'processing', 'id_antenna']

# Cell
def _get_files(p, fs, extensions=None):
    p = Path(p)
    res = [p/f for f in fs if not f.startswith('.')
           and ((not extensions) or f'.{f.split(".")[-1].lower()}' in extensions)]
    return res

def get_files(path, extensions=None, recurse=True, folders=None, followlinks=True):
    "Get all the files in `path` with optional `extensions`, optionally with `recurse`, only in `folders`, if specified."
    path = Path(path)
    folders=L(folders)
    if extensions is not None:
        extensions = set(uniqueify(extensions))
        extensions = {e.lower() for e in extensions}
    if recurse:
        res = []
        for i,(p,d,f) in enumerate(os.walk(path, followlinks=followlinks)): # returns (dirpath, dirnames, filenames)
            if len(folders) !=0 and i==0: d[:] = [o for o in d if o in folders]
            else:                         d[:] = [o for o in d if not o.startswith('.')]
            if len(folders) !=0 and i==0 and '.' not in folders: continue
            res += _get_files(p, f, extensions)
    else:
        f = [o.name for o in os.scandir(path) if o.is_file()]
        res = _get_files(path, f, extensions)
    return L(res)

# Cell
def binary_file_generator(bin_file: path_type, marker: bytes = b'\x00UUUU', block_size: int = 4096) -> Iterator[bytes]:
    """
    str, bytes, int > bytes
    :param bin_file: arquivo binario que contém os dados
    :param marker: separador de blocos
    :param block_size: tamanho em bytes que é "lido" por vez no arquivo, evitando problemas de memória
    :return: bloco em formato binario
    Gerador que fornece a partir de de um arquivo binário, um bloco binário por vez.

    """
    with open(bin_file, mode='rb') as bfile:
        # O primeiro bloco do arquivo é o cabeçalho e tem 36 bytes de tamanho.
        yield bfile.read(36)
        # As demais partes podem prosseguir normalmente
        current = b''
        while True:
            block = bfile.read(block_size)
            if not block:  # end-of-file
                # yield current
                return None
            current += block
            while True:
                markerpos = current.find(marker)
                if markerpos < 0:
                    break
                yield current[:markerpos]
                current = current[markerpos + len(marker):]

# Cell
def file2block(file: Union[str, Path])->Mapping[int,L]:
    """Receives a path to a bin file and returns a defaultdict with unique block types as keys and a list of the Class Blocks as values
        :param file: A string or pathlib.Path like path to a `.bin`file generated by CFRS - Logger
        :return: A Dictionary with block types as keys and a list of the Class Blocks available as values
    """
    map_block = defaultdict(L)
    for bloco in L(binary_file_generator(file)).map(create_base_block):
        btype = bloco.type
        map_block[btype].append(block_constructor(btype, bloco))
    return map_block

# Cell
def optimize_floats(df: pd.DataFrame) -> pd.DataFrame:
    floats = df.select_dtypes(include=['float64']).columns.tolist()
    df[floats] = df[floats].apply(pd.to_numeric, downcast='float')
    return df


def optimize_ints(df: pd.DataFrame) -> pd.DataFrame:
    ints = df.select_dtypes(include=['int64']).columns.tolist()
    df[ints] = df[ints].apply(pd.to_numeric, downcast='integer')
    return df


def optimize_objects(df: pd.DataFrame, datetime_features: List[str]) -> pd.DataFrame:
    for col in df.select_dtypes(include=['object']):
        if col not in datetime_features:
            num_unique_values = len(df[col].unique())
            num_total_values = len(df[col])
            if float(num_unique_values) / num_total_values < 0.5:
                df[col] = df[col].astype('category')
        else:
            df[col] = pd.to_datetime(df[col])
    return df

def optimize(df: pd.DataFrame, datetime_features: List[str] = []):
    return optimize_floats(optimize_ints(optimize_objects(df, datetime_features)))


# Cell
def _extract_level(bloco: Any):
    return np.expand_dims(bloco.block_data, 0) # reshape((-1, 1))

def export_bin_level(map_block: Mapping[int,L], pivoted: bool = True, freq_dtype: str = 'float32')->pd.DataFrame:
    """Receives a mapping `map_block` and returns the Matrix with the Levels as values, Frequencies as columns and Block Number as index.
       :param pivoted: If False, optionally returns an unpivoted version of the Matrix
    """
    spectrum_blocks = map_block[63]
    assert len(spectrum_blocks), f"The spectrum block list is empty"
    levels = np.concatenate(parallel(_extract_level, spectrum_blocks, n_workers=8, progress=False))
    frequencies = getattr(spectrum_blocks[0], 'frequencies')
    pivot = pd.DataFrame(levels, columns=frequencies)
    if not pivoted:
#         unpivot = pivot.melt(var_name="Frequency(MHz)", value_name="Nivel(dBm)")
#         unpivot['Block_Number'] = levels.shape[0] * list(range(levels.shape[1]))
#         unpivot.sort_values(['Block_Number', 'Frequency(MHz)'], inplace=True)
#         unpivot.reset_index(drop=True, inplace=True)
#         unpivot =  unpivot.astype({'Block_Number': 'category', 'Frequency(MHz)': 'float32', "Nivel(dBm)" : 'float16'})
        # Doing directly as numpy is faster than pandas
        unpivot = np.array([np.repeat(np.arange(levels.shape[1]), levels.shape[0]),
                            np.tile(frequencies, levels.shape[0]),
                            levels.flatten()]).T
        return pd.DataFrame(unpivot, columns=COLS_B).astype(LEVELS)
    return pivot

# Cell
def export_bin_meta(map_block: Mapping[int,L])->pd.DataFrame:
    """Receives a Mapping with the different `. bin` Blocks and extracts the metadata listed in `META` in a dataframe format
    """
    if not len(map_block[63]):
        warnings.warn("Check if your Binary File is of type 63. GPS Block 40 length != Spectrum Block 63")
    n_data = len(map_block[63])
    output = {}
    output['Block_Number'] = L(range(n_data))
    for attr in BLOCO_40:
        output[attr] = map_block[40].attrgot(attr)
    for attr in BLOCO_63:
        output[attr] = map_block[63].attrgot(attr)
    output['Equipement_ID'] = L(getattr(map_block[21][0], 'hostname')) * n_data
    df = pd.DataFrame(output)
    df.columns = META.keys()
#     for col, dtype in zip(df.columns, META_DTYPE):
#         df[col] = df[col].astype(dtype)
    return df.astype(META)
